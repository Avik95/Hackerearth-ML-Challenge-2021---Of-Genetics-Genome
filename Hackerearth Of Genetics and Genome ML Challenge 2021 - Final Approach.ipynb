{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACKEREARTH OF GENETICS AND GENOME CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Packages :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import missingpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# deep learning packages :\n",
    "# tensorflow :\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "# keras :\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,InputLayer,BatchNormalization,GaussianDropout,AlphaDropout\n",
    "from tensorflow.keras import optimizers,layers,initializers,regularizers,activations,losses,metrics\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# visualization packages :\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Datasets : \n",
      "\n",
      "   Patient Id  Patient Age Genes in mother's side Inherited from father  \\\n",
      "0  PID0x6418          2.0                    Yes                    No   \n",
      "1  PID0x25d5          4.0                    Yes                   Yes   \n",
      "2  PID0x4a82          6.0                    Yes                    No   \n",
      "3  PID0x4ac8         12.0                    Yes                    No   \n",
      "4  PID0x1bf7         11.0                    Yes                    No   \n",
      "\n",
      "  Maternal gene Paternal gene  Blood cell count (mcL) Patient First Name  \\\n",
      "0           Yes            No                4.760603            Richard   \n",
      "1            No            No                4.910669               Mike   \n",
      "2            No            No                4.893297           Kimberly   \n",
      "3           Yes            No                4.705280            Jeffery   \n",
      "4           NaN           Yes                4.720703            Johanna   \n",
      "\n",
      "  Family Name Father's name  ...  Birth defects  \\\n",
      "0         NaN         Larre  ...            NaN   \n",
      "1         NaN        Brycen  ...       Multiple   \n",
      "2         NaN        Nashon  ...       Singular   \n",
      "3   Hoelscher        Aayaan  ...       Singular   \n",
      "4    Stutzman         Suave  ...       Multiple   \n",
      "\n",
      "   White Blood cell count (thousand per microliter) Blood test result  \\\n",
      "0                                          9.857562               NaN   \n",
      "1                                          5.522560            normal   \n",
      "2                                               NaN            normal   \n",
      "3                                          7.919321      inconclusive   \n",
      "4                                          4.098210               NaN   \n",
      "\n",
      "  Symptom 1 Symptom 2 Symptom 3 Symptom 4  Symptom 5  \\\n",
      "0       1.0       1.0       1.0       1.0        1.0   \n",
      "1       1.0       NaN       1.0       1.0        0.0   \n",
      "2       0.0       1.0       1.0       1.0        1.0   \n",
      "3       0.0       0.0       1.0       0.0        0.0   \n",
      "4       0.0       0.0       0.0       0.0        NaN   \n",
      "\n",
      "                               Genetic Disorder  \\\n",
      "0   Mitochondrial genetic inheritance disorders   \n",
      "1                                           NaN   \n",
      "2  Multifactorial genetic inheritance disorders   \n",
      "3   Mitochondrial genetic inheritance disorders   \n",
      "4  Multifactorial genetic inheritance disorders   \n",
      "\n",
      "                     Disorder Subclass  \n",
      "0  Leber's hereditary optic neuropathy  \n",
      "1                      Cystic fibrosis  \n",
      "2                             Diabetes  \n",
      "3                       Leigh syndrome  \n",
      "4                               Cancer  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "Test Datasets  : \n",
      "\n",
      "   Patient Id  Patient Age Genes in mother's side Inherited from father  \\\n",
      "0  PID0x4175            6                     No                   Yes   \n",
      "1  PID0x21f5           10                    Yes                    No   \n",
      "2  PID0x49b8            5                     No                   NaN   \n",
      "3  PID0x2d97           13                     No                   Yes   \n",
      "4  PID0x58da            5                     No                   NaN   \n",
      "\n",
      "  Maternal gene Paternal gene  Blood cell count (mcL) Patient First Name  \\\n",
      "0            No            No                4.981655            Charles   \n",
      "1           NaN           Yes                5.118890          Catherine   \n",
      "2            No            No                4.876204              James   \n",
      "3           Yes            No                4.687767              Brian   \n",
      "4           NaN           Yes                5.152362               Gary   \n",
      "\n",
      "  Family Name Father's name  ...  \\\n",
      "0         NaN          Kore  ...   \n",
      "1         NaN        Homero  ...   \n",
      "2         NaN       Danield  ...   \n",
      "3         NaN       Orville  ...   \n",
      "4         NaN        Issiah  ...   \n",
      "\n",
      "   History of anomalies in previous pregnancies  No. of previous abortion  \\\n",
      "0                                           NaN                       2.0   \n",
      "1                                           Yes                       NaN   \n",
      "2                                            No                       0.0   \n",
      "3                                           Yes                       NaN   \n",
      "4                                            No                       NaN   \n",
      "\n",
      "  Birth defects White Blood cell count (thousand per microliter)  \\\n",
      "0      Multiple                                              NaN   \n",
      "1      Multiple                                         8.179584   \n",
      "2      Singular                                              NaN   \n",
      "3      Singular                                         6.884071   \n",
      "4      Multiple                                         6.195178   \n",
      "\n",
      "   Blood test result Symptom 1 Symptom 2  Symptom 3  Symptom 4  Symptom 5  \n",
      "0  slightly abnormal      True      True       True       True       True  \n",
      "1             normal     False     False      False       True      False  \n",
      "2  slightly abnormal     False     False       True       True      False  \n",
      "3             normal      True     False       True      False       True  \n",
      "4             normal      True      True       True       True      False  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train Datasets :\n",
    "\n",
    "train = pd.read_csv(\"K:/Hackerath Hackathon 2021/Hackerearth OfGenomes and Genetics Challenge/Dataset/train.csv\")\n",
    "\n",
    "# Test Datasets :\n",
    "\n",
    "test = pd.read_csv(\"K:/Hackerath Hackathon 2021/Hackerearth OfGenomes and Genetics Challenge/Dataset/test.csv\")\n",
    "\n",
    "print(\"Train Datasets : \\n\\n\" ,train.head())\n",
    "print(\"Test Datasets  : \\n\\n\" ,test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Unnecessary Columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_train = train.drop(['Patient Id','Patient First Name','Family Name',\"Father's name\"],axis='columns')\n",
    "\n",
    "edited_test = test.drop(['Patient Id','Patient First Name','Family Name',\"Father's name\"],axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Patient Age', 'Genes in mother's side', 'Inherited from father',\n",
       "       'Maternal gene', 'Paternal gene', 'Blood cell count (mcL)',\n",
       "       'Mother's age', 'Father's age', 'Institute Name',\n",
       "       'Location of Institute', 'Status', 'Respiratory Rate (breaths/min)',\n",
       "       'Heart Rate (rates/min', 'Test 1', 'Test 2', 'Test 3', 'Test 4',\n",
       "       'Test 5', 'Parental consent', 'Follow-up', 'Gender', 'Birth asphyxia',\n",
       "       'Autopsy shows birth defect (if applicable)', 'Place of birth',\n",
       "       'Folic acid details (peri-conceptional)',\n",
       "       'H/O serious maternal illness', 'H/O radiation exposure (x-ray)',\n",
       "       'H/O substance abuse', 'Assisted conception IVF/ART',\n",
       "       'History of anomalies in previous pregnancies',\n",
       "       'No. of previous abortion', 'Birth defects',\n",
       "       'White Blood cell count (thousand per microliter)', 'Blood test result',\n",
       "       'Symptom 1', 'Symptom 2', 'Symptom 3', 'Symptom 4', 'Symptom 5',\n",
       "       'Genetic Disorder', 'Disorder Subclass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking missing values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient Age                                          1427\n",
       "Genes in mother's side                                  0\n",
       "Inherited from father                                 306\n",
       "Maternal gene                                        2810\n",
       "Paternal gene                                           0\n",
       "Blood cell count (mcL)                                  0\n",
       "Mother's age                                         6036\n",
       "Father's age                                         5986\n",
       "Institute Name                                       5106\n",
       "Location of Institute                               10931\n",
       "Status                                                  0\n",
       "Respiratory Rate (breaths/min)                       2149\n",
       "Heart Rate (rates/min                                2113\n",
       "Test 1                                               2127\n",
       "Test 2                                               2152\n",
       "Test 3                                               2147\n",
       "Test 4                                               2140\n",
       "Test 5                                               2170\n",
       "Parental consent                                     2125\n",
       "Follow-up                                            2166\n",
       "Gender                                               2173\n",
       "Birth asphyxia                                       2139\n",
       "Autopsy shows birth defect (if applicable)           1026\n",
       "Place of birth                                       2124\n",
       "Folic acid details (peri-conceptional)               2117\n",
       "H/O serious maternal illness                         2152\n",
       "H/O radiation exposure (x-ray)                       7069\n",
       "H/O substance abuse                                  7237\n",
       "Assisted conception IVF/ART                          2122\n",
       "History of anomalies in previous pregnancies         2172\n",
       "No. of previous abortion                             2162\n",
       "Birth defects                                        2154\n",
       "White Blood cell count (thousand per microliter)     2148\n",
       "Blood test result                                    2145\n",
       "Symptom 1                                            2155\n",
       "Symptom 2                                            2222\n",
       "Symptom 3                                            2101\n",
       "Symptom 4                                            2113\n",
       "Symptom 5                                            2153\n",
       "Genetic Disorder                                     2146\n",
       "Disorder Subclass                                    2168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient Age                                            0\n",
       "Genes in mother's side                                 0\n",
       "Inherited from father                                551\n",
       "Maternal gene                                       3723\n",
       "Paternal gene                                          0\n",
       "Blood cell count (mcL)                                 0\n",
       "Mother's age                                           0\n",
       "Father's age                                           0\n",
       "Institute Name                                      5004\n",
       "Location of Institute                               4760\n",
       "Status                                                 0\n",
       "Respiratory Rate (breaths/min)                      4991\n",
       "Heart Rate (rates/min                               4974\n",
       "Test 1                                              2120\n",
       "Test 2                                              2081\n",
       "Test 3                                              2099\n",
       "Test 4                                              2082\n",
       "Test 5                                              2091\n",
       "Parental consent                                    2095\n",
       "Follow-up                                           2090\n",
       "Gender                                              2102\n",
       "Birth asphyxia                                      2079\n",
       "Autopsy shows birth defect (if applicable)          1063\n",
       "Place of birth                                      2089\n",
       "Folic acid details (peri-conceptional)              2092\n",
       "H/O serious maternal illness                        2080\n",
       "H/O radiation exposure (x-ray)                      3867\n",
       "H/O substance abuse                                 3904\n",
       "Assisted conception IVF/ART                         2085\n",
       "History of anomalies in previous pregnancies        2097\n",
       "No. of previous abortion                            2096\n",
       "Birth defects                                       2095\n",
       "White Blood cell count (thousand per microliter)    2102\n",
       "Blood test result                                   2080\n",
       "Symptom 1                                              0\n",
       "Symptom 2                                              0\n",
       "Symptom 3                                              0\n",
       "Symptom 4                                              0\n",
       "Symptom 5                                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_train['Location of Institute'] = pd.factorize(edited_train['Location of Institute'])[0]\n",
    "edited_train['Institute Name'] = pd.factorize(edited_train['Institute Name'])[0]\n",
    "edited_train['Test 1'] = pd.factorize(edited_train['Test 1'])[0]\n",
    "edited_train['Test 2'] = pd.factorize(edited_train['Test 2'])[0]\n",
    "edited_train['Test 3'] = pd.factorize(edited_train['Test 3'])[0]\n",
    "edited_train['Test 4'] = pd.factorize(edited_train['Test 4'])[0]\n",
    "edited_train['Test 5'] = pd.factorize(edited_train['Test 5'])[0]\n",
    "edited_train['Gender'] = pd.factorize(edited_train['Gender'])[0]\n",
    "edited_train['Autopsy shows birth defect (if applicable)'] = pd.factorize(edited_train['Autopsy shows birth defect (if applicable)'])[0]\n",
    "edited_train['Place of birth'] = pd.factorize(edited_train['Place of birth'])[0]\n",
    "edited_train['Folic acid details (peri-conceptional)'] = pd.factorize(edited_train['Folic acid details (peri-conceptional)'])[0]\n",
    "edited_train['H/O serious maternal illness'] = pd.factorize(edited_train['H/O serious maternal illness'])[0]\n",
    "edited_train['H/O radiation exposure (x-ray)'] = pd.factorize(edited_train['H/O radiation exposure (x-ray)'])[0]\n",
    "edited_train['H/O substance abuse'] = pd.factorize(edited_train['H/O substance abuse'])[0]\n",
    "edited_train['Assisted conception IVF/ART'] = pd.factorize(edited_train['Assisted conception IVF/ART'])[0]\n",
    "edited_train['History of anomalies in previous pregnancies'] = pd.factorize(edited_train['History of anomalies in previous pregnancies'])[0]\n",
    "edited_train['Birth defects'] = pd.factorize(edited_train['Birth defects'])[0]\n",
    "edited_train['Blood test result'] = pd.factorize(edited_train['Blood test result'])[0]\n",
    "edited_train['Symptom 1'] = pd.factorize(edited_train['Symptom 1'])[0]\n",
    "edited_train['Symptom 2'] = pd.factorize(edited_train['Symptom 2'])[0]\n",
    "edited_train['Symptom 3'] = pd.factorize(edited_train['Symptom 3'])[0]\n",
    "edited_train['Symptom 4'] = pd.factorize(edited_train['Symptom 4'])[0]\n",
    "edited_train['Symptom 5'] = pd.factorize(edited_train['Symptom 5'])[0]\n",
    "edited_train[\"Genes in mother's side\"] = pd.factorize(edited_train[\"Genes in mother's side\"])[0]\n",
    "edited_train['Paternal gene'] = pd.factorize(edited_train['Paternal gene'])[0]\n",
    "edited_train['Status'] = pd.factorize(edited_train['Status'])[0]\n",
    "edited_train['Inherited from father'] = pd.factorize(edited_train['Inherited from father'])[0]\n",
    "edited_train['Maternal gene'] = pd.factorize(edited_train['Maternal gene'])[0]\n",
    "edited_train['Respiratory Rate (breaths/min)'] = pd.factorize(edited_train['Respiratory Rate (breaths/min)'])[0]\n",
    "edited_train['Heart Rate (rates/min'] = pd.factorize(edited_train['Heart Rate (rates/min'])[0]\n",
    "edited_train['Birth asphyxia'] = pd.factorize(edited_train['Birth asphyxia'])[0]\n",
    "edited_train['Parental consent'] = pd.factorize(edited_train['Parental consent'])[0]\n",
    "edited_train['Follow-up'] = pd.factorize(edited_train['Follow-up'])[0]\n",
    "\n",
    "label1 = pd.factorize(edited_train['Genetic Disorder'])[1]\n",
    "label2 = pd.factorize(edited_train['Disorder Subclass'])[1]\n",
    "\n",
    "edited_train['Genetic Disorder'] = pd.factorize(edited_train['Genetic Disorder'])[0]\n",
    "edited_train['Disorder Subclass'] = pd.factorize(edited_train['Disorder Subclass'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = LabelEncoder()\n",
    "genetic_disorder_encoded = encoder1.fit_transform(label1)\n",
    "encoder2 = LabelEncoder()\n",
    "disorder_subclass_encoded = encoder2.fit_transform(label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_test['Inherited from father'] = pd.factorize(edited_test['Inherited from father'])[0]\n",
    "edited_test['Maternal gene'] = pd.factorize(edited_test['Maternal gene'])[0]\n",
    "edited_test['Institute Name'] = pd.factorize(edited_test['Institute Name'])[0]\n",
    "edited_test['Location of Institute'] = pd.factorize(edited_test['Location of Institute'])[0]\n",
    "edited_test['Respiratory Rate (breaths/min)'] = pd.factorize(edited_test['Respiratory Rate (breaths/min)'])[0]\n",
    "edited_test['Heart Rate (rates/min'] = pd.factorize(edited_test['Heart Rate (rates/min'])[0]\n",
    "edited_test['Test 1'] = pd.factorize(edited_test['Test 1'])[0]\n",
    "edited_test['Test 2'] = pd.factorize(edited_test['Test 2'])[0]\n",
    "edited_test['Test 3'] = pd.factorize(edited_test['Test 3'])[0]\n",
    "edited_test['Test 4'] = pd.factorize(edited_test['Test 4'])[0]\n",
    "edited_test['Test 5'] = pd.factorize(edited_test['Test 5'])[0]\n",
    "edited_test['Parental consent'] = pd.factorize(edited_test['Parental consent'])[0]\n",
    "edited_test['Follow-up'] = pd.factorize(edited_test['Follow-up'])[0]\n",
    "edited_test['Gender'] = pd.factorize(edited_test['Gender'])[0]\n",
    "edited_test['Birth asphyxia'] = pd.factorize(edited_test['Birth asphyxia'])[0]\n",
    "edited_test['Autopsy shows birth defect (if applicable)'] = pd.factorize(edited_test['Autopsy shows birth defect (if applicable)'])[0]\n",
    "edited_test['Place of birth'] = pd.factorize(edited_test['Place of birth'])[0]\n",
    "edited_test['Folic acid details (peri-conceptional)'] = pd.factorize(edited_test['Folic acid details (peri-conceptional)'])[0]\n",
    "edited_test['H/O serious maternal illness'] = pd.factorize(edited_test['H/O serious maternal illness'])[0]\n",
    "edited_test['H/O radiation exposure (x-ray)'] = pd.factorize(edited_test['H/O radiation exposure (x-ray)'])[0]\n",
    "edited_test['H/O substance abuse'] = pd.factorize(edited_test['H/O substance abuse'])[0]\n",
    "edited_test['Assisted conception IVF/ART'] = pd.factorize(edited_test['Assisted conception IVF/ART'])[0]\n",
    "edited_test['History of anomalies in previous pregnancies'] = pd.factorize(edited_test['History of anomalies in previous pregnancies'])[0]\n",
    "edited_test['Birth defects'] = pd.factorize(edited_test['Birth defects'])[0]\n",
    "edited_test['Blood test result'] = pd.factorize(edited_test['Blood test result'])[0]\n",
    "edited_test['Paternal gene'] = pd.factorize(edited_test['Paternal gene'])[0]\n",
    "edited_test['Status'] = pd.factorize(edited_test['Status'])[0]\n",
    "edited_test[\"Genes in mother's side\"] = pd.factorize(edited_test[\"Genes in mother's side\"])[0]\n",
    "edited_test['Symptom 1'] = pd.factorize(edited_test['Symptom 1'])[0]\n",
    "edited_test['Symptom 2'] = pd.factorize(edited_test['Symptom 2'])[0]\n",
    "edited_test['Symptom 3'] = pd.factorize(edited_test['Symptom 3'])[0]\n",
    "edited_test['Symptom 4'] = pd.factorize(edited_test['Symptom 4'])[0]\n",
    "edited_test['Symptom 5'] = pd.factorize(edited_test['Symptom 5'])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_train = edited_train.replace(-1,np.nan)\n",
    "edited_test = edited_test.replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22083, 41), (9465, 39))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_train.shape , edited_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = []\n",
    "for i in range(41):\n",
    "    j.append(i)\n",
    "    \n",
    "k = []\n",
    "for i in range(39):\n",
    "    k.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "# Performing Imputation on train data :\n",
    "\n",
    "imputer1 = missingpy.MissForest(random_state=42)\n",
    "imputed_train = imputer1.fit_transform(edited_train.iloc[:,j])\n",
    "\n",
    "\n",
    "# Performing imputation on test data :\n",
    "\n",
    "imputer2 = missingpy.MissForest(random_state = 50)\n",
    "imputed_test = imputer2.fit_transform(edited_test.iloc[:,k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_train.iloc[:,:] = imputed_train\n",
    "edited_test.iloc[:,:] = imputed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Genes in mother's side</th>\n",
       "      <th>Inherited from father</th>\n",
       "      <th>Maternal gene</th>\n",
       "      <th>Paternal gene</th>\n",
       "      <th>Blood cell count (mcL)</th>\n",
       "      <th>Mother's age</th>\n",
       "      <th>Father's age</th>\n",
       "      <th>Institute Name</th>\n",
       "      <th>Location of Institute</th>\n",
       "      <th>...</th>\n",
       "      <th>Birth defects</th>\n",
       "      <th>White Blood cell count (thousand per microliter)</th>\n",
       "      <th>Blood test result</th>\n",
       "      <th>Symptom 1</th>\n",
       "      <th>Symptom 2</th>\n",
       "      <th>Symptom 3</th>\n",
       "      <th>Symptom 4</th>\n",
       "      <th>Symptom 5</th>\n",
       "      <th>Genetic Disorder</th>\n",
       "      <th>Disorder Subclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.760603</td>\n",
       "      <td>36.2</td>\n",
       "      <td>40.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>9.857562</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.910669</td>\n",
       "      <td>35.1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.522560</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.893297</td>\n",
       "      <td>41.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.68</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.771881</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.705280</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.20</td>\n",
       "      <td>14.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.919321</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.720703</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.098210</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22078</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.258298</td>\n",
       "      <td>35.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.584811</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22079</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.974220</td>\n",
       "      <td>34.9</td>\n",
       "      <td>56.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.041556</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22080</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.186470</td>\n",
       "      <td>35.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.715464</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22081</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.858543</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.437670</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22082</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.738067</td>\n",
       "      <td>32.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.188371</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22083 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient Age  Genes in mother's side  Inherited from father  \\\n",
       "0              2.0                     0.0                    0.0   \n",
       "1              4.0                     0.0                    1.0   \n",
       "2              6.0                     0.0                    0.0   \n",
       "3             12.0                     0.0                    0.0   \n",
       "4             11.0                     0.0                    0.0   \n",
       "...            ...                     ...                    ...   \n",
       "22078          4.0                     0.0                    1.0   \n",
       "22079          8.0                     1.0                    1.0   \n",
       "22080          8.0                     0.0                    0.0   \n",
       "22081          7.0                     0.0                    0.0   \n",
       "22082         11.0                     0.0                    0.0   \n",
       "\n",
       "       Maternal gene  Paternal gene  Blood cell count (mcL)  Mother's age  \\\n",
       "0               0.00            0.0                4.760603          36.2   \n",
       "1               1.00            0.0                4.910669          35.1   \n",
       "2               1.00            0.0                4.893297          41.0   \n",
       "3               0.00            0.0                4.705280          21.0   \n",
       "4               0.58            1.0                4.720703          32.0   \n",
       "...              ...            ...                     ...           ...   \n",
       "22078           0.00            0.0                5.258298          35.0   \n",
       "22079           1.00            1.0                4.974220          34.9   \n",
       "22080           0.00            0.0                5.186470          35.0   \n",
       "22081           0.00            1.0                4.858543          19.0   \n",
       "22082           1.00            0.0                4.738067          32.0   \n",
       "\n",
       "       Father's age  Institute Name  Location of Institute  ...  \\\n",
       "0             40.94            0.00                   0.00  ...   \n",
       "1             23.00            1.00                   1.00  ...   \n",
       "2             22.00            4.00                  12.68  ...   \n",
       "3             42.20           14.74                   0.00  ...   \n",
       "4             44.18            2.00                   2.00  ...   \n",
       "...             ...             ...                    ...  ...   \n",
       "22078         64.00           17.00                  19.00  ...   \n",
       "22079         56.00           22.00                  12.00  ...   \n",
       "22080         51.00            4.00                  12.25  ...   \n",
       "22081         44.27            4.00                  10.71  ...   \n",
       "22082         62.00           23.00                   2.00  ...   \n",
       "\n",
       "       Birth defects  White Blood cell count (thousand per microliter)  \\\n",
       "0               0.31                                          9.857562   \n",
       "1               0.00                                          5.522560   \n",
       "2               1.00                                          7.771881   \n",
       "3               1.00                                          7.919321   \n",
       "4               0.00                                          4.098210   \n",
       "...              ...                                               ...   \n",
       "22078           0.00                                          6.584811   \n",
       "22079           0.00                                          7.041556   \n",
       "22080           1.00                                          7.715464   \n",
       "22081           0.00                                          8.437670   \n",
       "22082           1.00                                         11.188371   \n",
       "\n",
       "       Blood test result  Symptom 1  Symptom 2  Symptom 3  Symptom 4  \\\n",
       "0                   1.26        0.0       0.00        0.0        0.0   \n",
       "1                   0.00        0.0       0.34        0.0        0.0   \n",
       "2                   0.00        1.0       0.00        0.0        0.0   \n",
       "3                   1.00        1.0       1.00        0.0        1.0   \n",
       "4                   1.51        1.0       1.00        1.0        1.0   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "22078               1.00        1.0       1.00        0.0        1.0   \n",
       "22079               1.00        0.0       0.00        0.0        0.0   \n",
       "22080               0.00        1.0       1.00        1.0        0.0   \n",
       "22081               3.00        0.0       0.00        0.0        1.0   \n",
       "22082               0.00        0.0       1.00        0.0        0.0   \n",
       "\n",
       "       Symptom 5  Genetic Disorder  Disorder Subclass  \n",
       "0           0.00               0.0                0.0  \n",
       "1           1.00               2.0                1.0  \n",
       "2           0.00               1.0                2.0  \n",
       "3           1.00               0.0                3.0  \n",
       "4           1.00               1.0                4.0  \n",
       "...          ...               ...                ...  \n",
       "22078       1.00               0.0                3.0  \n",
       "22079       1.00               1.0                2.0  \n",
       "22080       0.35               0.0                7.0  \n",
       "22081       1.00               0.0                3.0  \n",
       "22082       0.00               1.0                2.0  \n",
       "\n",
       "[22083 rows x 41 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Genes in mother's side</th>\n",
       "      <th>Inherited from father</th>\n",
       "      <th>Maternal gene</th>\n",
       "      <th>Paternal gene</th>\n",
       "      <th>Blood cell count (mcL)</th>\n",
       "      <th>Mother's age</th>\n",
       "      <th>Father's age</th>\n",
       "      <th>Institute Name</th>\n",
       "      <th>Location of Institute</th>\n",
       "      <th>...</th>\n",
       "      <th>History of anomalies in previous pregnancies</th>\n",
       "      <th>No. of previous abortion</th>\n",
       "      <th>Birth defects</th>\n",
       "      <th>White Blood cell count (thousand per microliter)</th>\n",
       "      <th>Blood test result</th>\n",
       "      <th>Symptom 1</th>\n",
       "      <th>Symptom 2</th>\n",
       "      <th>Symptom 3</th>\n",
       "      <th>Symptom 4</th>\n",
       "      <th>Symptom 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.981655</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.921911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.118890</td>\n",
       "      <td>33.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.179584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.876204</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.31</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.601921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.687767</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.884071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.152362</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.195178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.878335</td>\n",
       "      <td>28.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.89</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.234960</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.927151</td>\n",
       "      <td>37.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.859536</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.898352</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>5.696062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.804840</td>\n",
       "      <td>36.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9464</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.421236</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11.08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.492765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9465 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient Age  Genes in mother's side  Inherited from father  \\\n",
       "0             6.0                     0.0                   0.00   \n",
       "1            10.0                     1.0                   1.00   \n",
       "2             5.0                     0.0                   0.58   \n",
       "3            13.0                     0.0                   0.00   \n",
       "4             5.0                     0.0                   0.59   \n",
       "...           ...                     ...                    ...   \n",
       "9460          9.0                     1.0                   0.00   \n",
       "9461          1.0                     1.0                   1.00   \n",
       "9462          2.0                     0.0                   0.00   \n",
       "9463         13.0                     0.0                   0.00   \n",
       "9464         12.0                     0.0                   1.00   \n",
       "\n",
       "      Maternal gene  Paternal gene  Blood cell count (mcL)  Mother's age  \\\n",
       "0              0.00            0.0                4.981655          38.0   \n",
       "1              0.67            1.0                5.118890          33.0   \n",
       "2              0.00            0.0                4.876204          48.0   \n",
       "3              1.00            0.0                4.687767          25.0   \n",
       "4              0.72            1.0                5.152362          41.0   \n",
       "...             ...            ...                     ...           ...   \n",
       "9460           0.79            0.0                4.878335          28.0   \n",
       "9461           0.48            1.0                4.927151          37.0   \n",
       "9462           0.00            0.0                4.898352          24.0   \n",
       "9463           0.00            0.0                4.804840          36.0   \n",
       "9464           1.00            1.0                5.421236          40.0   \n",
       "\n",
       "      Father's age  Institute Name  Location of Institute  ...  \\\n",
       "0             61.0            0.00                   0.00  ...   \n",
       "1             53.0           14.60                   1.00  ...   \n",
       "2             60.0           14.31                   2.00  ...   \n",
       "3             55.0            1.00                   3.00  ...   \n",
       "4             38.0            2.00                  10.53  ...   \n",
       "...            ...             ...                    ...  ...   \n",
       "9460          63.0           10.89                   3.00  ...   \n",
       "9461          62.0           11.99                   5.00  ...   \n",
       "9462          32.0           23.00                  14.00  ...   \n",
       "9463          56.0            2.00                  10.78  ...   \n",
       "9464          35.0            2.00                  11.08  ...   \n",
       "\n",
       "      History of anomalies in previous pregnancies  No. of previous abortion  \\\n",
       "0                                             0.30                      2.00   \n",
       "1                                             0.00                      1.81   \n",
       "2                                             1.00                      0.00   \n",
       "3                                             0.00                      1.72   \n",
       "4                                             1.00                      1.68   \n",
       "...                                            ...                       ...   \n",
       "9460                                          0.00                      2.00   \n",
       "9461                                          1.00                      1.68   \n",
       "9462                                          1.00                      3.00   \n",
       "9463                                          0.49                      1.00   \n",
       "9464                                          1.00                      0.00   \n",
       "\n",
       "      Birth defects  White Blood cell count (thousand per microliter)  \\\n",
       "0              0.00                                          6.921911   \n",
       "1              0.00                                          8.179584   \n",
       "2              1.00                                          7.601921   \n",
       "3              1.00                                          6.884071   \n",
       "4              0.00                                          6.195178   \n",
       "...             ...                                               ...   \n",
       "9460           0.00                                          7.234960   \n",
       "9461           1.00                                          4.859536   \n",
       "9462           0.44                                          5.696062   \n",
       "9463           1.00                                          3.000000   \n",
       "9464           1.00                                          7.492765   \n",
       "\n",
       "      Blood test result  Symptom 1  Symptom 2  Symptom 3  Symptom 4  Symptom 5  \n",
       "0                   0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1                   1.0        1.0        1.0        1.0        0.0        1.0  \n",
       "2                   0.0        1.0        1.0        0.0        0.0        1.0  \n",
       "3                   1.0        0.0        1.0        0.0        1.0        0.0  \n",
       "4                   1.0        0.0        0.0        0.0        0.0        1.0  \n",
       "...                 ...        ...        ...        ...        ...        ...  \n",
       "9460                3.0        1.0        0.0        0.0        0.0        1.0  \n",
       "9461                3.0        1.0        0.0        1.0        0.0        0.0  \n",
       "9462                1.0        1.0        0.0        1.0        1.0        0.0  \n",
       "9463                2.0        0.0        0.0        0.0        0.0        0.0  \n",
       "9464                3.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[9465 rows x 39 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize the columns :¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_train = round(edited_train,0).astype(int)\n",
    "edited_test = round(edited_test,0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning : Keras Sequential Wide Deep Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 : Modelling for 'Genetic Disorder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing keras model \n",
    "\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(150)        # for reproductive reason\n",
    "\n",
    "def baseline_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = [39]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation = LeakyReLU(0.3),\n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 100),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001,l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(64, activation = LeakyReLU(0.3) , \n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 200),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001 , l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(64, activation = LeakyReLU(0.3) , \n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 300),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001 , l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(3, activation = 'softmax', \n",
    "                    kernel_initializer = initializers.he_normal(seed = 400),\n",
    "                    use_bias = True))\n",
    "    model.output_shape       # you can ignore this \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer = \"adam\", \n",
    "                  metrics = \"accuracy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 39)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 39)                156       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               20480     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropou (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropou (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,383\n",
      "Trainable params: 59,025\n",
      "Non-trainable params: 1,358\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "553/553 [==============================] - 27s 7ms/step - loss: 1.0446 - accuracy: 0.4883 - val_loss: 0.7990 - val_accuracy: 0.6577\n",
      "Epoch 2/20\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.7965 - accuracy: 0.6256 - val_loss: 0.7392 - val_accuracy: 0.6622\n",
      "Epoch 3/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7716 - accuracy: 0.6408 - val_loss: 0.7439 - val_accuracy: 0.6670\n",
      "Epoch 4/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7697 - accuracy: 0.6376 - val_loss: 0.7259 - val_accuracy: 0.6690\n",
      "Epoch 5/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7627 - accuracy: 0.6379 - val_loss: 0.7189 - val_accuracy: 0.6708\n",
      "Epoch 6/20\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.7394 - accuracy: 0.6502 - val_loss: 0.7412 - val_accuracy: 0.6658\n",
      "Epoch 7/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7406 - accuracy: 0.6561 - val_loss: 0.7024 - val_accuracy: 0.6817\n",
      "Epoch 8/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7426 - accuracy: 0.6478 - val_loss: 0.7077 - val_accuracy: 0.6679\n",
      "Epoch 9/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7419 - accuracy: 0.6558 - val_loss: 0.7134 - val_accuracy: 0.6783\n",
      "Epoch 10/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7261 - accuracy: 0.6608 - val_loss: 0.7059 - val_accuracy: 0.6781\n",
      "Epoch 11/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7323 - accuracy: 0.6654 - val_loss: 0.7027 - val_accuracy: 0.6767\n",
      "Epoch 12/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7424 - accuracy: 0.6460 - val_loss: 0.7074 - val_accuracy: 0.6708\n",
      "Epoch 13/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7203 - accuracy: 0.6663 - val_loss: 0.7146 - val_accuracy: 0.6633\n",
      "Epoch 14/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7230 - accuracy: 0.6700 - val_loss: 0.7130 - val_accuracy: 0.6783\n",
      "Epoch 15/20\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.7135 - accuracy: 0.6650 - val_loss: 0.7445 - val_accuracy: 0.6457\n",
      "Epoch 16/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7182 - accuracy: 0.6664 - val_loss: 0.7025 - val_accuracy: 0.6772\n",
      "Epoch 17/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7206 - accuracy: 0.6706 - val_loss: 0.7222 - val_accuracy: 0.6584\n",
      "Epoch 18/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7013 - accuracy: 0.6804 - val_loss: 0.7110 - val_accuracy: 0.6729\n",
      "Epoch 19/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7111 - accuracy: 0.6716 - val_loss: 0.7218 - val_accuracy: 0.6636\n",
      "Epoch 20/20\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7037 - accuracy: 0.6740 - val_loss: 0.7215 - val_accuracy: 0.6749\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "\n",
    "# fit model\n",
    "history = estimator.fit(edited_train.iloc[:,:39] , edited_train['Genetic Disorder'] , \n",
    "                        validation_split = 0.2, \n",
    "                        epochs=20, \n",
    "                        verbose=1, \n",
    "                        batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for 'Genetic Disorder':\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend(loc ='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(xlabel=\"epochs\")\n",
    "plt.ylabel(ylabel=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation : We see 80% train data gives accuracy 0.6740 and 20% train data treated as valid data is giving 0.6749 accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 : Modelling for 'Disorder Subclass' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing keras model \n",
    "\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(350)        # for reproductive reason\n",
    "\n",
    "def baseline_model2():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = [40]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation = LeakyReLU(0.3),\n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 100),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001,l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(64, activation = LeakyReLU(0.3) , \n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 200),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001 , l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(64, activation = LeakyReLU(0.3) , \n",
    "                    kernel_initializer = initializers.glorot_normal(seed = 300),\n",
    "                    bias_regularizer = regularizers.L1L2(l1 = 0.001 , l2 = 0.001),\n",
    "                    bias_initializer = 'zeros',\n",
    "                    use_bias = True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AlphaDropout(0.025))\n",
    "    model.add(Dense(9, activation = 'softmax', \n",
    "                    kernel_initializer = initializers.he_normal(seed = 400),\n",
    "                    use_bias = True))\n",
    "    model.output_shape       # you can ignore this \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer = \"adam\", \n",
    "                  metrics = \"accuracy\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               20992     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "alpha_dropout_6 (AlphaDropou (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "alpha_dropout_7 (AlphaDropou (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "alpha_dropout_8 (AlphaDropou (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 61,289\n",
      "Trainable params: 59,929\n",
      "Non-trainable params: 1,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model2().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator2 = KerasClassifier(build_fn=baseline_model2,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "553/553 [==============================] - 6s 5ms/step - loss: 1.1775 - accuracy: 0.5735 - val_loss: 0.6886 - val_accuracy: 0.7295\n",
      "Epoch 2/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7679 - accuracy: 0.7060 - val_loss: 0.6696 - val_accuracy: 0.7342\n",
      "Epoch 3/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7432 - accuracy: 0.7049 - val_loss: 0.6567 - val_accuracy: 0.7455\n",
      "Epoch 4/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7075 - accuracy: 0.7178 - val_loss: 0.6762 - val_accuracy: 0.7338\n",
      "Epoch 5/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.7021 - accuracy: 0.7235 - val_loss: 0.6467 - val_accuracy: 0.7458\n",
      "Epoch 6/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6895 - accuracy: 0.7232 - val_loss: 0.6467 - val_accuracy: 0.7415\n",
      "Epoch 7/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6854 - accuracy: 0.7321 - val_loss: 0.6491 - val_accuracy: 0.7471\n",
      "Epoch 8/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6899 - accuracy: 0.7231 - val_loss: 0.6431 - val_accuracy: 0.7480\n",
      "Epoch 9/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.7381 - val_loss: 0.6393 - val_accuracy: 0.7433\n",
      "Epoch 10/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6689 - accuracy: 0.7293 - val_loss: 0.6348 - val_accuracy: 0.7487\n",
      "Epoch 11/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6793 - accuracy: 0.7266 - val_loss: 0.6437 - val_accuracy: 0.7403\n",
      "Epoch 12/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6761 - accuracy: 0.7273 - val_loss: 0.6582 - val_accuracy: 0.7365\n",
      "Epoch 13/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6623 - accuracy: 0.7298 - val_loss: 0.6528 - val_accuracy: 0.7387\n",
      "Epoch 14/24\n",
      "553/553 [==============================] - 3s 6ms/step - loss: 0.6630 - accuracy: 0.7335 - val_loss: 0.6455 - val_accuracy: 0.7410\n",
      "Epoch 15/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6599 - accuracy: 0.7316 - val_loss: 0.6353 - val_accuracy: 0.7469\n",
      "Epoch 16/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6582 - accuracy: 0.7334 - val_loss: 0.6497 - val_accuracy: 0.7435\n",
      "Epoch 17/24\n",
      "553/553 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.7346 - val_loss: 0.6539 - val_accuracy: 0.7378\n",
      "Epoch 18/24\n",
      "553/553 [==============================] - 3s 6ms/step - loss: 0.6558 - accuracy: 0.7341 - val_loss: 0.6487 - val_accuracy: 0.7405\n",
      "Epoch 19/24\n",
      "553/553 [==============================] - 3s 6ms/step - loss: 0.6568 - accuracy: 0.7322 - val_loss: 0.6336 - val_accuracy: 0.7419\n",
      "Epoch 20/24\n",
      "553/553 [==============================] - 3s 5ms/step - loss: 0.6451 - accuracy: 0.7369 - val_loss: 0.6432 - val_accuracy: 0.7455\n",
      "Epoch 21/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6597 - accuracy: 0.7296 - val_loss: 0.6527 - val_accuracy: 0.7433\n",
      "Epoch 22/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6308 - accuracy: 0.7381 - val_loss: 0.6527 - val_accuracy: 0.7399\n",
      "Epoch 23/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6340 - accuracy: 0.7375 - val_loss: 0.6440 - val_accuracy: 0.7417\n",
      "Epoch 24/24\n",
      "553/553 [==============================] - 2s 4ms/step - loss: 0.6479 - accuracy: 0.7299 - val_loss: 0.6476 - val_accuracy: 0.7424\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "\n",
    "# fit model\n",
    "history2 = estimator2.fit(edited_train.iloc[:,:40] , edited_train['Disorder Subclass'] , \n",
    "                        validation_split = 0.2, \n",
    "                        epochs=24, \n",
    "                        verbose=1, \n",
    "                        batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for 'Disorder Subclass':\n",
    "plt.plot(history2.history['accuracy'], label='train')\n",
    "plt.plot(history2.history['val_accuracy'], label='test')\n",
    "plt.legend(loc ='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(xlabel=\"epochs\")\n",
    "plt.ylabel(ylabel=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation : We see 80% train data gives accuracy 0.73 and 20% train data treated as valid data is giving 0.74 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So we see in both the phases there is no overfitting and model is responding nicely to the valid 20% of train data . We will use 'baseline_model' and 'baseline_model2' setup for deployment stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deployment :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 : 'Genetic Disorder' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Network :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"344pt\" height=\"876pt\" viewBox=\"0.00 0.00 413.00 1051.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.833333 0.833333) rotate(0) translate(4 1047)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1047 409,-1047 409,4 -4,4\"/>\n",
       "<!-- 1757502699024 -->\n",
       "<g id=\"node1\" class=\"node\"><title>1757502699024</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48,-996.5 48,-1042.5 357,-1042.5 357,-996.5 48,-996.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"131.5\" y=\"-1015.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">flatten_7_input: InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"215,-996.5 215,-1042.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"215,-1019.5 271,-1019.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"271,-996.5 271,-1042.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"314\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 39)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"271,-1019.5 357,-1019.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"314\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 39)]</text>\n",
       "</g>\n",
       "<!-- 1757502626016 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1757502626016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81.5,-913.5 81.5,-959.5 323.5,-959.5 323.5,-913.5 81.5,-913.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-932.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">flatten_7: Flatten</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"190.5,-913.5 190.5,-959.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"190.5,-936.5 246.5,-936.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"218.5\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"246.5,-913.5 246.5,-959.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 39)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"246.5,-936.5 323.5,-936.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 39)</text>\n",
       "</g>\n",
       "<!-- 1757502699024&#45;&gt;1757502626016 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>1757502699024-&gt;1757502626016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-996.366C202.5,-988.152 202.5,-978.658 202.5,-969.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-969.607 202.5,-959.607 199,-969.607 206,-969.607\"/>\n",
       "</g>\n",
       "<!-- 1757487667952 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1757487667952</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-830.5 3,-876.5 402,-876.5 402,-830.5 3,-830.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-849.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_28: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-830.5 269,-876.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-853.5 325,-853.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-830.5 325,-876.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 39)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-853.5 402,-853.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 39)</text>\n",
       "</g>\n",
       "<!-- 1757502626016&#45;&gt;1757487667952 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1757502626016-&gt;1757487667952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-913.366C202.5,-905.152 202.5,-895.658 202.5,-886.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-886.607 202.5,-876.607 199,-886.607 206,-886.607\"/>\n",
       "</g>\n",
       "<!-- 1757502420496 -->\n",
       "<g id=\"node4\" class=\"node\"><title>1757502420496</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-747.5 77.5,-793.5 327.5,-793.5 327.5,-747.5 77.5,-747.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-766.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_28: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-747.5 188.5,-793.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-770.5 244.5,-770.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-747.5 244.5,-793.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 39)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-770.5 327.5,-770.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1757487667952&#45;&gt;1757502420496 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1757487667952-&gt;1757502420496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-830.366C202.5,-822.152 202.5,-812.658 202.5,-803.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-803.607 202.5,-793.607 199,-803.607 206,-803.607\"/>\n",
       "</g>\n",
       "<!-- 1757502692320 -->\n",
       "<g id=\"node5\" class=\"node\"><title>1757502692320</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-664.5 0,-710.5 405,-710.5 405,-664.5 0,-664.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-683.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_29: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266,-664.5 266,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266,-687.5 322,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"322,-664.5 322,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"322,-687.5 405,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1757502420496&#45;&gt;1757502692320 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1757502420496-&gt;1757502692320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-747.366C202.5,-739.152 202.5,-729.658 202.5,-720.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-720.607 202.5,-710.607 199,-720.607 206,-720.607\"/>\n",
       "</g>\n",
       "<!-- 1757502626592 -->\n",
       "<g id=\"node6\" class=\"node\"><title>1757502626592</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"30,-581.5 30,-627.5 375,-627.5 375,-581.5 30,-581.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-600.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_21: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-581.5 236,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-604.5 292,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"292,-581.5 292,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"292,-604.5 375,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1757502692320&#45;&gt;1757502626592 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>1757502692320-&gt;1757502626592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-664.366C202.5,-656.152 202.5,-646.658 202.5,-637.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-637.607 202.5,-627.607 199,-637.607 206,-637.607\"/>\n",
       "</g>\n",
       "<!-- 1757469334304 -->\n",
       "<g id=\"node7\" class=\"node\"><title>1757469334304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-498.5 77.5,-544.5 327.5,-544.5 327.5,-498.5 77.5,-498.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-517.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_29: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-498.5 188.5,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-521.5 244.5,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-498.5 244.5,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-521.5 327.5,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757502626592&#45;&gt;1757469334304 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>1757502626592-&gt;1757469334304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-581.366C202.5,-573.152 202.5,-563.658 202.5,-554.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-554.607 202.5,-544.607 199,-554.607 206,-554.607\"/>\n",
       "</g>\n",
       "<!-- 1757502457456 -->\n",
       "<g id=\"node8\" class=\"node\"><title>1757502457456</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-415.5 3,-461.5 402,-461.5 402,-415.5 3,-415.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-434.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_30: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-415.5 269,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-438.5 325,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-415.5 325,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-438.5 402,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757469334304&#45;&gt;1757502457456 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>1757469334304-&gt;1757502457456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-498.366C202.5,-490.152 202.5,-480.658 202.5,-471.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-471.607 202.5,-461.607 199,-471.607 206,-471.607\"/>\n",
       "</g>\n",
       "<!-- 1757502421264 -->\n",
       "<g id=\"node9\" class=\"node\"><title>1757502421264</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-332.5 33,-378.5 372,-378.5 372,-332.5 33,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-351.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_22: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-332.5 239,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-355.5 295,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-332.5 295,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-355.5 372,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757502457456&#45;&gt;1757502421264 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>1757502457456-&gt;1757502421264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-415.366C202.5,-407.152 202.5,-397.658 202.5,-388.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-388.607 202.5,-378.607 199,-388.607 206,-388.607\"/>\n",
       "</g>\n",
       "<!-- 1757476784064 -->\n",
       "<g id=\"node10\" class=\"node\"><title>1757476784064</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80.5,-249.5 80.5,-295.5 324.5,-295.5 324.5,-249.5 80.5,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-268.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_30: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-249.5 191.5,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-272.5 247.5,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-249.5 247.5,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-272.5 324.5,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757502421264&#45;&gt;1757476784064 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>1757502421264-&gt;1757476784064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-332.366C202.5,-324.152 202.5,-314.658 202.5,-305.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-305.607 202.5,-295.607 199,-305.607 206,-305.607\"/>\n",
       "</g>\n",
       "<!-- 1757476684704 -->\n",
       "<g id=\"node11\" class=\"node\"><title>1757476684704</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-166.5 3,-212.5 402,-212.5 402,-166.5 3,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-185.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_31: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-166.5 269,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-189.5 325,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-166.5 325,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-189.5 402,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757476784064&#45;&gt;1757476684704 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>1757476784064-&gt;1757476684704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-249.366C202.5,-241.152 202.5,-231.658 202.5,-222.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-222.607 202.5,-212.607 199,-222.607 206,-222.607\"/>\n",
       "</g>\n",
       "<!-- 1757488361728 -->\n",
       "<g id=\"node12\" class=\"node\"><title>1757488361728</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-83.5 33,-129.5 372,-129.5 372,-83.5 33,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-102.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_23: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-83.5 239,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-106.5 295,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-83.5 295,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-106.5 372,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757476684704&#45;&gt;1757488361728 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>1757476684704-&gt;1757488361728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-166.366C202.5,-158.152 202.5,-148.658 202.5,-139.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-139.607 202.5,-129.607 199,-139.607 206,-139.607\"/>\n",
       "</g>\n",
       "<!-- 1757502356352 -->\n",
       "<g id=\"node13\" class=\"node\"><title>1757502356352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80.5,-0.5 80.5,-46.5 324.5,-46.5 324.5,-0.5 80.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-19.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_31: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-0.5 191.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-23.5 247.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-0.5 247.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-23.5 324.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 1757488361728&#45;&gt;1757502356352 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>1757488361728-&gt;1757502356352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-83.3664C202.5,-75.1516 202.5,-65.6579 202.5,-56.7252\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-56.6068 202.5,-46.6068 199,-56.6069 206,-56.6068\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(baseline_model(), show_shapes=True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the estimator with the full data :\n",
    "\n",
    "final_estimator = KerasClassifier(build_fn=baseline_model,  verbose = 1 , shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Disorder Prediction utilizing full train data for the test data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22083, 41)\n",
      "(4417, 41)\n"
     ]
    }
   ],
   "source": [
    "valid_data = edited_train.sample(frac=0.2, random_state=42 )         \n",
    "print(edited_train.shape)\n",
    "print(valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "691/691 [==============================] - 6s 5ms/step - loss: 1.0167 - accuracy: 0.4965 - val_loss: 0.7707 - val_accuracy: 0.6586\n",
      "Epoch 2/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7777 - accuracy: 0.6357 - val_loss: 0.7417 - val_accuracy: 0.6697\n",
      "Epoch 3/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7642 - accuracy: 0.6440 - val_loss: 0.7274 - val_accuracy: 0.6719\n",
      "Epoch 4/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7543 - accuracy: 0.6493 - val_loss: 0.7330 - val_accuracy: 0.6710\n",
      "Epoch 5/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7578 - accuracy: 0.6484 - val_loss: 0.7069 - val_accuracy: 0.6801\n",
      "Epoch 6/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7416 - accuracy: 0.6533 - val_loss: 0.7019 - val_accuracy: 0.6790\n",
      "Epoch 7/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7320 - accuracy: 0.6642 - val_loss: 0.7049 - val_accuracy: 0.6781\n",
      "Epoch 8/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7321 - accuracy: 0.6557 - val_loss: 0.7097 - val_accuracy: 0.6803\n",
      "Epoch 9/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.7345 - accuracy: 0.6617 - val_loss: 0.6959 - val_accuracy: 0.6830\n",
      "Epoch 10/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7302 - accuracy: 0.6565 - val_loss: 0.6980 - val_accuracy: 0.6808\n",
      "Epoch 11/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7268 - accuracy: 0.6638 - val_loss: 0.6977 - val_accuracy: 0.6806\n",
      "Epoch 12/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.7151 - accuracy: 0.6669 - val_loss: 0.6941 - val_accuracy: 0.6973\n",
      "Epoch 13/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7246 - accuracy: 0.6673 - val_loss: 0.7026 - val_accuracy: 0.6862\n",
      "Epoch 14/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7215 - accuracy: 0.6626 - val_loss: 0.6945 - val_accuracy: 0.6867\n",
      "Epoch 15/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.7158 - accuracy: 0.6665 - val_loss: 0.6867 - val_accuracy: 0.6880\n",
      "Epoch 16/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7096 - accuracy: 0.6696 - val_loss: 0.6969 - val_accuracy: 0.6778\n",
      "Epoch 17/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7225 - accuracy: 0.6662 - val_loss: 0.6841 - val_accuracy: 0.6914\n",
      "Epoch 18/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7087 - accuracy: 0.6693 - val_loss: 0.6959 - val_accuracy: 0.6853\n",
      "Epoch 19/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7088 - accuracy: 0.6695 - val_loss: 0.6901 - val_accuracy: 0.6880\n",
      "Epoch 20/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7071 - accuracy: 0.6730 - val_loss: 0.6797 - val_accuracy: 0.6957\n",
      "Epoch 21/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7007 - accuracy: 0.6773 - val_loss: 0.6805 - val_accuracy: 0.6939\n",
      "Epoch 22/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.7046 - accuracy: 0.6723 - val_loss: 0.6790 - val_accuracy: 0.6898\n",
      "Epoch 23/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7025 - accuracy: 0.6732 - val_loss: 0.6770 - val_accuracy: 0.6962\n",
      "Epoch 24/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7010 - accuracy: 0.6754 - val_loss: 0.7011 - val_accuracy: 0.6821\n",
      "Epoch 25/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6924 - accuracy: 0.6797 - val_loss: 0.6722 - val_accuracy: 0.6989\n",
      "Epoch 26/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6944 - accuracy: 0.6741 - val_loss: 0.6840 - val_accuracy: 0.6926\n",
      "Epoch 27/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6948 - accuracy: 0.6784 - val_loss: 0.6739 - val_accuracy: 0.6928\n",
      "Epoch 28/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6949 - accuracy: 0.6785 - val_loss: 0.6763 - val_accuracy: 0.6941\n",
      "Epoch 29/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6889 - accuracy: 0.6823 - val_loss: 0.6900 - val_accuracy: 0.6855\n",
      "Epoch 30/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6929 - accuracy: 0.6808 - val_loss: 0.6647 - val_accuracy: 0.6989\n",
      "Epoch 31/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7048 - accuracy: 0.6786 - val_loss: 0.6687 - val_accuracy: 0.7012\n",
      "Epoch 32/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6803 - accuracy: 0.6843 - val_loss: 0.6719 - val_accuracy: 0.6980\n",
      "Epoch 33/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6906 - accuracy: 0.6851 - val_loss: 0.6788 - val_accuracy: 0.7007\n",
      "Epoch 34/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6827 - accuracy: 0.6859 - val_loss: 0.6580 - val_accuracy: 0.7059\n",
      "Epoch 35/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6815 - accuracy: 0.6875 - val_loss: 0.6599 - val_accuracy: 0.7055\n",
      "Epoch 36/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6807 - accuracy: 0.6844 - val_loss: 0.6614 - val_accuracy: 0.7059\n",
      "Epoch 37/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6767 - accuracy: 0.6919 - val_loss: 0.6618 - val_accuracy: 0.6996\n",
      "Epoch 38/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6751 - accuracy: 0.6912 - val_loss: 0.6518 - val_accuracy: 0.7132\n",
      "Epoch 39/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6765 - accuracy: 0.6898 - val_loss: 0.6636 - val_accuracy: 0.6955\n",
      "Epoch 40/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6833 - accuracy: 0.6886 - val_loss: 0.6598 - val_accuracy: 0.7068\n",
      "Epoch 41/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6666 - accuracy: 0.6925 - val_loss: 0.6607 - val_accuracy: 0.7018\n",
      "Epoch 42/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6757 - accuracy: 0.6900 - val_loss: 0.6616 - val_accuracy: 0.7034\n",
      "Epoch 43/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6601 - accuracy: 0.6960 - val_loss: 0.6455 - val_accuracy: 0.7122\n",
      "Epoch 44/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6642 - accuracy: 0.6936 - val_loss: 0.6442 - val_accuracy: 0.7122\n",
      "Epoch 45/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6716 - accuracy: 0.6928 - val_loss: 0.6389 - val_accuracy: 0.7147\n",
      "Epoch 46/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6715 - accuracy: 0.6927 - val_loss: 0.6522 - val_accuracy: 0.7034\n",
      "Epoch 47/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6697 - accuracy: 0.6948 - val_loss: 0.6366 - val_accuracy: 0.7165\n",
      "Epoch 48/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6636 - accuracy: 0.6935 - val_loss: 0.6410 - val_accuracy: 0.7068\n",
      "Epoch 49/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6714 - accuracy: 0.6955 - val_loss: 0.6405 - val_accuracy: 0.7118\n",
      "Epoch 50/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6776 - accuracy: 0.6908 - val_loss: 0.6494 - val_accuracy: 0.7107\n",
      "Epoch 51/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6636 - accuracy: 0.6990 - val_loss: 0.6423 - val_accuracy: 0.7170\n",
      "Epoch 52/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6590 - accuracy: 0.7012 - val_loss: 0.6410 - val_accuracy: 0.7120\n",
      "Epoch 53/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6547 - accuracy: 0.6999 - val_loss: 0.6464 - val_accuracy: 0.7152\n",
      "Epoch 54/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6612 - accuracy: 0.6964 - val_loss: 0.6456 - val_accuracy: 0.7145\n",
      "Epoch 55/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6606 - accuracy: 0.6933 - val_loss: 0.6508 - val_accuracy: 0.7109\n",
      "Epoch 56/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6568 - accuracy: 0.6999 - val_loss: 0.6476 - val_accuracy: 0.7113\n",
      "Epoch 57/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6497 - accuracy: 0.6999 - val_loss: 0.6441 - val_accuracy: 0.7093\n",
      "Epoch 58/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6549 - accuracy: 0.7047 - val_loss: 0.6387 - val_accuracy: 0.7152\n",
      "Epoch 59/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6499 - accuracy: 0.6950 - val_loss: 0.6315 - val_accuracy: 0.7168\n",
      "Epoch 60/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6516 - accuracy: 0.7034 - val_loss: 0.6302 - val_accuracy: 0.7193\n",
      "Epoch 61/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6454 - accuracy: 0.7069 - val_loss: 0.6321 - val_accuracy: 0.7143\n",
      "Epoch 62/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6590 - accuracy: 0.6994 - val_loss: 0.6366 - val_accuracy: 0.7186\n",
      "Epoch 63/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6511 - accuracy: 0.7020 - val_loss: 0.6345 - val_accuracy: 0.7163\n",
      "Epoch 64/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6422 - accuracy: 0.7106 - val_loss: 0.6251 - val_accuracy: 0.7184\n",
      "Epoch 65/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6426 - accuracy: 0.7059 - val_loss: 0.6395 - val_accuracy: 0.7109\n",
      "Epoch 66/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6479 - accuracy: 0.7008 - val_loss: 0.6318 - val_accuracy: 0.7270\n",
      "Epoch 67/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6426 - accuracy: 0.7057 - val_loss: 0.6284 - val_accuracy: 0.7258\n",
      "Epoch 68/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6408 - accuracy: 0.7074 - val_loss: 0.6214 - val_accuracy: 0.7272\n",
      "Epoch 69/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6386 - accuracy: 0.7098 - val_loss: 0.6276 - val_accuracy: 0.7247\n",
      "Epoch 70/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6399 - accuracy: 0.7071 - val_loss: 0.6356 - val_accuracy: 0.7195\n",
      "Epoch 71/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6384 - accuracy: 0.7115 - val_loss: 0.6328 - val_accuracy: 0.7181\n",
      "Epoch 72/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6332 - accuracy: 0.7132 - val_loss: 0.6281 - val_accuracy: 0.7165\n",
      "Epoch 73/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6428 - accuracy: 0.7115 - val_loss: 0.6258 - val_accuracy: 0.7224\n",
      "Epoch 74/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6358 - accuracy: 0.7119 - val_loss: 0.6274 - val_accuracy: 0.7297\n",
      "Epoch 75/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6339 - accuracy: 0.7158 - val_loss: 0.6264 - val_accuracy: 0.7301\n",
      "Epoch 76/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6300 - accuracy: 0.7152 - val_loss: 0.6233 - val_accuracy: 0.7252\n",
      "Epoch 77/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6376 - accuracy: 0.7108 - val_loss: 0.6247 - val_accuracy: 0.7240\n",
      "Epoch 78/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6332 - accuracy: 0.7129 - val_loss: 0.6163 - val_accuracy: 0.7265\n",
      "Epoch 79/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6322 - accuracy: 0.7163 - val_loss: 0.6098 - val_accuracy: 0.7281\n",
      "Epoch 80/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6269 - accuracy: 0.7166 - val_loss: 0.6282 - val_accuracy: 0.7215\n",
      "Epoch 81/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6233 - accuracy: 0.7165 - val_loss: 0.6288 - val_accuracy: 0.7199\n",
      "Epoch 82/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6261 - accuracy: 0.7114 - val_loss: 0.6151 - val_accuracy: 0.7261\n",
      "Epoch 83/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6382 - accuracy: 0.7093 - val_loss: 0.6054 - val_accuracy: 0.7340\n",
      "Epoch 84/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6303 - accuracy: 0.7119 - val_loss: 0.6150 - val_accuracy: 0.7315\n",
      "Epoch 85/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6262 - accuracy: 0.7157 - val_loss: 0.6174 - val_accuracy: 0.7317\n",
      "Epoch 86/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6228 - accuracy: 0.7179 - val_loss: 0.6224 - val_accuracy: 0.7238\n",
      "Epoch 87/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6198 - accuracy: 0.7218 - val_loss: 0.6145 - val_accuracy: 0.7315\n",
      "Epoch 88/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6248 - accuracy: 0.7176 - val_loss: 0.6064 - val_accuracy: 0.7338\n",
      "Epoch 89/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6169 - accuracy: 0.7227 - val_loss: 0.6094 - val_accuracy: 0.7301\n",
      "Epoch 90/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6191 - accuracy: 0.7209 - val_loss: 0.6231 - val_accuracy: 0.7333\n",
      "Epoch 91/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6156 - accuracy: 0.7202 - val_loss: 0.5918 - val_accuracy: 0.7405\n",
      "Epoch 92/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6120 - accuracy: 0.7229 - val_loss: 0.6090 - val_accuracy: 0.7390\n",
      "Epoch 93/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6144 - accuracy: 0.7278 - val_loss: 0.6078 - val_accuracy: 0.7333\n",
      "Epoch 94/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6150 - accuracy: 0.7243 - val_loss: 0.5956 - val_accuracy: 0.7455\n",
      "Epoch 95/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6179 - accuracy: 0.7191 - val_loss: 0.6022 - val_accuracy: 0.7408\n",
      "Epoch 96/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6150 - accuracy: 0.7211 - val_loss: 0.6039 - val_accuracy: 0.7360\n",
      "Epoch 97/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6180 - accuracy: 0.7152 - val_loss: 0.6059 - val_accuracy: 0.7378\n",
      "Epoch 98/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6116 - accuracy: 0.7198 - val_loss: 0.6115 - val_accuracy: 0.7403\n",
      "Epoch 99/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5977 - accuracy: 0.7324 - val_loss: 0.6031 - val_accuracy: 0.7353\n",
      "Epoch 100/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6038 - accuracy: 0.7293 - val_loss: 0.5956 - val_accuracy: 0.7417\n",
      "Epoch 101/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6179 - accuracy: 0.7176 - val_loss: 0.5974 - val_accuracy: 0.7448\n",
      "Epoch 102/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6038 - accuracy: 0.7276 - val_loss: 0.6060 - val_accuracy: 0.7401\n",
      "Epoch 103/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6039 - accuracy: 0.7306 - val_loss: 0.5995 - val_accuracy: 0.7392\n",
      "Epoch 104/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6150 - accuracy: 0.7193 - val_loss: 0.5939 - val_accuracy: 0.7455\n",
      "Epoch 105/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.6068 - accuracy: 0.7265 - val_loss: 0.5982 - val_accuracy: 0.7412\n",
      "Epoch 106/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5971 - accuracy: 0.7277 - val_loss: 0.5967 - val_accuracy: 0.7462\n",
      "Epoch 107/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6029 - accuracy: 0.7306 - val_loss: 0.5993 - val_accuracy: 0.7415\n",
      "Epoch 108/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5944 - accuracy: 0.7363 - val_loss: 0.6153 - val_accuracy: 0.7329\n",
      "Epoch 109/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5967 - accuracy: 0.7278 - val_loss: 0.6007 - val_accuracy: 0.7387\n",
      "Epoch 110/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6040 - accuracy: 0.7289 - val_loss: 0.5928 - val_accuracy: 0.7435\n",
      "Epoch 111/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6039 - accuracy: 0.7279 - val_loss: 0.5849 - val_accuracy: 0.7510\n",
      "Epoch 112/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5915 - accuracy: 0.7339 - val_loss: 0.6091 - val_accuracy: 0.7349\n",
      "Epoch 113/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6020 - accuracy: 0.7277 - val_loss: 0.5822 - val_accuracy: 0.7399\n",
      "Epoch 114/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5911 - accuracy: 0.7384 - val_loss: 0.5869 - val_accuracy: 0.7437\n",
      "Epoch 115/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5908 - accuracy: 0.7329 - val_loss: 0.5787 - val_accuracy: 0.7496\n",
      "Epoch 116/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5911 - accuracy: 0.7350 - val_loss: 0.5800 - val_accuracy: 0.7528\n",
      "Epoch 117/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5902 - accuracy: 0.7328 - val_loss: 0.5881 - val_accuracy: 0.7458\n",
      "Epoch 118/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5920 - accuracy: 0.7364 - val_loss: 0.5833 - val_accuracy: 0.7548\n",
      "Epoch 119/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5806 - accuracy: 0.7449 - val_loss: 0.5800 - val_accuracy: 0.7541\n",
      "Epoch 120/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5938 - accuracy: 0.7340 - val_loss: 0.5811 - val_accuracy: 0.7485\n",
      "Epoch 121/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5911 - accuracy: 0.7392 - val_loss: 0.5778 - val_accuracy: 0.7512\n",
      "Epoch 122/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5794 - accuracy: 0.7384 - val_loss: 0.5933 - val_accuracy: 0.7439\n",
      "Epoch 123/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5858 - accuracy: 0.7401 - val_loss: 0.5778 - val_accuracy: 0.7498\n",
      "Epoch 124/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5910 - accuracy: 0.7360 - val_loss: 0.5701 - val_accuracy: 0.7584\n",
      "Epoch 125/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5805 - accuracy: 0.7442 - val_loss: 0.5838 - val_accuracy: 0.7476\n",
      "Epoch 126/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5801 - accuracy: 0.7430 - val_loss: 0.5759 - val_accuracy: 0.7496\n",
      "Epoch 127/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5767 - accuracy: 0.7443 - val_loss: 0.5731 - val_accuracy: 0.7568\n",
      "Epoch 128/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5930 - accuracy: 0.7348 - val_loss: 0.5775 - val_accuracy: 0.7544\n",
      "Epoch 129/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7326 - val_loss: 0.5767 - val_accuracy: 0.7494\n",
      "Epoch 130/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5791 - accuracy: 0.7441 - val_loss: 0.5691 - val_accuracy: 0.7616\n",
      "Epoch 131/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5774 - accuracy: 0.7460 - val_loss: 0.5736 - val_accuracy: 0.7505\n",
      "Epoch 132/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5782 - accuracy: 0.7397 - val_loss: 0.5689 - val_accuracy: 0.7562\n",
      "Epoch 133/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5893 - accuracy: 0.7346 - val_loss: 0.5644 - val_accuracy: 0.7580\n",
      "Epoch 134/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5799 - accuracy: 0.7398 - val_loss: 0.5617 - val_accuracy: 0.7587\n",
      "Epoch 135/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5822 - accuracy: 0.7419 - val_loss: 0.5988 - val_accuracy: 0.7383\n",
      "Epoch 136/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5925 - accuracy: 0.7342 - val_loss: 0.5542 - val_accuracy: 0.7621\n",
      "Epoch 137/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5831 - accuracy: 0.7419 - val_loss: 0.5687 - val_accuracy: 0.7566\n",
      "Epoch 138/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5914 - accuracy: 0.7334 - val_loss: 0.5697 - val_accuracy: 0.7598\n",
      "Epoch 139/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5749 - accuracy: 0.7433 - val_loss: 0.5594 - val_accuracy: 0.7625\n",
      "Epoch 140/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5841 - accuracy: 0.7390 - val_loss: 0.5590 - val_accuracy: 0.7630\n",
      "Epoch 141/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5690 - accuracy: 0.7446 - val_loss: 0.5627 - val_accuracy: 0.7607\n",
      "Epoch 142/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5788 - accuracy: 0.7431 - val_loss: 0.5588 - val_accuracy: 0.7650\n",
      "Epoch 143/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5651 - accuracy: 0.7472 - val_loss: 0.5780 - val_accuracy: 0.7501\n",
      "Epoch 144/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5746 - accuracy: 0.7430 - val_loss: 0.5861 - val_accuracy: 0.7473\n",
      "Epoch 145/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5748 - accuracy: 0.7442 - val_loss: 0.5492 - val_accuracy: 0.7688\n",
      "Epoch 146/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5730 - accuracy: 0.7529 - val_loss: 0.5633 - val_accuracy: 0.7636\n",
      "Epoch 147/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5766 - accuracy: 0.7464 - val_loss: 0.5706 - val_accuracy: 0.7575\n",
      "Epoch 148/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5798 - accuracy: 0.7488 - val_loss: 0.5735 - val_accuracy: 0.7589\n",
      "Epoch 149/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5785 - accuracy: 0.7440 - val_loss: 0.5491 - val_accuracy: 0.7636\n",
      "Epoch 150/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5552 - accuracy: 0.7579 - val_loss: 0.5733 - val_accuracy: 0.7555\n",
      "Epoch 151/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5672 - accuracy: 0.7518 - val_loss: 0.5463 - val_accuracy: 0.7707\n",
      "Epoch 152/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5722 - accuracy: 0.7455 - val_loss: 0.5509 - val_accuracy: 0.7700\n",
      "Epoch 153/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5726 - accuracy: 0.7424 - val_loss: 0.5829 - val_accuracy: 0.7523\n",
      "Epoch 154/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5696 - accuracy: 0.7483 - val_loss: 0.5664 - val_accuracy: 0.7564\n",
      "Epoch 155/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5678 - accuracy: 0.7484 - val_loss: 0.5629 - val_accuracy: 0.7575\n",
      "Epoch 156/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5678 - accuracy: 0.7488 - val_loss: 0.5644 - val_accuracy: 0.7627\n",
      "Epoch 157/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5635 - accuracy: 0.7524 - val_loss: 0.5485 - val_accuracy: 0.7670\n",
      "Epoch 158/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5677 - accuracy: 0.7480 - val_loss: 0.5578 - val_accuracy: 0.7670\n",
      "Epoch 159/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5540 - accuracy: 0.7516 - val_loss: 0.5486 - val_accuracy: 0.7679\n",
      "Epoch 160/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5741 - accuracy: 0.7428 - val_loss: 0.5417 - val_accuracy: 0.7722\n",
      "Epoch 161/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5576 - accuracy: 0.7494 - val_loss: 0.5586 - val_accuracy: 0.7612\n",
      "Epoch 162/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5727 - accuracy: 0.7452 - val_loss: 0.5448 - val_accuracy: 0.7709\n",
      "Epoch 163/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5615 - accuracy: 0.7483 - val_loss: 0.5646 - val_accuracy: 0.7605\n",
      "Epoch 164/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5570 - accuracy: 0.7510 - val_loss: 0.5582 - val_accuracy: 0.7684\n",
      "Epoch 165/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5632 - accuracy: 0.7530 - val_loss: 0.5520 - val_accuracy: 0.7650\n",
      "Epoch 166/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5652 - accuracy: 0.7499 - val_loss: 0.5703 - val_accuracy: 0.7584\n",
      "Epoch 167/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5679 - accuracy: 0.7494 - val_loss: 0.5529 - val_accuracy: 0.7729\n",
      "Epoch 168/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5532 - accuracy: 0.7552 - val_loss: 0.5677 - val_accuracy: 0.7557\n",
      "Epoch 169/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5468 - accuracy: 0.7630 - val_loss: 0.5422 - val_accuracy: 0.7700\n",
      "Epoch 170/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5571 - accuracy: 0.7558 - val_loss: 0.5472 - val_accuracy: 0.7734\n",
      "Epoch 171/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5504 - accuracy: 0.7564 - val_loss: 0.5461 - val_accuracy: 0.7722\n",
      "Epoch 172/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5716 - accuracy: 0.7462 - val_loss: 0.5430 - val_accuracy: 0.7731\n",
      "Epoch 173/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5498 - accuracy: 0.7569 - val_loss: 0.5230 - val_accuracy: 0.7788\n",
      "Epoch 174/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5452 - accuracy: 0.7623 - val_loss: 0.5438 - val_accuracy: 0.7765\n",
      "Epoch 175/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5559 - accuracy: 0.7547 - val_loss: 0.5378 - val_accuracy: 0.7741\n",
      "Epoch 176/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5510 - accuracy: 0.7582 - val_loss: 0.5366 - val_accuracy: 0.7797\n",
      "Epoch 177/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5508 - accuracy: 0.7583 - val_loss: 0.5492 - val_accuracy: 0.7700\n",
      "Epoch 178/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5542 - accuracy: 0.7577 - val_loss: 0.5532 - val_accuracy: 0.7659\n",
      "Epoch 179/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.7568 - val_loss: 0.5281 - val_accuracy: 0.7741\n",
      "Epoch 180/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5515 - accuracy: 0.7545 - val_loss: 0.5405 - val_accuracy: 0.7673\n",
      "Epoch 181/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5532 - accuracy: 0.7527 - val_loss: 0.5698 - val_accuracy: 0.7578\n",
      "Epoch 182/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5580 - accuracy: 0.7547 - val_loss: 0.5357 - val_accuracy: 0.7752\n",
      "Epoch 183/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5471 - accuracy: 0.7661 - val_loss: 0.5473 - val_accuracy: 0.7736\n",
      "Epoch 184/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5515 - accuracy: 0.7605 - val_loss: 0.5262 - val_accuracy: 0.7775\n",
      "Epoch 185/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5541 - accuracy: 0.7560 - val_loss: 0.5238 - val_accuracy: 0.7874\n",
      "Epoch 186/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5579 - accuracy: 0.7564 - val_loss: 0.5414 - val_accuracy: 0.7759\n",
      "Epoch 187/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5552 - accuracy: 0.7566 - val_loss: 0.5330 - val_accuracy: 0.7754\n",
      "Epoch 188/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5515 - accuracy: 0.7581 - val_loss: 0.5331 - val_accuracy: 0.7759\n",
      "Epoch 189/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5434 - accuracy: 0.7584 - val_loss: 0.5285 - val_accuracy: 0.7795\n",
      "Epoch 190/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5422 - accuracy: 0.7593 - val_loss: 0.5216 - val_accuracy: 0.7818\n",
      "Epoch 191/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5442 - accuracy: 0.7611 - val_loss: 0.5608 - val_accuracy: 0.7607\n",
      "Epoch 192/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5330 - accuracy: 0.7648 - val_loss: 0.5444 - val_accuracy: 0.7702\n",
      "Epoch 193/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7608 - val_loss: 0.5267 - val_accuracy: 0.7729\n",
      "Epoch 194/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5481 - accuracy: 0.7573 - val_loss: 0.5241 - val_accuracy: 0.7795\n",
      "Epoch 195/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.5370 - accuracy: 0.7633 - val_loss: 0.5126 - val_accuracy: 0.7858\n",
      "Epoch 196/1500\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 0.5439 - accuracy: 0.7648 - val_loss: 0.5012 - val_accuracy: 0.7849\n",
      "Epoch 197/1500\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 0.5472 - accuracy: 0.7593 - val_loss: 0.5319 - val_accuracy: 0.7775\n",
      "Epoch 198/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.5424 - accuracy: 0.7640 - val_loss: 0.5329 - val_accuracy: 0.7759\n",
      "Epoch 199/1500\n",
      "691/691 [==============================] - 4s 7ms/step - loss: 0.5467 - accuracy: 0.7597 - val_loss: 0.5274 - val_accuracy: 0.7741\n",
      "Epoch 200/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5432 - accuracy: 0.7599 - val_loss: 0.5183 - val_accuracy: 0.7897\n",
      "Epoch 201/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7635 - val_loss: 0.5489 - val_accuracy: 0.7641\n",
      "Epoch 202/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5454 - accuracy: 0.7571 - val_loss: 0.5406 - val_accuracy: 0.7722\n",
      "Epoch 203/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5338 - accuracy: 0.7634 - val_loss: 0.5385 - val_accuracy: 0.7747\n",
      "Epoch 204/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5440 - accuracy: 0.7611 - val_loss: 0.5367 - val_accuracy: 0.7799\n",
      "Epoch 205/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5354 - accuracy: 0.7641 - val_loss: 0.5469 - val_accuracy: 0.7797\n",
      "Epoch 206/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7617 - val_loss: 0.5284 - val_accuracy: 0.7824\n",
      "Epoch 207/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5507 - accuracy: 0.7552 - val_loss: 0.5452 - val_accuracy: 0.7734\n",
      "Epoch 208/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5412 - accuracy: 0.7588 - val_loss: 0.5194 - val_accuracy: 0.7838\n",
      "Epoch 209/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5292 - accuracy: 0.7677 - val_loss: 0.5319 - val_accuracy: 0.7795\n",
      "Epoch 210/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7633 - val_loss: 0.5396 - val_accuracy: 0.7743\n",
      "Epoch 211/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5415 - accuracy: 0.7588 - val_loss: 0.5235 - val_accuracy: 0.7806\n",
      "Epoch 212/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5274 - accuracy: 0.7736 - val_loss: 0.5139 - val_accuracy: 0.7833\n",
      "Epoch 213/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5281 - accuracy: 0.7748 - val_loss: 0.5263 - val_accuracy: 0.7820\n",
      "Epoch 214/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5269 - accuracy: 0.7709 - val_loss: 0.5277 - val_accuracy: 0.7829\n",
      "Epoch 215/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5443 - accuracy: 0.7610 - val_loss: 0.5100 - val_accuracy: 0.7913\n",
      "Epoch 216/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5303 - accuracy: 0.7730 - val_loss: 0.5086 - val_accuracy: 0.7802\n",
      "Epoch 217/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7641 - val_loss: 0.5231 - val_accuracy: 0.7842\n",
      "Epoch 218/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5260 - accuracy: 0.7720 - val_loss: 0.5487 - val_accuracy: 0.7698\n",
      "Epoch 219/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5344 - accuracy: 0.7577 - val_loss: 0.5133 - val_accuracy: 0.7894\n",
      "Epoch 220/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5269 - accuracy: 0.7684 - val_loss: 0.5326 - val_accuracy: 0.7827\n",
      "Epoch 221/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5425 - accuracy: 0.7566 - val_loss: 0.5207 - val_accuracy: 0.7863\n",
      "Epoch 222/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5345 - accuracy: 0.7642 - val_loss: 0.5195 - val_accuracy: 0.7827\n",
      "Epoch 223/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5289 - accuracy: 0.7697 - val_loss: 0.5165 - val_accuracy: 0.7870\n",
      "Epoch 224/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5278 - accuracy: 0.7714 - val_loss: 0.5070 - val_accuracy: 0.7944\n",
      "Epoch 225/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5252 - accuracy: 0.7722 - val_loss: 0.5023 - val_accuracy: 0.7960\n",
      "Epoch 226/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5321 - accuracy: 0.7637 - val_loss: 0.5079 - val_accuracy: 0.7890\n",
      "Epoch 227/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5294 - accuracy: 0.7670 - val_loss: 0.5125 - val_accuracy: 0.7890\n",
      "Epoch 228/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5326 - accuracy: 0.7679 - val_loss: 0.5282 - val_accuracy: 0.7827\n",
      "Epoch 229/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5244 - accuracy: 0.7740 - val_loss: 0.5133 - val_accuracy: 0.7949\n",
      "Epoch 230/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5217 - accuracy: 0.7706 - val_loss: 0.5217 - val_accuracy: 0.7797\n",
      "Epoch 231/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5289 - accuracy: 0.7653 - val_loss: 0.5033 - val_accuracy: 0.7953\n",
      "Epoch 232/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5228 - accuracy: 0.7699 - val_loss: 0.5175 - val_accuracy: 0.7849\n",
      "Epoch 233/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5400 - accuracy: 0.7622 - val_loss: 0.5160 - val_accuracy: 0.7838\n",
      "Epoch 234/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5253 - accuracy: 0.7685 - val_loss: 0.5040 - val_accuracy: 0.7962\n",
      "Epoch 235/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5296 - accuracy: 0.7632 - val_loss: 0.5004 - val_accuracy: 0.7894\n",
      "Epoch 236/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5334 - accuracy: 0.7610 - val_loss: 0.5033 - val_accuracy: 0.7913\n",
      "Epoch 237/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5270 - accuracy: 0.7655 - val_loss: 0.5109 - val_accuracy: 0.7897\n",
      "Epoch 238/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5390 - accuracy: 0.7596 - val_loss: 0.4981 - val_accuracy: 0.7962\n",
      "Epoch 239/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5262 - accuracy: 0.7692 - val_loss: 0.4959 - val_accuracy: 0.7965\n",
      "Epoch 240/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5191 - accuracy: 0.7763 - val_loss: 0.5012 - val_accuracy: 0.7942\n",
      "Epoch 241/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5133 - accuracy: 0.7765 - val_loss: 0.5025 - val_accuracy: 0.7915\n",
      "Epoch 242/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5260 - accuracy: 0.7696 - val_loss: 0.5016 - val_accuracy: 0.7940\n",
      "Epoch 243/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5083 - accuracy: 0.7806 - val_loss: 0.5227 - val_accuracy: 0.7770\n",
      "Epoch 244/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5261 - accuracy: 0.7686 - val_loss: 0.4963 - val_accuracy: 0.7974\n",
      "Epoch 245/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5144 - accuracy: 0.7762 - val_loss: 0.5024 - val_accuracy: 0.7919\n",
      "Epoch 246/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5165 - accuracy: 0.7759 - val_loss: 0.5092 - val_accuracy: 0.7978\n",
      "Epoch 247/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5232 - accuracy: 0.7687 - val_loss: 0.4943 - val_accuracy: 0.7958\n",
      "Epoch 248/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5142 - accuracy: 0.7770 - val_loss: 0.5156 - val_accuracy: 0.7894\n",
      "Epoch 249/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5185 - accuracy: 0.7735 - val_loss: 0.5075 - val_accuracy: 0.7910\n",
      "Epoch 250/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5222 - accuracy: 0.7717 - val_loss: 0.5223 - val_accuracy: 0.7890\n",
      "Epoch 251/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5194 - accuracy: 0.7731 - val_loss: 0.5192 - val_accuracy: 0.7854\n",
      "Epoch 252/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5034 - accuracy: 0.7817 - val_loss: 0.5069 - val_accuracy: 0.7883\n",
      "Epoch 253/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5272 - accuracy: 0.7706 - val_loss: 0.4950 - val_accuracy: 0.7962\n",
      "Epoch 254/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5277 - accuracy: 0.7707 - val_loss: 0.4987 - val_accuracy: 0.7974\n",
      "Epoch 255/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5130 - accuracy: 0.7765 - val_loss: 0.5002 - val_accuracy: 0.7960\n",
      "Epoch 256/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5223 - accuracy: 0.7697 - val_loss: 0.5149 - val_accuracy: 0.7967\n",
      "Epoch 257/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5303 - accuracy: 0.7662 - val_loss: 0.5102 - val_accuracy: 0.7913\n",
      "Epoch 258/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5237 - accuracy: 0.7731 - val_loss: 0.5510 - val_accuracy: 0.7673\n",
      "Epoch 259/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5234 - accuracy: 0.7671 - val_loss: 0.5181 - val_accuracy: 0.7829\n",
      "Epoch 260/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5119 - accuracy: 0.7769 - val_loss: 0.5038 - val_accuracy: 0.7915\n",
      "Epoch 261/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5259 - accuracy: 0.7685 - val_loss: 0.4936 - val_accuracy: 0.7996\n",
      "Epoch 262/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5177 - accuracy: 0.7728 - val_loss: 0.5038 - val_accuracy: 0.7931\n",
      "Epoch 263/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5062 - accuracy: 0.7816 - val_loss: 0.5060 - val_accuracy: 0.7947\n",
      "Epoch 264/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5126 - accuracy: 0.7772 - val_loss: 0.5019 - val_accuracy: 0.7958\n",
      "Epoch 265/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5207 - accuracy: 0.7735 - val_loss: 0.4753 - val_accuracy: 0.8067\n",
      "Epoch 266/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5166 - accuracy: 0.7732 - val_loss: 0.4878 - val_accuracy: 0.8021\n",
      "Epoch 267/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5116 - accuracy: 0.7743 - val_loss: 0.5109 - val_accuracy: 0.7953\n",
      "Epoch 268/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5152 - accuracy: 0.7736 - val_loss: 0.4973 - val_accuracy: 0.7910\n",
      "Epoch 269/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5226 - accuracy: 0.7687 - val_loss: 0.4913 - val_accuracy: 0.7983\n",
      "Epoch 270/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5217 - accuracy: 0.7693 - val_loss: 0.5165 - val_accuracy: 0.7987\n",
      "Epoch 271/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5189 - accuracy: 0.7751 - val_loss: 0.4873 - val_accuracy: 0.8051\n",
      "Epoch 272/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5097 - accuracy: 0.7784 - val_loss: 0.5112 - val_accuracy: 0.7874\n",
      "Epoch 273/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5113 - accuracy: 0.7770 - val_loss: 0.4877 - val_accuracy: 0.7981\n",
      "Epoch 274/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5092 - accuracy: 0.7806 - val_loss: 0.4821 - val_accuracy: 0.8060\n",
      "Epoch 275/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5049 - accuracy: 0.7810 - val_loss: 0.4880 - val_accuracy: 0.8053\n",
      "Epoch 276/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5119 - accuracy: 0.7797 - val_loss: 0.4820 - val_accuracy: 0.8024\n",
      "Epoch 277/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5067 - accuracy: 0.7783 - val_loss: 0.4962 - val_accuracy: 0.7935\n",
      "Epoch 278/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5072 - accuracy: 0.7835 - val_loss: 0.5116 - val_accuracy: 0.7935\n",
      "Epoch 279/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5174 - accuracy: 0.7750 - val_loss: 0.4971 - val_accuracy: 0.7915\n",
      "Epoch 280/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5035 - accuracy: 0.7824 - val_loss: 0.4746 - val_accuracy: 0.8089\n",
      "Epoch 281/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5004 - accuracy: 0.7828 - val_loss: 0.4876 - val_accuracy: 0.8008\n",
      "Epoch 282/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5081 - accuracy: 0.7756 - val_loss: 0.4968 - val_accuracy: 0.7999\n",
      "Epoch 283/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5077 - accuracy: 0.7809 - val_loss: 0.5136 - val_accuracy: 0.7885\n",
      "Epoch 284/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5085 - accuracy: 0.7778 - val_loss: 0.5015 - val_accuracy: 0.7944\n",
      "Epoch 285/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5096 - accuracy: 0.7795 - val_loss: 0.5009 - val_accuracy: 0.8003\n",
      "Epoch 286/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5152 - accuracy: 0.7759 - val_loss: 0.4842 - val_accuracy: 0.8014\n",
      "Epoch 287/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5074 - accuracy: 0.7760 - val_loss: 0.4777 - val_accuracy: 0.8116\n",
      "Epoch 288/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5008 - accuracy: 0.7834 - val_loss: 0.4830 - val_accuracy: 0.8046\n",
      "Epoch 289/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5036 - accuracy: 0.7821 - val_loss: 0.5186 - val_accuracy: 0.7876\n",
      "Epoch 290/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5046 - accuracy: 0.7788 - val_loss: 0.4832 - val_accuracy: 0.8103\n",
      "Epoch 291/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4949 - accuracy: 0.7856 - val_loss: 0.4895 - val_accuracy: 0.8014\n",
      "Epoch 292/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4987 - accuracy: 0.7853 - val_loss: 0.4855 - val_accuracy: 0.8030\n",
      "Epoch 293/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5062 - accuracy: 0.7791 - val_loss: 0.5095 - val_accuracy: 0.7978\n",
      "Epoch 294/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4970 - accuracy: 0.7837 - val_loss: 0.4801 - val_accuracy: 0.8051\n",
      "Epoch 295/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5327 - accuracy: 0.7664 - val_loss: 0.4786 - val_accuracy: 0.8017\n",
      "Epoch 296/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5044 - accuracy: 0.7740 - val_loss: 0.5113 - val_accuracy: 0.7858\n",
      "Epoch 297/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4952 - accuracy: 0.7859 - val_loss: 0.4880 - val_accuracy: 0.8062\n",
      "Epoch 298/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4985 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.8014\n",
      "Epoch 299/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5127 - accuracy: 0.7769 - val_loss: 0.4938 - val_accuracy: 0.7960\n",
      "Epoch 300/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4991 - accuracy: 0.7846 - val_loss: 0.4761 - val_accuracy: 0.8098\n",
      "Epoch 301/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5002 - accuracy: 0.7831 - val_loss: 0.4806 - val_accuracy: 0.8073\n",
      "Epoch 302/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4952 - accuracy: 0.7843 - val_loss: 0.5039 - val_accuracy: 0.8008\n",
      "Epoch 303/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4986 - accuracy: 0.7857 - val_loss: 0.4803 - val_accuracy: 0.8078\n",
      "Epoch 304/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4965 - accuracy: 0.7835 - val_loss: 0.4760 - val_accuracy: 0.8137\n",
      "Epoch 305/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4890 - accuracy: 0.7920 - val_loss: 0.4591 - val_accuracy: 0.8202\n",
      "Epoch 306/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4935 - accuracy: 0.7895 - val_loss: 0.4876 - val_accuracy: 0.8091\n",
      "Epoch 307/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4983 - accuracy: 0.7875 - val_loss: 0.4771 - val_accuracy: 0.8103\n",
      "Epoch 308/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5085 - accuracy: 0.7781 - val_loss: 0.4695 - val_accuracy: 0.8094\n",
      "Epoch 309/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5111 - accuracy: 0.7778 - val_loss: 0.4730 - val_accuracy: 0.8110\n",
      "Epoch 310/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4959 - accuracy: 0.7845 - val_loss: 0.4823 - val_accuracy: 0.8037\n",
      "Epoch 311/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5135 - accuracy: 0.7786 - val_loss: 0.4751 - val_accuracy: 0.8096\n",
      "Epoch 312/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4998 - accuracy: 0.7849 - val_loss: 0.4637 - val_accuracy: 0.8121\n",
      "Epoch 313/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4971 - accuracy: 0.7852 - val_loss: 0.4801 - val_accuracy: 0.8035\n",
      "Epoch 314/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5036 - accuracy: 0.7802 - val_loss: 0.4733 - val_accuracy: 0.8182\n",
      "Epoch 315/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5095 - accuracy: 0.7797 - val_loss: 0.4822 - val_accuracy: 0.8110\n",
      "Epoch 316/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4895 - accuracy: 0.7928 - val_loss: 0.4822 - val_accuracy: 0.8026\n",
      "Epoch 317/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5020 - accuracy: 0.7828 - val_loss: 0.4750 - val_accuracy: 0.8026\n",
      "Epoch 318/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4921 - accuracy: 0.7877 - val_loss: 0.4694 - val_accuracy: 0.8119\n",
      "Epoch 319/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4924 - accuracy: 0.7868 - val_loss: 0.4766 - val_accuracy: 0.8067\n",
      "Epoch 320/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5012 - accuracy: 0.7845 - val_loss: 0.4746 - val_accuracy: 0.8128\n",
      "Epoch 321/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5064 - accuracy: 0.7795 - val_loss: 0.4626 - val_accuracy: 0.8180\n",
      "Epoch 322/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5009 - accuracy: 0.7835 - val_loss: 0.4676 - val_accuracy: 0.8146\n",
      "Epoch 323/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4946 - accuracy: 0.7851 - val_loss: 0.4608 - val_accuracy: 0.8130\n",
      "Epoch 324/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.4876 - val_accuracy: 0.8058\n",
      "Epoch 325/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5022 - accuracy: 0.7789 - val_loss: 0.4705 - val_accuracy: 0.8082\n",
      "Epoch 326/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5059 - accuracy: 0.7805 - val_loss: 0.4830 - val_accuracy: 0.8055\n",
      "Epoch 327/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4946 - accuracy: 0.7819 - val_loss: 0.4843 - val_accuracy: 0.8144\n",
      "Epoch 328/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4940 - accuracy: 0.7826 - val_loss: 0.4534 - val_accuracy: 0.8202\n",
      "Epoch 329/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4987 - accuracy: 0.7851 - val_loss: 0.4827 - val_accuracy: 0.8058\n",
      "Epoch 330/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4938 - accuracy: 0.7855 - val_loss: 0.4686 - val_accuracy: 0.8162\n",
      "Epoch 331/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5044 - accuracy: 0.7810 - val_loss: 0.4721 - val_accuracy: 0.8150\n",
      "Epoch 332/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4960 - accuracy: 0.7844 - val_loss: 0.4769 - val_accuracy: 0.8053\n",
      "Epoch 333/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4868 - accuracy: 0.7935 - val_loss: 0.4796 - val_accuracy: 0.8058\n",
      "Epoch 334/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4922 - accuracy: 0.7858 - val_loss: 0.4673 - val_accuracy: 0.8150\n",
      "Epoch 335/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4862 - accuracy: 0.7867 - val_loss: 0.4767 - val_accuracy: 0.8039\n",
      "Epoch 336/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4881 - accuracy: 0.7881 - val_loss: 0.4776 - val_accuracy: 0.8107\n",
      "Epoch 337/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4808 - accuracy: 0.7955 - val_loss: 0.4644 - val_accuracy: 0.8125\n",
      "Epoch 338/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4938 - accuracy: 0.7848 - val_loss: 0.4771 - val_accuracy: 0.8033\n",
      "Epoch 339/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5031 - accuracy: 0.7841 - val_loss: 0.4613 - val_accuracy: 0.8078\n",
      "Epoch 340/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4880 - accuracy: 0.7904 - val_loss: 0.4890 - val_accuracy: 0.8003\n",
      "Epoch 341/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4807 - accuracy: 0.7942 - val_loss: 0.4616 - val_accuracy: 0.8196\n",
      "Epoch 342/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4908 - accuracy: 0.7880 - val_loss: 0.4705 - val_accuracy: 0.8123\n",
      "Epoch 343/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4925 - accuracy: 0.7853 - val_loss: 0.4544 - val_accuracy: 0.8196\n",
      "Epoch 344/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4875 - accuracy: 0.7888 - val_loss: 0.4566 - val_accuracy: 0.8193\n",
      "Epoch 345/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4841 - accuracy: 0.7915 - val_loss: 0.4705 - val_accuracy: 0.8144\n",
      "Epoch 346/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4889 - accuracy: 0.7904 - val_loss: 0.4884 - val_accuracy: 0.8008\n",
      "Epoch 347/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4875 - accuracy: 0.7915 - val_loss: 0.4829 - val_accuracy: 0.8094\n",
      "Epoch 348/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4982 - accuracy: 0.7815 - val_loss: 0.5235 - val_accuracy: 0.7915\n",
      "Epoch 349/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4946 - accuracy: 0.7837 - val_loss: 0.4710 - val_accuracy: 0.8078\n",
      "Epoch 350/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4880 - accuracy: 0.7852 - val_loss: 0.4536 - val_accuracy: 0.8132\n",
      "Epoch 351/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4897 - accuracy: 0.7846 - val_loss: 0.4652 - val_accuracy: 0.8119\n",
      "Epoch 352/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4833 - accuracy: 0.7923 - val_loss: 0.4579 - val_accuracy: 0.8175\n",
      "Epoch 353/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4744 - accuracy: 0.7997 - val_loss: 0.4413 - val_accuracy: 0.8291\n",
      "Epoch 354/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4921 - accuracy: 0.7876 - val_loss: 0.4872 - val_accuracy: 0.8026\n",
      "Epoch 355/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4838 - accuracy: 0.7908 - val_loss: 0.4597 - val_accuracy: 0.8130\n",
      "Epoch 356/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4788 - accuracy: 0.7943 - val_loss: 0.4599 - val_accuracy: 0.8157\n",
      "Epoch 357/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4897 - accuracy: 0.7886 - val_loss: 0.4722 - val_accuracy: 0.8060\n",
      "Epoch 358/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4922 - accuracy: 0.7892 - val_loss: 0.4732 - val_accuracy: 0.8116\n",
      "Epoch 359/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4815 - accuracy: 0.7943 - val_loss: 0.4602 - val_accuracy: 0.8205\n",
      "Epoch 360/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4869 - accuracy: 0.7887 - val_loss: 0.4613 - val_accuracy: 0.8144\n",
      "Epoch 361/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4905 - accuracy: 0.7868 - val_loss: 0.4581 - val_accuracy: 0.8187\n",
      "Epoch 362/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4849 - accuracy: 0.7905 - val_loss: 0.4612 - val_accuracy: 0.8144\n",
      "Epoch 363/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4896 - accuracy: 0.7888 - val_loss: 0.4588 - val_accuracy: 0.8187\n",
      "Epoch 364/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4816 - accuracy: 0.7908 - val_loss: 0.4466 - val_accuracy: 0.8257\n",
      "Epoch 365/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4742 - accuracy: 0.7949 - val_loss: 0.4641 - val_accuracy: 0.8162\n",
      "Epoch 366/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4806 - accuracy: 0.7933 - val_loss: 0.4573 - val_accuracy: 0.8171\n",
      "Epoch 367/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4892 - accuracy: 0.7882 - val_loss: 0.4489 - val_accuracy: 0.8200\n",
      "Epoch 368/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4883 - accuracy: 0.7900 - val_loss: 0.4501 - val_accuracy: 0.8214\n",
      "Epoch 369/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4838 - accuracy: 0.7886 - val_loss: 0.4479 - val_accuracy: 0.8239\n",
      "Epoch 370/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4912 - accuracy: 0.7915 - val_loss: 0.4672 - val_accuracy: 0.8193\n",
      "Epoch 371/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4828 - accuracy: 0.7876 - val_loss: 0.4651 - val_accuracy: 0.8166\n",
      "Epoch 372/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4891 - accuracy: 0.7905 - val_loss: 0.4722 - val_accuracy: 0.8060\n",
      "Epoch 373/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4815 - accuracy: 0.7919 - val_loss: 0.4609 - val_accuracy: 0.8202\n",
      "Epoch 374/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4788 - accuracy: 0.7958 - val_loss: 0.4392 - val_accuracy: 0.8250\n",
      "Epoch 375/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4768 - accuracy: 0.7924 - val_loss: 0.4690 - val_accuracy: 0.8132\n",
      "Epoch 376/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4841 - accuracy: 0.7921 - val_loss: 0.4746 - val_accuracy: 0.8116\n",
      "Epoch 377/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4868 - accuracy: 0.7885 - val_loss: 0.4547 - val_accuracy: 0.8227\n",
      "Epoch 378/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4719 - accuracy: 0.8027 - val_loss: 0.4587 - val_accuracy: 0.8198\n",
      "Epoch 379/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4910 - accuracy: 0.7865 - val_loss: 0.4458 - val_accuracy: 0.8250\n",
      "Epoch 380/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4823 - accuracy: 0.7911 - val_loss: 0.4629 - val_accuracy: 0.8200\n",
      "Epoch 381/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4867 - accuracy: 0.7898 - val_loss: 0.4776 - val_accuracy: 0.8076\n",
      "Epoch 382/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4881 - accuracy: 0.7862 - val_loss: 0.4532 - val_accuracy: 0.8243\n",
      "Epoch 383/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4798 - accuracy: 0.7965 - val_loss: 0.4576 - val_accuracy: 0.8234\n",
      "Epoch 384/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4739 - accuracy: 0.8006 - val_loss: 0.4531 - val_accuracy: 0.8279\n",
      "Epoch 385/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4830 - accuracy: 0.7928 - val_loss: 0.4642 - val_accuracy: 0.8164\n",
      "Epoch 386/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4766 - accuracy: 0.7914 - val_loss: 0.4702 - val_accuracy: 0.8091\n",
      "Epoch 387/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4862 - accuracy: 0.7928 - val_loss: 0.4386 - val_accuracy: 0.8234\n",
      "Epoch 388/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4785 - accuracy: 0.7974 - val_loss: 0.4683 - val_accuracy: 0.8051\n",
      "Epoch 389/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4800 - accuracy: 0.7950 - val_loss: 0.4436 - val_accuracy: 0.8218\n",
      "Epoch 390/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4702 - accuracy: 0.8001 - val_loss: 0.4620 - val_accuracy: 0.8128\n",
      "Epoch 391/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4946 - accuracy: 0.7843 - val_loss: 0.4524 - val_accuracy: 0.8223\n",
      "Epoch 392/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4755 - accuracy: 0.7955 - val_loss: 0.4481 - val_accuracy: 0.8211\n",
      "Epoch 393/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4754 - accuracy: 0.7971 - val_loss: 0.4489 - val_accuracy: 0.8196\n",
      "Epoch 394/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4773 - accuracy: 0.7946 - val_loss: 0.4619 - val_accuracy: 0.8175\n",
      "Epoch 395/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4780 - accuracy: 0.7930 - val_loss: 0.4454 - val_accuracy: 0.8157\n",
      "Epoch 396/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4761 - accuracy: 0.7998 - val_loss: 0.4521 - val_accuracy: 0.8182\n",
      "Epoch 397/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4762 - accuracy: 0.7914 - val_loss: 0.4513 - val_accuracy: 0.8207\n",
      "Epoch 398/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4880 - accuracy: 0.7891 - val_loss: 0.4499 - val_accuracy: 0.8254\n",
      "Epoch 399/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4736 - accuracy: 0.7954 - val_loss: 0.4496 - val_accuracy: 0.8207\n",
      "Epoch 400/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4869 - accuracy: 0.7893 - val_loss: 0.4353 - val_accuracy: 0.8334\n",
      "Epoch 401/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4809 - accuracy: 0.7908 - val_loss: 0.4456 - val_accuracy: 0.8277\n",
      "Epoch 402/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4769 - accuracy: 0.7939 - val_loss: 0.4516 - val_accuracy: 0.8225\n",
      "Epoch 403/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4826 - accuracy: 0.7907 - val_loss: 0.4392 - val_accuracy: 0.8291\n",
      "Epoch 404/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4828 - accuracy: 0.7901 - val_loss: 0.4563 - val_accuracy: 0.8191\n",
      "Epoch 405/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4781 - accuracy: 0.7922 - val_loss: 0.4579 - val_accuracy: 0.8230\n",
      "Epoch 406/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4749 - accuracy: 0.7951 - val_loss: 0.4609 - val_accuracy: 0.8162\n",
      "Epoch 407/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4680 - accuracy: 0.7978 - val_loss: 0.4474 - val_accuracy: 0.8279\n",
      "Epoch 408/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4669 - accuracy: 0.7991 - val_loss: 0.4668 - val_accuracy: 0.8155\n",
      "Epoch 409/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4740 - accuracy: 0.7957 - val_loss: 0.4722 - val_accuracy: 0.8162\n",
      "Epoch 410/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4776 - accuracy: 0.7988 - val_loss: 0.4367 - val_accuracy: 0.8286\n",
      "Epoch 411/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4813 - accuracy: 0.7949 - val_loss: 0.4456 - val_accuracy: 0.8205\n",
      "Epoch 412/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4768 - accuracy: 0.7974 - val_loss: 0.4406 - val_accuracy: 0.8325\n",
      "Epoch 413/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4784 - accuracy: 0.7893 - val_loss: 0.4390 - val_accuracy: 0.8300\n",
      "Epoch 414/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4671 - accuracy: 0.7958 - val_loss: 0.4423 - val_accuracy: 0.8284\n",
      "Epoch 415/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4852 - accuracy: 0.7944 - val_loss: 0.4363 - val_accuracy: 0.8273\n",
      "Epoch 416/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4701 - accuracy: 0.7958 - val_loss: 0.4436 - val_accuracy: 0.8198\n",
      "Epoch 417/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4644 - accuracy: 0.8004 - val_loss: 0.4365 - val_accuracy: 0.8293\n",
      "Epoch 418/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4724 - accuracy: 0.7974 - val_loss: 0.4378 - val_accuracy: 0.8288\n",
      "Epoch 419/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4727 - accuracy: 0.7963 - val_loss: 0.4373 - val_accuracy: 0.8356\n",
      "Epoch 420/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.8051 - val_loss: 0.4643 - val_accuracy: 0.8182\n",
      "Epoch 421/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4780 - accuracy: 0.7947 - val_loss: 0.4591 - val_accuracy: 0.8189\n",
      "Epoch 422/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4627 - accuracy: 0.8032 - val_loss: 0.4407 - val_accuracy: 0.8218\n",
      "Epoch 423/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4804 - accuracy: 0.7925 - val_loss: 0.4545 - val_accuracy: 0.8180\n",
      "Epoch 424/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.7986 - val_loss: 0.4582 - val_accuracy: 0.8191\n",
      "Epoch 425/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4798 - accuracy: 0.7958 - val_loss: 0.4906 - val_accuracy: 0.8046\n",
      "Epoch 426/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4867 - accuracy: 0.7904 - val_loss: 0.4426 - val_accuracy: 0.8234\n",
      "Epoch 427/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4756 - accuracy: 0.7992 - val_loss: 0.4426 - val_accuracy: 0.8268\n",
      "Epoch 428/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4675 - accuracy: 0.7976 - val_loss: 0.4697 - val_accuracy: 0.8071\n",
      "Epoch 429/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4692 - accuracy: 0.8035 - val_loss: 0.4292 - val_accuracy: 0.8386\n",
      "Epoch 430/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4577 - accuracy: 0.8047 - val_loss: 0.4592 - val_accuracy: 0.8164\n",
      "Epoch 431/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4705 - accuracy: 0.7971 - val_loss: 0.4509 - val_accuracy: 0.8225\n",
      "Epoch 432/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4631 - accuracy: 0.7993 - val_loss: 0.4434 - val_accuracy: 0.8245\n",
      "Epoch 433/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4735 - accuracy: 0.7934 - val_loss: 0.4245 - val_accuracy: 0.8417\n",
      "Epoch 434/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4570 - accuracy: 0.8032 - val_loss: 0.4677 - val_accuracy: 0.8191\n",
      "Epoch 435/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4645 - accuracy: 0.8018 - val_loss: 0.4454 - val_accuracy: 0.8250\n",
      "Epoch 436/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4709 - accuracy: 0.8017 - val_loss: 0.4542 - val_accuracy: 0.8230\n",
      "Epoch 437/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4804 - accuracy: 0.7895 - val_loss: 0.4371 - val_accuracy: 0.8282\n",
      "Epoch 438/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4709 - accuracy: 0.7969 - val_loss: 0.4334 - val_accuracy: 0.8309\n",
      "Epoch 439/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4742 - accuracy: 0.7926 - val_loss: 0.4360 - val_accuracy: 0.8270\n",
      "Epoch 440/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4716 - accuracy: 0.7984 - val_loss: 0.4364 - val_accuracy: 0.8295\n",
      "Epoch 441/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4771 - accuracy: 0.7963 - val_loss: 0.4454 - val_accuracy: 0.8248\n",
      "Epoch 442/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7965 - val_loss: 0.4372 - val_accuracy: 0.8297\n",
      "Epoch 443/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4681 - accuracy: 0.7987 - val_loss: 0.4293 - val_accuracy: 0.8322\n",
      "Epoch 444/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4650 - accuracy: 0.8003 - val_loss: 0.4354 - val_accuracy: 0.8309\n",
      "Epoch 445/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4750 - accuracy: 0.7952 - val_loss: 0.4457 - val_accuracy: 0.8211\n",
      "Epoch 446/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4671 - accuracy: 0.7975 - val_loss: 0.4409 - val_accuracy: 0.8245\n",
      "Epoch 447/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4559 - accuracy: 0.8011 - val_loss: 0.4751 - val_accuracy: 0.8046\n",
      "Epoch 448/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4750 - accuracy: 0.7966 - val_loss: 0.4330 - val_accuracy: 0.8304\n",
      "Epoch 449/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4593 - accuracy: 0.8014 - val_loss: 0.4457 - val_accuracy: 0.8223\n",
      "Epoch 450/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4676 - accuracy: 0.7971 - val_loss: 0.4375 - val_accuracy: 0.8322\n",
      "Epoch 451/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4557 - accuracy: 0.8007 - val_loss: 0.4301 - val_accuracy: 0.8329\n",
      "Epoch 452/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7946 - val_loss: 0.4490 - val_accuracy: 0.8252\n",
      "Epoch 453/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4687 - accuracy: 0.8015 - val_loss: 0.4348 - val_accuracy: 0.8325\n",
      "Epoch 454/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4653 - accuracy: 0.8002 - val_loss: 0.4476 - val_accuracy: 0.8241\n",
      "Epoch 455/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4695 - accuracy: 0.7979 - val_loss: 0.4332 - val_accuracy: 0.8300\n",
      "Epoch 456/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4596 - accuracy: 0.8011 - val_loss: 0.4373 - val_accuracy: 0.8295\n",
      "Epoch 457/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4799 - accuracy: 0.7947 - val_loss: 0.4240 - val_accuracy: 0.8390\n",
      "Epoch 458/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4717 - accuracy: 0.8014 - val_loss: 0.4381 - val_accuracy: 0.8225\n",
      "Epoch 459/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7975 - val_loss: 0.4285 - val_accuracy: 0.8338\n",
      "Epoch 460/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4564 - accuracy: 0.8046 - val_loss: 0.4352 - val_accuracy: 0.8250\n",
      "Epoch 461/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4654 - accuracy: 0.7987 - val_loss: 0.4380 - val_accuracy: 0.8293\n",
      "Epoch 462/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4673 - accuracy: 0.7984 - val_loss: 0.4284 - val_accuracy: 0.8352\n",
      "Epoch 463/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4626 - accuracy: 0.8025 - val_loss: 0.4395 - val_accuracy: 0.8282\n",
      "Epoch 464/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4606 - accuracy: 0.8042 - val_loss: 0.4383 - val_accuracy: 0.8291\n",
      "Epoch 465/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4553 - accuracy: 0.8047 - val_loss: 0.4565 - val_accuracy: 0.8245\n",
      "Epoch 466/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4663 - accuracy: 0.7985 - val_loss: 0.4419 - val_accuracy: 0.8243\n",
      "Epoch 467/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.7970 - val_loss: 0.4446 - val_accuracy: 0.8257\n",
      "Epoch 468/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4677 - accuracy: 0.7978 - val_loss: 0.4186 - val_accuracy: 0.8365\n",
      "Epoch 469/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4617 - accuracy: 0.8029 - val_loss: 0.4134 - val_accuracy: 0.8415\n",
      "Epoch 470/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4650 - accuracy: 0.8008 - val_loss: 0.4407 - val_accuracy: 0.8279\n",
      "Epoch 471/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4580 - accuracy: 0.8055 - val_loss: 0.4370 - val_accuracy: 0.8329\n",
      "Epoch 472/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4579 - accuracy: 0.8040 - val_loss: 0.4260 - val_accuracy: 0.8341\n",
      "Epoch 473/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4600 - accuracy: 0.8030 - val_loss: 0.4312 - val_accuracy: 0.8336\n",
      "Epoch 474/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4545 - accuracy: 0.8076 - val_loss: 0.4294 - val_accuracy: 0.8313\n",
      "Epoch 475/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4587 - accuracy: 0.7991 - val_loss: 0.4480 - val_accuracy: 0.8159\n",
      "Epoch 476/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4618 - accuracy: 0.8017 - val_loss: 0.4225 - val_accuracy: 0.8363\n",
      "Epoch 477/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4572 - accuracy: 0.8032 - val_loss: 0.4372 - val_accuracy: 0.8284\n",
      "Epoch 478/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7999 - val_loss: 0.4323 - val_accuracy: 0.8270\n",
      "Epoch 479/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4589 - accuracy: 0.8020 - val_loss: 0.4239 - val_accuracy: 0.8354\n",
      "Epoch 480/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4586 - accuracy: 0.7997 - val_loss: 0.4311 - val_accuracy: 0.8264\n",
      "Epoch 481/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4709 - accuracy: 0.8005 - val_loss: 0.4214 - val_accuracy: 0.8368\n",
      "Epoch 482/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.8067 - val_loss: 0.4315 - val_accuracy: 0.8329\n",
      "Epoch 483/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4677 - accuracy: 0.7999 - val_loss: 0.4357 - val_accuracy: 0.8270\n",
      "Epoch 484/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4635 - accuracy: 0.7993 - val_loss: 0.4341 - val_accuracy: 0.8307\n",
      "Epoch 485/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.8064 - val_loss: 0.4815 - val_accuracy: 0.8076\n",
      "Epoch 486/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4705 - accuracy: 0.8005 - val_loss: 0.4437 - val_accuracy: 0.8248\n",
      "Epoch 487/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4586 - accuracy: 0.8063 - val_loss: 0.4402 - val_accuracy: 0.8243\n",
      "Epoch 488/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4605 - accuracy: 0.8046 - val_loss: 0.4341 - val_accuracy: 0.8316\n",
      "Epoch 489/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4623 - accuracy: 0.7990 - val_loss: 0.4208 - val_accuracy: 0.8325\n",
      "Epoch 490/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4612 - accuracy: 0.8008 - val_loss: 0.4372 - val_accuracy: 0.8313\n",
      "Epoch 491/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4580 - accuracy: 0.8051 - val_loss: 0.4401 - val_accuracy: 0.8295\n",
      "Epoch 492/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4737 - accuracy: 0.7966 - val_loss: 0.4184 - val_accuracy: 0.8372\n",
      "Epoch 493/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4642 - accuracy: 0.7951 - val_loss: 0.4573 - val_accuracy: 0.8171\n",
      "Epoch 494/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4656 - accuracy: 0.7940 - val_loss: 0.4314 - val_accuracy: 0.8268\n",
      "Epoch 495/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4700 - accuracy: 0.8003 - val_loss: 0.4237 - val_accuracy: 0.8361\n",
      "Epoch 496/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4600 - accuracy: 0.8048 - val_loss: 0.4342 - val_accuracy: 0.8275\n",
      "Epoch 497/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.8061 - val_loss: 0.4570 - val_accuracy: 0.8177\n",
      "Epoch 498/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4646 - accuracy: 0.7970 - val_loss: 0.4406 - val_accuracy: 0.8277\n",
      "Epoch 499/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4674 - accuracy: 0.7977 - val_loss: 0.4293 - val_accuracy: 0.8295\n",
      "Epoch 500/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4744 - accuracy: 0.7956 - val_loss: 0.4406 - val_accuracy: 0.8341\n",
      "Epoch 501/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4695 - accuracy: 0.7968 - val_loss: 0.4186 - val_accuracy: 0.8399\n",
      "Epoch 502/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.8079 - val_loss: 0.4197 - val_accuracy: 0.8379\n",
      "Epoch 503/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.8021 - val_loss: 0.4212 - val_accuracy: 0.8331\n",
      "Epoch 504/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4581 - accuracy: 0.8056 - val_loss: 0.4234 - val_accuracy: 0.8322\n",
      "Epoch 505/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4553 - accuracy: 0.8062 - val_loss: 0.4331 - val_accuracy: 0.8304\n",
      "Epoch 506/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4464 - accuracy: 0.8053 - val_loss: 0.4216 - val_accuracy: 0.8327\n",
      "Epoch 507/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4518 - accuracy: 0.8095 - val_loss: 0.4365 - val_accuracy: 0.8325\n",
      "Epoch 508/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4696 - accuracy: 0.8020 - val_loss: 0.4260 - val_accuracy: 0.8347\n",
      "Epoch 509/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4446 - accuracy: 0.8117 - val_loss: 0.4500 - val_accuracy: 0.8257\n",
      "Epoch 510/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.8000 - val_loss: 0.4322 - val_accuracy: 0.8329\n",
      "Epoch 511/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4665 - accuracy: 0.7998 - val_loss: 0.4284 - val_accuracy: 0.8322\n",
      "Epoch 512/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4606 - accuracy: 0.8032 - val_loss: 0.4293 - val_accuracy: 0.8350\n",
      "Epoch 513/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4573 - accuracy: 0.8000 - val_loss: 0.4241 - val_accuracy: 0.8336\n",
      "Epoch 514/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.8085 - val_loss: 0.4287 - val_accuracy: 0.8370\n",
      "Epoch 515/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4553 - accuracy: 0.8072 - val_loss: 0.4156 - val_accuracy: 0.8404\n",
      "Epoch 516/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4474 - accuracy: 0.8129 - val_loss: 0.4452 - val_accuracy: 0.8282\n",
      "Epoch 517/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4662 - accuracy: 0.7991 - val_loss: 0.4267 - val_accuracy: 0.8350\n",
      "Epoch 518/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4504 - accuracy: 0.8081 - val_loss: 0.4267 - val_accuracy: 0.8347\n",
      "Epoch 519/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4532 - accuracy: 0.8082 - val_loss: 0.4323 - val_accuracy: 0.8291\n",
      "Epoch 520/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4647 - accuracy: 0.8004 - val_loss: 0.4300 - val_accuracy: 0.8343\n",
      "Epoch 521/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4553 - accuracy: 0.8053 - val_loss: 0.4434 - val_accuracy: 0.8232\n",
      "Epoch 522/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4660 - accuracy: 0.7973 - val_loss: 0.4116 - val_accuracy: 0.8420\n",
      "Epoch 523/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4515 - accuracy: 0.8080 - val_loss: 0.4000 - val_accuracy: 0.8508\n",
      "Epoch 524/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4579 - accuracy: 0.8021 - val_loss: 0.4167 - val_accuracy: 0.8393\n",
      "Epoch 525/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4441 - accuracy: 0.8116 - val_loss: 0.4440 - val_accuracy: 0.8254\n",
      "Epoch 526/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4436 - accuracy: 0.8097 - val_loss: 0.4198 - val_accuracy: 0.8384\n",
      "Epoch 527/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4506 - accuracy: 0.8094 - val_loss: 0.4205 - val_accuracy: 0.8379\n",
      "Epoch 528/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.8065 - val_loss: 0.4082 - val_accuracy: 0.8485\n",
      "Epoch 529/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4550 - accuracy: 0.8034 - val_loss: 0.4427 - val_accuracy: 0.8302\n",
      "Epoch 530/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4552 - accuracy: 0.8042 - val_loss: 0.4124 - val_accuracy: 0.8429\n",
      "Epoch 531/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4493 - accuracy: 0.8104 - val_loss: 0.4148 - val_accuracy: 0.8370\n",
      "Epoch 532/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4555 - accuracy: 0.8056 - val_loss: 0.4181 - val_accuracy: 0.8393\n",
      "Epoch 533/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.8087 - val_loss: 0.4094 - val_accuracy: 0.8365\n",
      "Epoch 534/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4562 - accuracy: 0.8048 - val_loss: 0.3994 - val_accuracy: 0.8454\n",
      "Epoch 535/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4516 - accuracy: 0.8074 - val_loss: 0.4247 - val_accuracy: 0.8327\n",
      "Epoch 536/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4624 - accuracy: 0.8028 - val_loss: 0.4215 - val_accuracy: 0.8386\n",
      "Epoch 537/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4675 - accuracy: 0.8018 - val_loss: 0.4330 - val_accuracy: 0.8334\n",
      "Epoch 538/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4654 - accuracy: 0.8012 - val_loss: 0.4347 - val_accuracy: 0.8302\n",
      "Epoch 539/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4622 - accuracy: 0.8023 - val_loss: 0.4030 - val_accuracy: 0.8470\n",
      "Epoch 540/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4602 - accuracy: 0.8031 - val_loss: 0.4214 - val_accuracy: 0.8327\n",
      "Epoch 541/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4552 - accuracy: 0.8084 - val_loss: 0.4152 - val_accuracy: 0.8413\n",
      "Epoch 542/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4412 - accuracy: 0.8158 - val_loss: 0.4006 - val_accuracy: 0.8447\n",
      "Epoch 543/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4518 - accuracy: 0.8082 - val_loss: 0.4526 - val_accuracy: 0.8202\n",
      "Epoch 544/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4519 - accuracy: 0.8060 - val_loss: 0.4094 - val_accuracy: 0.8445\n",
      "Epoch 545/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.8065 - val_loss: 0.4255 - val_accuracy: 0.8300\n",
      "Epoch 546/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4597 - accuracy: 0.8029 - val_loss: 0.4148 - val_accuracy: 0.8377\n",
      "Epoch 547/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4476 - accuracy: 0.8084 - val_loss: 0.4115 - val_accuracy: 0.8395\n",
      "Epoch 548/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4501 - accuracy: 0.8084 - val_loss: 0.4268 - val_accuracy: 0.8266\n",
      "Epoch 549/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4381 - accuracy: 0.8111 - val_loss: 0.4269 - val_accuracy: 0.8343\n",
      "Epoch 550/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4545 - accuracy: 0.8026 - val_loss: 0.4206 - val_accuracy: 0.8374\n",
      "Epoch 551/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4567 - accuracy: 0.8052 - val_loss: 0.4095 - val_accuracy: 0.8393\n",
      "Epoch 552/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4572 - accuracy: 0.8080 - val_loss: 0.4094 - val_accuracy: 0.8431\n",
      "Epoch 553/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4508 - accuracy: 0.8027 - val_loss: 0.4084 - val_accuracy: 0.8476\n",
      "Epoch 554/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4439 - accuracy: 0.8110 - val_loss: 0.4042 - val_accuracy: 0.8422\n",
      "Epoch 555/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.8067 - val_loss: 0.4030 - val_accuracy: 0.8449\n",
      "Epoch 556/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4585 - accuracy: 0.8021 - val_loss: 0.4168 - val_accuracy: 0.8456\n",
      "Epoch 557/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4479 - accuracy: 0.8071 - val_loss: 0.3987 - val_accuracy: 0.8513\n",
      "Epoch 558/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4543 - accuracy: 0.8052 - val_loss: 0.4105 - val_accuracy: 0.8488\n",
      "Epoch 559/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4562 - accuracy: 0.8082 - val_loss: 0.4114 - val_accuracy: 0.8436\n",
      "Epoch 560/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4428 - accuracy: 0.8126 - val_loss: 0.4073 - val_accuracy: 0.8458\n",
      "Epoch 561/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4489 - accuracy: 0.8097 - val_loss: 0.4105 - val_accuracy: 0.8479\n",
      "Epoch 562/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4519 - accuracy: 0.8068 - val_loss: 0.4325 - val_accuracy: 0.8352\n",
      "Epoch 563/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4440 - accuracy: 0.8092 - val_loss: 0.4088 - val_accuracy: 0.8463\n",
      "Epoch 564/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4468 - accuracy: 0.8128 - val_loss: 0.4163 - val_accuracy: 0.8379\n",
      "Epoch 565/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4530 - accuracy: 0.8065 - val_loss: 0.3998 - val_accuracy: 0.8458\n",
      "Epoch 566/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4559 - accuracy: 0.8040 - val_loss: 0.4157 - val_accuracy: 0.8361\n",
      "Epoch 567/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4476 - accuracy: 0.8104 - val_loss: 0.4089 - val_accuracy: 0.8456\n",
      "Epoch 568/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4424 - accuracy: 0.8086 - val_loss: 0.4256 - val_accuracy: 0.8402\n",
      "Epoch 569/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4457 - accuracy: 0.8124 - val_loss: 0.4108 - val_accuracy: 0.8458\n",
      "Epoch 570/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4423 - accuracy: 0.8103 - val_loss: 0.4148 - val_accuracy: 0.8386\n",
      "Epoch 571/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4454 - accuracy: 0.8128 - val_loss: 0.4147 - val_accuracy: 0.8440\n",
      "Epoch 572/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4557 - accuracy: 0.8052 - val_loss: 0.4350 - val_accuracy: 0.8295\n",
      "Epoch 573/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4505 - accuracy: 0.8063 - val_loss: 0.4199 - val_accuracy: 0.8451\n",
      "Epoch 574/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4492 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8422\n",
      "Epoch 575/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4460 - accuracy: 0.8123 - val_loss: 0.4146 - val_accuracy: 0.8370\n",
      "Epoch 576/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4537 - accuracy: 0.8121 - val_loss: 0.4141 - val_accuracy: 0.8379\n",
      "Epoch 577/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4578 - accuracy: 0.8074 - val_loss: 0.4108 - val_accuracy: 0.8406\n",
      "Epoch 578/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4349 - accuracy: 0.8161 - val_loss: 0.3985 - val_accuracy: 0.8497\n",
      "Epoch 579/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4482 - accuracy: 0.8112 - val_loss: 0.4068 - val_accuracy: 0.8431\n",
      "Epoch 580/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4558 - accuracy: 0.8051 - val_loss: 0.4258 - val_accuracy: 0.8336\n",
      "Epoch 581/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.8110 - val_loss: 0.4197 - val_accuracy: 0.8422\n",
      "Epoch 582/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4587 - accuracy: 0.7986 - val_loss: 0.4153 - val_accuracy: 0.8350\n",
      "Epoch 583/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4556 - accuracy: 0.8038 - val_loss: 0.4241 - val_accuracy: 0.8438\n",
      "Epoch 584/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4480 - accuracy: 0.8112 - val_loss: 0.4097 - val_accuracy: 0.8440\n",
      "Epoch 585/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4472 - accuracy: 0.8081 - val_loss: 0.4174 - val_accuracy: 0.8408\n",
      "Epoch 586/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4399 - accuracy: 0.8098 - val_loss: 0.3939 - val_accuracy: 0.8472\n",
      "Epoch 587/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4450 - accuracy: 0.8079 - val_loss: 0.4049 - val_accuracy: 0.8494\n",
      "Epoch 588/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4564 - accuracy: 0.8068 - val_loss: 0.4136 - val_accuracy: 0.8379\n",
      "Epoch 589/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4344 - accuracy: 0.8160 - val_loss: 0.4147 - val_accuracy: 0.8438\n",
      "Epoch 590/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4481 - accuracy: 0.8093 - val_loss: 0.3978 - val_accuracy: 0.8472\n",
      "Epoch 591/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4422 - accuracy: 0.8127 - val_loss: 0.4014 - val_accuracy: 0.8440\n",
      "Epoch 592/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4473 - accuracy: 0.8096 - val_loss: 0.4162 - val_accuracy: 0.8431\n",
      "Epoch 593/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4455 - accuracy: 0.8084 - val_loss: 0.4060 - val_accuracy: 0.8447\n",
      "Epoch 594/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4459 - accuracy: 0.8103 - val_loss: 0.4263 - val_accuracy: 0.8365\n",
      "Epoch 595/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4375 - accuracy: 0.8153 - val_loss: 0.3968 - val_accuracy: 0.8519\n",
      "Epoch 596/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4486 - accuracy: 0.8064 - val_loss: 0.4247 - val_accuracy: 0.8350\n",
      "Epoch 597/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4413 - accuracy: 0.8108 - val_loss: 0.4360 - val_accuracy: 0.8297\n",
      "Epoch 598/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4411 - accuracy: 0.8118 - val_loss: 0.4213 - val_accuracy: 0.8424\n",
      "Epoch 599/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4356 - accuracy: 0.8147 - val_loss: 0.4245 - val_accuracy: 0.8313\n",
      "Epoch 600/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.8075 - val_loss: 0.3991 - val_accuracy: 0.8470\n",
      "Epoch 601/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4514 - accuracy: 0.8080 - val_loss: 0.4143 - val_accuracy: 0.8420\n",
      "Epoch 602/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4451 - accuracy: 0.8143 - val_loss: 0.3960 - val_accuracy: 0.8574\n",
      "Epoch 603/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4407 - accuracy: 0.8171 - val_loss: 0.4164 - val_accuracy: 0.8329\n",
      "Epoch 604/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4423 - accuracy: 0.8135 - val_loss: 0.4101 - val_accuracy: 0.8454\n",
      "Epoch 605/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4422 - accuracy: 0.8147 - val_loss: 0.4163 - val_accuracy: 0.8404\n",
      "Epoch 606/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4379 - accuracy: 0.8198 - val_loss: 0.3992 - val_accuracy: 0.8490\n",
      "Epoch 607/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4591 - accuracy: 0.8029 - val_loss: 0.4254 - val_accuracy: 0.8270\n",
      "Epoch 608/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4508 - accuracy: 0.8049 - val_loss: 0.3993 - val_accuracy: 0.8537\n",
      "Epoch 609/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4607 - accuracy: 0.8039 - val_loss: 0.4066 - val_accuracy: 0.8411\n",
      "Epoch 610/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4472 - accuracy: 0.8093 - val_loss: 0.3919 - val_accuracy: 0.8517\n",
      "Epoch 611/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4493 - accuracy: 0.8064 - val_loss: 0.4111 - val_accuracy: 0.8431\n",
      "Epoch 612/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4468 - accuracy: 0.8079 - val_loss: 0.4138 - val_accuracy: 0.8463\n",
      "Epoch 613/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4509 - accuracy: 0.8034 - val_loss: 0.4006 - val_accuracy: 0.8479\n",
      "Epoch 614/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4480 - accuracy: 0.8119 - val_loss: 0.4178 - val_accuracy: 0.8363\n",
      "Epoch 615/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4471 - accuracy: 0.8110 - val_loss: 0.4127 - val_accuracy: 0.8422\n",
      "Epoch 616/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4406 - accuracy: 0.8099 - val_loss: 0.4098 - val_accuracy: 0.8411\n",
      "Epoch 617/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4374 - accuracy: 0.8153 - val_loss: 0.4147 - val_accuracy: 0.8463\n",
      "Epoch 618/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4505 - accuracy: 0.8081 - val_loss: 0.4188 - val_accuracy: 0.8404\n",
      "Epoch 619/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4334 - accuracy: 0.8184 - val_loss: 0.4110 - val_accuracy: 0.8465\n",
      "Epoch 620/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4458 - accuracy: 0.8115 - val_loss: 0.4237 - val_accuracy: 0.8393\n",
      "Epoch 621/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4494 - accuracy: 0.8100 - val_loss: 0.4108 - val_accuracy: 0.8494\n",
      "Epoch 622/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4344 - accuracy: 0.8181 - val_loss: 0.4134 - val_accuracy: 0.8386\n",
      "Epoch 623/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4490 - accuracy: 0.8087 - val_loss: 0.4124 - val_accuracy: 0.8384\n",
      "Epoch 624/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4463 - accuracy: 0.8148 - val_loss: 0.4055 - val_accuracy: 0.8456\n",
      "Epoch 625/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4446 - accuracy: 0.8124 - val_loss: 0.4144 - val_accuracy: 0.8440\n",
      "Epoch 626/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4451 - accuracy: 0.8111 - val_loss: 0.4045 - val_accuracy: 0.8485\n",
      "Epoch 627/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4541 - accuracy: 0.8080 - val_loss: 0.4037 - val_accuracy: 0.8485\n",
      "Epoch 628/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.8124 - val_loss: 0.3905 - val_accuracy: 0.8519\n",
      "Epoch 629/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4439 - accuracy: 0.8085 - val_loss: 0.3886 - val_accuracy: 0.8533\n",
      "Epoch 630/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4432 - accuracy: 0.8154 - val_loss: 0.4016 - val_accuracy: 0.8481\n",
      "Epoch 631/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4407 - accuracy: 0.8149 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
      "Epoch 632/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.8103 - val_loss: 0.4211 - val_accuracy: 0.8374\n",
      "Epoch 633/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.8045 - val_loss: 0.3964 - val_accuracy: 0.8499\n",
      "Epoch 634/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4320 - accuracy: 0.8211 - val_loss: 0.4109 - val_accuracy: 0.8449\n",
      "Epoch 635/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4494 - accuracy: 0.8175 - val_loss: 0.4009 - val_accuracy: 0.8454\n",
      "Epoch 636/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4441 - accuracy: 0.8070 - val_loss: 0.4035 - val_accuracy: 0.8535\n",
      "Epoch 637/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4440 - accuracy: 0.8094 - val_loss: 0.4200 - val_accuracy: 0.8365\n",
      "Epoch 638/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4387 - accuracy: 0.8163 - val_loss: 0.3950 - val_accuracy: 0.8567\n",
      "Epoch 639/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4414 - accuracy: 0.8147 - val_loss: 0.4224 - val_accuracy: 0.8313\n",
      "Epoch 640/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4440 - accuracy: 0.8137 - val_loss: 0.4001 - val_accuracy: 0.8515\n",
      "Epoch 641/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4445 - accuracy: 0.8116 - val_loss: 0.3957 - val_accuracy: 0.8526\n",
      "Epoch 642/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4453 - accuracy: 0.8137 - val_loss: 0.4091 - val_accuracy: 0.8427\n",
      "Epoch 643/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4341 - accuracy: 0.8148 - val_loss: 0.3890 - val_accuracy: 0.8526\n",
      "Epoch 644/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4282 - accuracy: 0.8187 - val_loss: 0.3742 - val_accuracy: 0.8657\n",
      "Epoch 645/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4386 - accuracy: 0.8154 - val_loss: 0.3907 - val_accuracy: 0.8499\n",
      "Epoch 646/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4486 - accuracy: 0.8061 - val_loss: 0.3910 - val_accuracy: 0.8513\n",
      "Epoch 647/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4365 - accuracy: 0.8121 - val_loss: 0.3874 - val_accuracy: 0.8526\n",
      "Epoch 648/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4385 - accuracy: 0.8133 - val_loss: 0.3795 - val_accuracy: 0.8549\n",
      "Epoch 649/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4471 - accuracy: 0.8087 - val_loss: 0.4157 - val_accuracy: 0.8377\n",
      "Epoch 650/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4347 - accuracy: 0.8183 - val_loss: 0.4056 - val_accuracy: 0.8465\n",
      "Epoch 651/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4370 - accuracy: 0.8160 - val_loss: 0.3911 - val_accuracy: 0.8479\n",
      "Epoch 652/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4349 - accuracy: 0.8163 - val_loss: 0.3927 - val_accuracy: 0.8510\n",
      "Epoch 653/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4415 - accuracy: 0.8140 - val_loss: 0.3954 - val_accuracy: 0.8492\n",
      "Epoch 654/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4457 - accuracy: 0.8097 - val_loss: 0.3918 - val_accuracy: 0.8599\n",
      "Epoch 655/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4359 - accuracy: 0.8161 - val_loss: 0.3959 - val_accuracy: 0.8501\n",
      "Epoch 656/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4478 - accuracy: 0.8117 - val_loss: 0.4118 - val_accuracy: 0.8397\n",
      "Epoch 657/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4452 - accuracy: 0.8063 - val_loss: 0.3941 - val_accuracy: 0.8522\n",
      "Epoch 658/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4501 - accuracy: 0.8061 - val_loss: 0.4242 - val_accuracy: 0.8331\n",
      "Epoch 659/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4438 - accuracy: 0.8123 - val_loss: 0.4164 - val_accuracy: 0.8494\n",
      "Epoch 660/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4414 - accuracy: 0.8136 - val_loss: 0.3901 - val_accuracy: 0.8576\n",
      "Epoch 661/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4366 - accuracy: 0.8166 - val_loss: 0.3944 - val_accuracy: 0.8547\n",
      "Epoch 662/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4359 - accuracy: 0.8145 - val_loss: 0.3819 - val_accuracy: 0.8578\n",
      "Epoch 663/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4333 - accuracy: 0.8164 - val_loss: 0.3942 - val_accuracy: 0.8565\n",
      "Epoch 664/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4340 - accuracy: 0.8192 - val_loss: 0.3895 - val_accuracy: 0.8558\n",
      "Epoch 665/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4230 - accuracy: 0.8161 - val_loss: 0.4018 - val_accuracy: 0.8460\n",
      "Epoch 666/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4375 - accuracy: 0.8169 - val_loss: 0.3950 - val_accuracy: 0.8524\n",
      "Epoch 667/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4425 - accuracy: 0.8094 - val_loss: 0.3866 - val_accuracy: 0.8540\n",
      "Epoch 668/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4409 - accuracy: 0.8111 - val_loss: 0.4031 - val_accuracy: 0.8451\n",
      "Epoch 669/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4474 - accuracy: 0.8082 - val_loss: 0.4257 - val_accuracy: 0.8390\n",
      "Epoch 670/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4292 - accuracy: 0.8212 - val_loss: 0.3750 - val_accuracy: 0.8644\n",
      "Epoch 671/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4327 - accuracy: 0.8201 - val_loss: 0.3921 - val_accuracy: 0.8524\n",
      "Epoch 672/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4336 - accuracy: 0.8181 - val_loss: 0.3869 - val_accuracy: 0.8542\n",
      "Epoch 673/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4398 - accuracy: 0.8135 - val_loss: 0.4001 - val_accuracy: 0.8492\n",
      "Epoch 674/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4451 - accuracy: 0.8092 - val_loss: 0.4022 - val_accuracy: 0.8449\n",
      "Epoch 675/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.4341 - accuracy: 0.8125 - val_loss: 0.3918 - val_accuracy: 0.8565\n",
      "Epoch 676/1500\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.4364 - accuracy: 0.8154 - val_loss: 0.3909 - val_accuracy: 0.8556\n",
      "Epoch 677/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4347 - accuracy: 0.8143 - val_loss: 0.3856 - val_accuracy: 0.8517\n",
      "Epoch 678/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4407 - accuracy: 0.8107 - val_loss: 0.3858 - val_accuracy: 0.8599\n",
      "Epoch 679/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4416 - accuracy: 0.8123 - val_loss: 0.3957 - val_accuracy: 0.8490\n",
      "Epoch 680/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4404 - accuracy: 0.8143 - val_loss: 0.3941 - val_accuracy: 0.8501\n",
      "Epoch 681/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4362 - accuracy: 0.8128 - val_loss: 0.3970 - val_accuracy: 0.8472\n",
      "Epoch 682/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4316 - accuracy: 0.8161 - val_loss: 0.4119 - val_accuracy: 0.8374\n",
      "Epoch 683/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4284 - accuracy: 0.8203 - val_loss: 0.3837 - val_accuracy: 0.8567\n",
      "Epoch 684/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4346 - accuracy: 0.8195 - val_loss: 0.3968 - val_accuracy: 0.8524\n",
      "Epoch 685/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4442 - accuracy: 0.8080 - val_loss: 0.4047 - val_accuracy: 0.8470\n",
      "Epoch 686/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4324 - accuracy: 0.8185 - val_loss: 0.4140 - val_accuracy: 0.8442\n",
      "Epoch 687/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4312 - accuracy: 0.8158 - val_loss: 0.3858 - val_accuracy: 0.8569\n",
      "Epoch 688/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4248 - accuracy: 0.8199 - val_loss: 0.4008 - val_accuracy: 0.8476\n",
      "Epoch 689/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4482 - accuracy: 0.8119 - val_loss: 0.4151 - val_accuracy: 0.8494\n",
      "Epoch 690/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4338 - accuracy: 0.8166 - val_loss: 0.3908 - val_accuracy: 0.8535\n",
      "Epoch 691/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4385 - accuracy: 0.8140 - val_loss: 0.3990 - val_accuracy: 0.8528\n",
      "Epoch 692/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4337 - accuracy: 0.8179 - val_loss: 0.4119 - val_accuracy: 0.8424\n",
      "Epoch 693/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4449 - accuracy: 0.8111 - val_loss: 0.3843 - val_accuracy: 0.8583\n",
      "Epoch 694/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4346 - accuracy: 0.8134 - val_loss: 0.3835 - val_accuracy: 0.8585\n",
      "Epoch 695/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4353 - accuracy: 0.8159 - val_loss: 0.3961 - val_accuracy: 0.8562\n",
      "Epoch 696/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4362 - accuracy: 0.8156 - val_loss: 0.4088 - val_accuracy: 0.8456\n",
      "Epoch 697/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4286 - accuracy: 0.8202 - val_loss: 0.4124 - val_accuracy: 0.8456\n",
      "Epoch 698/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4417 - accuracy: 0.8135 - val_loss: 0.3890 - val_accuracy: 0.8562\n",
      "Epoch 699/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4372 - accuracy: 0.8163 - val_loss: 0.3929 - val_accuracy: 0.8497\n",
      "Epoch 700/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4292 - accuracy: 0.8142 - val_loss: 0.4178 - val_accuracy: 0.8386\n",
      "Epoch 701/1500\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 0.4334 - accuracy: 0.8175 - val_loss: 0.3825 - val_accuracy: 0.8594\n",
      "Epoch 702/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4333 - accuracy: 0.8145 - val_loss: 0.3918 - val_accuracy: 0.8540\n",
      "Epoch 703/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4258 - accuracy: 0.8211 - val_loss: 0.3739 - val_accuracy: 0.8651\n",
      "Epoch 704/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4296 - accuracy: 0.8200 - val_loss: 0.4015 - val_accuracy: 0.8526\n",
      "Epoch 705/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4439 - accuracy: 0.8084 - val_loss: 0.4391 - val_accuracy: 0.8270\n",
      "Epoch 706/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4340 - accuracy: 0.8163 - val_loss: 0.3980 - val_accuracy: 0.8494\n",
      "Epoch 707/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4328 - accuracy: 0.8171 - val_loss: 0.3990 - val_accuracy: 0.8517\n",
      "Epoch 708/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4391 - accuracy: 0.8132 - val_loss: 0.3853 - val_accuracy: 0.8605\n",
      "Epoch 709/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4388 - accuracy: 0.8138 - val_loss: 0.4187 - val_accuracy: 0.8329\n",
      "Epoch 710/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4354 - accuracy: 0.8141 - val_loss: 0.3987 - val_accuracy: 0.8497\n",
      "Epoch 711/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4342 - accuracy: 0.8169 - val_loss: 0.3987 - val_accuracy: 0.8442\n",
      "Epoch 712/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4423 - accuracy: 0.8119 - val_loss: 0.3982 - val_accuracy: 0.8513\n",
      "Epoch 713/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4290 - accuracy: 0.8191 - val_loss: 0.3952 - val_accuracy: 0.8433\n",
      "Epoch 714/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4342 - accuracy: 0.8158 - val_loss: 0.4088 - val_accuracy: 0.8399\n",
      "Epoch 715/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4412 - accuracy: 0.8146 - val_loss: 0.3996 - val_accuracy: 0.8524\n",
      "Epoch 716/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4369 - accuracy: 0.8130 - val_loss: 0.4216 - val_accuracy: 0.8309\n",
      "Epoch 717/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4273 - accuracy: 0.8182 - val_loss: 0.3751 - val_accuracy: 0.8592\n",
      "Epoch 718/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4255 - accuracy: 0.8233 - val_loss: 0.3792 - val_accuracy: 0.8626\n",
      "Epoch 719/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4282 - accuracy: 0.8130 - val_loss: 0.3939 - val_accuracy: 0.8506\n",
      "Epoch 720/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4354 - accuracy: 0.8215 - val_loss: 0.3982 - val_accuracy: 0.8497\n",
      "Epoch 721/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4356 - accuracy: 0.8156 - val_loss: 0.4024 - val_accuracy: 0.8528\n",
      "Epoch 722/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4273 - accuracy: 0.8176 - val_loss: 0.3750 - val_accuracy: 0.8576\n",
      "Epoch 723/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4405 - accuracy: 0.8094 - val_loss: 0.3744 - val_accuracy: 0.8630\n",
      "Epoch 724/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4324 - accuracy: 0.8164 - val_loss: 0.3971 - val_accuracy: 0.8533\n",
      "Epoch 725/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4264 - accuracy: 0.8152 - val_loss: 0.3793 - val_accuracy: 0.8537\n",
      "Epoch 726/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4274 - accuracy: 0.8199 - val_loss: 0.3975 - val_accuracy: 0.8526\n",
      "Epoch 727/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4217 - accuracy: 0.8234 - val_loss: 0.3764 - val_accuracy: 0.8621\n",
      "Epoch 728/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4285 - accuracy: 0.8182 - val_loss: 0.3766 - val_accuracy: 0.8642\n",
      "Epoch 729/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4204 - accuracy: 0.8265 - val_loss: 0.3933 - val_accuracy: 0.8522\n",
      "Epoch 730/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4243 - accuracy: 0.8207 - val_loss: 0.3686 - val_accuracy: 0.8628\n",
      "Epoch 731/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4312 - accuracy: 0.8158 - val_loss: 0.3953 - val_accuracy: 0.8506\n",
      "Epoch 732/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4274 - accuracy: 0.8188 - val_loss: 0.4024 - val_accuracy: 0.8485\n",
      "Epoch 733/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4269 - accuracy: 0.8195 - val_loss: 0.3795 - val_accuracy: 0.8583\n",
      "Epoch 734/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4363 - accuracy: 0.8170 - val_loss: 0.4035 - val_accuracy: 0.8451\n",
      "Epoch 735/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4335 - accuracy: 0.8146 - val_loss: 0.3907 - val_accuracy: 0.8547\n",
      "Epoch 736/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4314 - accuracy: 0.8222 - val_loss: 0.3968 - val_accuracy: 0.8513\n",
      "Epoch 737/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4307 - accuracy: 0.8178 - val_loss: 0.3953 - val_accuracy: 0.8531\n",
      "Epoch 738/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8215 - val_loss: 0.4028 - val_accuracy: 0.8494\n",
      "Epoch 739/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4376 - accuracy: 0.8147 - val_loss: 0.3908 - val_accuracy: 0.8547\n",
      "Epoch 740/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4243 - accuracy: 0.8225 - val_loss: 0.3636 - val_accuracy: 0.8662\n",
      "Epoch 741/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4198 - accuracy: 0.8251 - val_loss: 0.3755 - val_accuracy: 0.8601\n",
      "Epoch 742/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4354 - accuracy: 0.8113 - val_loss: 0.3806 - val_accuracy: 0.8608\n",
      "Epoch 743/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4318 - accuracy: 0.8165 - val_loss: 0.3899 - val_accuracy: 0.8565\n",
      "Epoch 744/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4330 - accuracy: 0.8141 - val_loss: 0.3867 - val_accuracy: 0.8542\n",
      "Epoch 745/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4308 - accuracy: 0.8166 - val_loss: 0.3872 - val_accuracy: 0.8562\n",
      "Epoch 746/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4205 - accuracy: 0.8232 - val_loss: 0.3856 - val_accuracy: 0.8558\n",
      "Epoch 747/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4322 - accuracy: 0.8144 - val_loss: 0.3949 - val_accuracy: 0.8553\n",
      "Epoch 748/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4373 - accuracy: 0.8149 - val_loss: 0.3904 - val_accuracy: 0.8519\n",
      "Epoch 749/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4361 - accuracy: 0.8149 - val_loss: 0.3801 - val_accuracy: 0.8569\n",
      "Epoch 750/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4298 - accuracy: 0.8185 - val_loss: 0.3805 - val_accuracy: 0.8594\n",
      "Epoch 751/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4317 - accuracy: 0.8141 - val_loss: 0.3924 - val_accuracy: 0.8492\n",
      "Epoch 752/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4219 - accuracy: 0.8237 - val_loss: 0.3773 - val_accuracy: 0.8580\n",
      "Epoch 753/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4293 - accuracy: 0.8208 - val_loss: 0.3866 - val_accuracy: 0.8544\n",
      "Epoch 754/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4239 - accuracy: 0.8236 - val_loss: 0.3896 - val_accuracy: 0.8601\n",
      "Epoch 755/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4321 - accuracy: 0.8184 - val_loss: 0.3830 - val_accuracy: 0.8560\n",
      "Epoch 756/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4248 - accuracy: 0.8188 - val_loss: 0.3659 - val_accuracy: 0.8651\n",
      "Epoch 757/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4277 - accuracy: 0.8191 - val_loss: 0.3993 - val_accuracy: 0.8451\n",
      "Epoch 758/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4303 - accuracy: 0.8200 - val_loss: 0.3869 - val_accuracy: 0.8549\n",
      "Epoch 759/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.8226 - val_loss: 0.3987 - val_accuracy: 0.8474\n",
      "Epoch 760/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4319 - accuracy: 0.8194 - val_loss: 0.3885 - val_accuracy: 0.8558\n",
      "Epoch 761/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4259 - accuracy: 0.8201 - val_loss: 0.3952 - val_accuracy: 0.8499\n",
      "Epoch 762/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4209 - accuracy: 0.8224 - val_loss: 0.3778 - val_accuracy: 0.8594\n",
      "Epoch 763/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4235 - accuracy: 0.8217 - val_loss: 0.3836 - val_accuracy: 0.8540\n",
      "Epoch 764/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4437 - accuracy: 0.8136 - val_loss: 0.3967 - val_accuracy: 0.8504\n",
      "Epoch 765/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4237 - accuracy: 0.8233 - val_loss: 0.4049 - val_accuracy: 0.8438\n",
      "Epoch 766/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4281 - accuracy: 0.8185 - val_loss: 0.3815 - val_accuracy: 0.8599\n",
      "Epoch 767/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4172 - accuracy: 0.8274 - val_loss: 0.3826 - val_accuracy: 0.8547\n",
      "Epoch 768/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4217 - accuracy: 0.8261 - val_loss: 0.3836 - val_accuracy: 0.8537\n",
      "Epoch 769/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4213 - accuracy: 0.8241 - val_loss: 0.3847 - val_accuracy: 0.8562\n",
      "Epoch 770/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4296 - accuracy: 0.8192 - val_loss: 0.3794 - val_accuracy: 0.8664\n",
      "Epoch 771/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4352 - accuracy: 0.8150 - val_loss: 0.3851 - val_accuracy: 0.8540\n",
      "Epoch 772/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4209 - accuracy: 0.8247 - val_loss: 0.3751 - val_accuracy: 0.8664\n",
      "Epoch 773/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4326 - accuracy: 0.8156 - val_loss: 0.3800 - val_accuracy: 0.8578\n",
      "Epoch 774/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4301 - accuracy: 0.8209 - val_loss: 0.3992 - val_accuracy: 0.8506\n",
      "Epoch 775/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4292 - accuracy: 0.8177 - val_loss: 0.3786 - val_accuracy: 0.8608\n",
      "Epoch 776/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4179 - accuracy: 0.8261 - val_loss: 0.3729 - val_accuracy: 0.8621\n",
      "Epoch 777/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4219 - accuracy: 0.8240 - val_loss: 0.3901 - val_accuracy: 0.8531\n",
      "Epoch 778/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4247 - accuracy: 0.8221 - val_loss: 0.3727 - val_accuracy: 0.8603\n",
      "Epoch 779/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4340 - accuracy: 0.8179 - val_loss: 0.3721 - val_accuracy: 0.8651\n",
      "Epoch 780/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4211 - accuracy: 0.8194 - val_loss: 0.3858 - val_accuracy: 0.8533\n",
      "Epoch 781/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4279 - accuracy: 0.8193 - val_loss: 0.3838 - val_accuracy: 0.8601\n",
      "Epoch 782/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4290 - accuracy: 0.8179 - val_loss: 0.3952 - val_accuracy: 0.8492\n",
      "Epoch 783/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4219 - accuracy: 0.8254 - val_loss: 0.3770 - val_accuracy: 0.8662\n",
      "Epoch 784/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4188 - accuracy: 0.8261 - val_loss: 0.3789 - val_accuracy: 0.8583\n",
      "Epoch 785/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4451 - accuracy: 0.8129 - val_loss: 0.3749 - val_accuracy: 0.8580\n",
      "Epoch 786/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4375 - accuracy: 0.8158 - val_loss: 0.3723 - val_accuracy: 0.8623\n",
      "Epoch 787/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4391 - accuracy: 0.8110 - val_loss: 0.3921 - val_accuracy: 0.8490\n",
      "Epoch 788/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4228 - accuracy: 0.8202 - val_loss: 0.3740 - val_accuracy: 0.8626\n",
      "Epoch 789/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4069 - accuracy: 0.8246 - val_loss: 0.4121 - val_accuracy: 0.8456\n",
      "Epoch 790/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.8209 - val_loss: 0.3860 - val_accuracy: 0.8596\n",
      "Epoch 791/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4332 - accuracy: 0.8131 - val_loss: 0.3775 - val_accuracy: 0.8642\n",
      "Epoch 792/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4203 - accuracy: 0.8178 - val_loss: 0.3881 - val_accuracy: 0.8590\n",
      "Epoch 793/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4319 - accuracy: 0.8155 - val_loss: 0.3608 - val_accuracy: 0.8682\n",
      "Epoch 794/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4210 - accuracy: 0.8229 - val_loss: 0.3869 - val_accuracy: 0.8571\n",
      "Epoch 795/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4264 - accuracy: 0.8149 - val_loss: 0.3954 - val_accuracy: 0.8472\n",
      "Epoch 796/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4217 - accuracy: 0.8224 - val_loss: 0.3733 - val_accuracy: 0.8603\n",
      "Epoch 797/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4226 - accuracy: 0.8197 - val_loss: 0.3691 - val_accuracy: 0.8605\n",
      "Epoch 798/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4258 - accuracy: 0.8212 - val_loss: 0.3726 - val_accuracy: 0.8583\n",
      "Epoch 799/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4208 - accuracy: 0.8216 - val_loss: 0.3646 - val_accuracy: 0.8644\n",
      "Epoch 800/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4212 - accuracy: 0.8208 - val_loss: 0.3880 - val_accuracy: 0.8547\n",
      "Epoch 801/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4200 - accuracy: 0.8215 - val_loss: 0.3734 - val_accuracy: 0.8617\n",
      "Epoch 802/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4364 - accuracy: 0.8144 - val_loss: 0.3817 - val_accuracy: 0.8585\n",
      "Epoch 803/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4311 - accuracy: 0.8159 - val_loss: 0.3769 - val_accuracy: 0.8605\n",
      "Epoch 804/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4293 - accuracy: 0.8204 - val_loss: 0.3577 - val_accuracy: 0.8730\n",
      "Epoch 805/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8254 - val_loss: 0.3714 - val_accuracy: 0.8653\n",
      "Epoch 806/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4214 - accuracy: 0.8227 - val_loss: 0.3801 - val_accuracy: 0.8603\n",
      "Epoch 807/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4281 - accuracy: 0.8141 - val_loss: 0.3709 - val_accuracy: 0.8617\n",
      "Epoch 808/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4298 - accuracy: 0.8224 - val_loss: 0.3650 - val_accuracy: 0.8678\n",
      "Epoch 809/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4213 - accuracy: 0.8211 - val_loss: 0.3842 - val_accuracy: 0.8492\n",
      "Epoch 810/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4425 - accuracy: 0.8129 - val_loss: 0.3673 - val_accuracy: 0.8676\n",
      "Epoch 811/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4227 - accuracy: 0.8213 - val_loss: 0.3594 - val_accuracy: 0.8691\n",
      "Epoch 812/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4270 - accuracy: 0.8188 - val_loss: 0.3764 - val_accuracy: 0.8621\n",
      "Epoch 813/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4188 - accuracy: 0.8232 - val_loss: 0.3819 - val_accuracy: 0.8571\n",
      "Epoch 814/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4181 - accuracy: 0.8264 - val_loss: 0.3654 - val_accuracy: 0.8655\n",
      "Epoch 815/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4234 - accuracy: 0.8243 - val_loss: 0.3644 - val_accuracy: 0.8660\n",
      "Epoch 816/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4105 - accuracy: 0.8275 - val_loss: 0.3552 - val_accuracy: 0.8739\n",
      "Epoch 817/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4256 - accuracy: 0.8223 - val_loss: 0.3724 - val_accuracy: 0.8657\n",
      "Epoch 818/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4187 - accuracy: 0.8221 - val_loss: 0.3751 - val_accuracy: 0.8599\n",
      "Epoch 819/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4292 - accuracy: 0.8173 - val_loss: 0.3604 - val_accuracy: 0.8703\n",
      "Epoch 820/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4288 - accuracy: 0.8190 - val_loss: 0.3921 - val_accuracy: 0.8565\n",
      "Epoch 821/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4277 - accuracy: 0.8211 - val_loss: 0.3621 - val_accuracy: 0.8671\n",
      "Epoch 822/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4145 - accuracy: 0.8237 - val_loss: 0.3868 - val_accuracy: 0.8580\n",
      "Epoch 823/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4184 - accuracy: 0.8230 - val_loss: 0.3829 - val_accuracy: 0.8567\n",
      "Epoch 824/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4172 - accuracy: 0.8228 - val_loss: 0.3719 - val_accuracy: 0.8646\n",
      "Epoch 825/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4156 - accuracy: 0.8238 - val_loss: 0.3790 - val_accuracy: 0.8655\n",
      "Epoch 826/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4224 - accuracy: 0.8244 - val_loss: 0.3726 - val_accuracy: 0.8569\n",
      "Epoch 827/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4261 - accuracy: 0.8209 - val_loss: 0.3753 - val_accuracy: 0.8662\n",
      "Epoch 828/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4121 - accuracy: 0.8233 - val_loss: 0.3712 - val_accuracy: 0.8648\n",
      "Epoch 829/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4195 - accuracy: 0.8209 - val_loss: 0.3705 - val_accuracy: 0.8660\n",
      "Epoch 830/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4204 - accuracy: 0.8195 - val_loss: 0.3850 - val_accuracy: 0.8594\n",
      "Epoch 831/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4140 - accuracy: 0.8244 - val_loss: 0.3847 - val_accuracy: 0.8574\n",
      "Epoch 832/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4232 - accuracy: 0.8215 - val_loss: 0.3846 - val_accuracy: 0.8614\n",
      "Epoch 833/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4291 - accuracy: 0.8174 - val_loss: 0.3920 - val_accuracy: 0.8565\n",
      "Epoch 834/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4208 - accuracy: 0.8233 - val_loss: 0.3557 - val_accuracy: 0.8689\n",
      "Epoch 835/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4169 - accuracy: 0.8269 - val_loss: 0.3920 - val_accuracy: 0.8547\n",
      "Epoch 836/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4256 - accuracy: 0.8203 - val_loss: 0.4025 - val_accuracy: 0.8433\n",
      "Epoch 837/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4181 - accuracy: 0.8219 - val_loss: 0.3787 - val_accuracy: 0.8583\n",
      "Epoch 838/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4364 - accuracy: 0.8174 - val_loss: 0.3737 - val_accuracy: 0.8635\n",
      "Epoch 839/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4241 - accuracy: 0.8180 - val_loss: 0.3766 - val_accuracy: 0.8617\n",
      "Epoch 840/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4147 - accuracy: 0.8254 - val_loss: 0.3836 - val_accuracy: 0.8537\n",
      "Epoch 841/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.8189 - val_loss: 0.3827 - val_accuracy: 0.8551\n",
      "Epoch 842/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4172 - accuracy: 0.8222 - val_loss: 0.4027 - val_accuracy: 0.8451\n",
      "Epoch 843/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4259 - accuracy: 0.8204 - val_loss: 0.3819 - val_accuracy: 0.8657\n",
      "Epoch 844/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4274 - accuracy: 0.8222 - val_loss: 0.3842 - val_accuracy: 0.8585\n",
      "Epoch 845/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4078 - accuracy: 0.8300 - val_loss: 0.3618 - val_accuracy: 0.8721\n",
      "Epoch 846/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4146 - accuracy: 0.8236 - val_loss: 0.3862 - val_accuracy: 0.8569\n",
      "Epoch 847/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4187 - accuracy: 0.8252 - val_loss: 0.3713 - val_accuracy: 0.8653\n",
      "Epoch 848/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4201 - accuracy: 0.8253 - val_loss: 0.3676 - val_accuracy: 0.8646\n",
      "Epoch 849/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4141 - accuracy: 0.8262 - val_loss: 0.3765 - val_accuracy: 0.8571\n",
      "Epoch 850/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4234 - accuracy: 0.8226 - val_loss: 0.3721 - val_accuracy: 0.8685\n",
      "Epoch 851/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4230 - accuracy: 0.8240 - val_loss: 0.3759 - val_accuracy: 0.8630\n",
      "Epoch 852/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4127 - accuracy: 0.8289 - val_loss: 0.3647 - val_accuracy: 0.8619\n",
      "Epoch 853/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4211 - accuracy: 0.8231 - val_loss: 0.3549 - val_accuracy: 0.8714\n",
      "Epoch 854/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4328 - accuracy: 0.8180 - val_loss: 0.3708 - val_accuracy: 0.8612\n",
      "Epoch 855/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4123 - accuracy: 0.8265 - val_loss: 0.3786 - val_accuracy: 0.8576\n",
      "Epoch 856/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4264 - accuracy: 0.8210 - val_loss: 0.3841 - val_accuracy: 0.8594\n",
      "Epoch 857/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4189 - accuracy: 0.8226 - val_loss: 0.3883 - val_accuracy: 0.8510\n",
      "Epoch 858/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4135 - accuracy: 0.8299 - val_loss: 0.3806 - val_accuracy: 0.8571\n",
      "Epoch 859/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4266 - accuracy: 0.8158 - val_loss: 0.3687 - val_accuracy: 0.8685\n",
      "Epoch 860/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4090 - accuracy: 0.8301 - val_loss: 0.3705 - val_accuracy: 0.8639\n",
      "Epoch 861/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8223 - val_loss: 0.3746 - val_accuracy: 0.8594\n",
      "Epoch 862/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4307 - accuracy: 0.8144 - val_loss: 0.3581 - val_accuracy: 0.8730\n",
      "Epoch 863/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4257 - accuracy: 0.8202 - val_loss: 0.3750 - val_accuracy: 0.8576\n",
      "Epoch 864/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4232 - accuracy: 0.8226 - val_loss: 0.3871 - val_accuracy: 0.8508\n",
      "Epoch 865/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4264 - accuracy: 0.8216 - val_loss: 0.3717 - val_accuracy: 0.8630\n",
      "Epoch 866/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4169 - accuracy: 0.8265 - val_loss: 0.3702 - val_accuracy: 0.8617\n",
      "Epoch 867/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4155 - accuracy: 0.8251 - val_loss: 0.3719 - val_accuracy: 0.8592\n",
      "Epoch 868/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4339 - accuracy: 0.8180 - val_loss: 0.3752 - val_accuracy: 0.8617\n",
      "Epoch 869/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4183 - accuracy: 0.8225 - val_loss: 0.3598 - val_accuracy: 0.8707\n",
      "Epoch 870/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4221 - accuracy: 0.8218 - val_loss: 0.3722 - val_accuracy: 0.8610\n",
      "Epoch 871/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4163 - accuracy: 0.8229 - val_loss: 0.3874 - val_accuracy: 0.8565\n",
      "Epoch 872/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4125 - accuracy: 0.8270 - val_loss: 0.3869 - val_accuracy: 0.8630\n",
      "Epoch 873/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4154 - accuracy: 0.8263 - val_loss: 0.3682 - val_accuracy: 0.8639\n",
      "Epoch 874/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4187 - accuracy: 0.8252 - val_loss: 0.3661 - val_accuracy: 0.8664\n",
      "Epoch 875/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4201 - accuracy: 0.8243 - val_loss: 0.3592 - val_accuracy: 0.8653\n",
      "Epoch 876/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4156 - accuracy: 0.8270 - val_loss: 0.3782 - val_accuracy: 0.8556\n",
      "Epoch 877/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4206 - accuracy: 0.8233 - val_loss: 0.3732 - val_accuracy: 0.8578\n",
      "Epoch 878/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4179 - accuracy: 0.8286 - val_loss: 0.3601 - val_accuracy: 0.8710\n",
      "Epoch 879/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4051 - accuracy: 0.8310 - val_loss: 0.3571 - val_accuracy: 0.8710\n",
      "Epoch 880/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4154 - accuracy: 0.8235 - val_loss: 0.3614 - val_accuracy: 0.8696\n",
      "Epoch 881/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4195 - accuracy: 0.8259 - val_loss: 0.3659 - val_accuracy: 0.8583\n",
      "Epoch 882/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4168 - accuracy: 0.8267 - val_loss: 0.3540 - val_accuracy: 0.8746\n",
      "Epoch 883/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4143 - accuracy: 0.8246 - val_loss: 0.3692 - val_accuracy: 0.8673\n",
      "Epoch 884/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4051 - accuracy: 0.8293 - val_loss: 0.3684 - val_accuracy: 0.8646\n",
      "Epoch 885/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4043 - accuracy: 0.8330 - val_loss: 0.3706 - val_accuracy: 0.8605\n",
      "Epoch 886/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4093 - accuracy: 0.8285 - val_loss: 0.3819 - val_accuracy: 0.8540\n",
      "Epoch 887/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4201 - accuracy: 0.8287 - val_loss: 0.3642 - val_accuracy: 0.8676\n",
      "Epoch 888/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8340 - val_loss: 0.3707 - val_accuracy: 0.8623\n",
      "Epoch 889/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4057 - accuracy: 0.8323 - val_loss: 0.3670 - val_accuracy: 0.8657\n",
      "Epoch 890/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4204 - accuracy: 0.8253 - val_loss: 0.4090 - val_accuracy: 0.8368\n",
      "Epoch 891/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4119 - accuracy: 0.8272 - val_loss: 0.3927 - val_accuracy: 0.8463\n",
      "Epoch 892/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4202 - accuracy: 0.8233 - val_loss: 0.3671 - val_accuracy: 0.8608\n",
      "Epoch 893/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4204 - accuracy: 0.8230 - val_loss: 0.3827 - val_accuracy: 0.8590\n",
      "Epoch 894/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4186 - accuracy: 0.8232 - val_loss: 0.3708 - val_accuracy: 0.8585\n",
      "Epoch 895/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4084 - accuracy: 0.8294 - val_loss: 0.3588 - val_accuracy: 0.8682\n",
      "Epoch 896/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4209 - accuracy: 0.8264 - val_loss: 0.3777 - val_accuracy: 0.8644\n",
      "Epoch 897/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4172 - accuracy: 0.8244 - val_loss: 0.3731 - val_accuracy: 0.8594\n",
      "Epoch 898/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4140 - accuracy: 0.8249 - val_loss: 0.3726 - val_accuracy: 0.8642\n",
      "Epoch 899/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4268 - accuracy: 0.8209 - val_loss: 0.3601 - val_accuracy: 0.8678\n",
      "Epoch 900/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4199 - accuracy: 0.8228 - val_loss: 0.3571 - val_accuracy: 0.8712\n",
      "Epoch 901/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4087 - accuracy: 0.8240 - val_loss: 0.3723 - val_accuracy: 0.8676\n",
      "Epoch 902/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4153 - accuracy: 0.8212 - val_loss: 0.3664 - val_accuracy: 0.8698\n",
      "Epoch 903/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4138 - accuracy: 0.8226 - val_loss: 0.3752 - val_accuracy: 0.8592\n",
      "Epoch 904/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4146 - accuracy: 0.8225 - val_loss: 0.3655 - val_accuracy: 0.8694\n",
      "Epoch 905/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4198 - accuracy: 0.8222 - val_loss: 0.3739 - val_accuracy: 0.8617\n",
      "Epoch 906/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4247 - accuracy: 0.8188 - val_loss: 0.3936 - val_accuracy: 0.8542\n",
      "Epoch 907/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4116 - accuracy: 0.8297 - val_loss: 0.3442 - val_accuracy: 0.8818\n",
      "Epoch 908/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8327 - val_loss: 0.3754 - val_accuracy: 0.8635\n",
      "Epoch 909/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4217 - accuracy: 0.8183 - val_loss: 0.3708 - val_accuracy: 0.8608\n",
      "Epoch 910/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4025 - accuracy: 0.8314 - val_loss: 0.3639 - val_accuracy: 0.8673\n",
      "Epoch 911/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4085 - accuracy: 0.8260 - val_loss: 0.3707 - val_accuracy: 0.8669\n",
      "Epoch 912/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4208 - accuracy: 0.8210 - val_loss: 0.3664 - val_accuracy: 0.8694\n",
      "Epoch 913/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4140 - accuracy: 0.8287 - val_loss: 0.3711 - val_accuracy: 0.8614\n",
      "Epoch 914/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4147 - accuracy: 0.8250 - val_loss: 0.3569 - val_accuracy: 0.8676\n",
      "Epoch 915/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4171 - accuracy: 0.8249 - val_loss: 0.3749 - val_accuracy: 0.8558\n",
      "Epoch 916/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4110 - accuracy: 0.8278 - val_loss: 0.3596 - val_accuracy: 0.8669\n",
      "Epoch 917/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4210 - accuracy: 0.8259 - val_loss: 0.3565 - val_accuracy: 0.8737\n",
      "Epoch 918/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4060 - accuracy: 0.8233 - val_loss: 0.3619 - val_accuracy: 0.8671\n",
      "Epoch 919/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4137 - accuracy: 0.8235 - val_loss: 0.3712 - val_accuracy: 0.8653\n",
      "Epoch 920/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4105 - accuracy: 0.8252 - val_loss: 0.3731 - val_accuracy: 0.8669\n",
      "Epoch 921/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4261 - accuracy: 0.8200 - val_loss: 0.3715 - val_accuracy: 0.8601\n",
      "Epoch 922/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4309 - accuracy: 0.8194 - val_loss: 0.3653 - val_accuracy: 0.8644\n",
      "Epoch 923/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4064 - accuracy: 0.8216 - val_loss: 0.3760 - val_accuracy: 0.8601\n",
      "Epoch 924/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4109 - accuracy: 0.8323 - val_loss: 0.3717 - val_accuracy: 0.8596\n",
      "Epoch 925/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4033 - accuracy: 0.8350 - val_loss: 0.3612 - val_accuracy: 0.8655\n",
      "Epoch 926/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4167 - accuracy: 0.8289 - val_loss: 0.3697 - val_accuracy: 0.8619\n",
      "Epoch 927/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4156 - accuracy: 0.8265 - val_loss: 0.3659 - val_accuracy: 0.8628\n",
      "Epoch 928/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4209 - accuracy: 0.8189 - val_loss: 0.3712 - val_accuracy: 0.8621\n",
      "Epoch 929/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4180 - accuracy: 0.8213 - val_loss: 0.3725 - val_accuracy: 0.8612\n",
      "Epoch 930/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4143 - accuracy: 0.8242 - val_loss: 0.3616 - val_accuracy: 0.8680\n",
      "Epoch 931/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4095 - accuracy: 0.8310 - val_loss: 0.3712 - val_accuracy: 0.8619\n",
      "Epoch 932/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4115 - accuracy: 0.8272 - val_loss: 0.3738 - val_accuracy: 0.8680\n",
      "Epoch 933/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4183 - accuracy: 0.8237 - val_loss: 0.3516 - val_accuracy: 0.8714\n",
      "Epoch 934/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4223 - accuracy: 0.8207 - val_loss: 0.3685 - val_accuracy: 0.8689\n",
      "Epoch 935/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4032 - accuracy: 0.8303 - val_loss: 0.3705 - val_accuracy: 0.8687\n",
      "Epoch 936/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8291 - val_loss: 0.3598 - val_accuracy: 0.8732\n",
      "Epoch 937/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8288 - val_loss: 0.3653 - val_accuracy: 0.8691\n",
      "Epoch 938/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4156 - accuracy: 0.8270 - val_loss: 0.3557 - val_accuracy: 0.8766\n",
      "Epoch 939/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4188 - accuracy: 0.8247 - val_loss: 0.3804 - val_accuracy: 0.8562\n",
      "Epoch 940/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4161 - accuracy: 0.8247 - val_loss: 0.3503 - val_accuracy: 0.8780\n",
      "Epoch 941/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4148 - accuracy: 0.8276 - val_loss: 0.3610 - val_accuracy: 0.8700\n",
      "Epoch 942/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4145 - accuracy: 0.8272 - val_loss: 0.3556 - val_accuracy: 0.8728\n",
      "Epoch 943/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4070 - accuracy: 0.8283 - val_loss: 0.3885 - val_accuracy: 0.8526\n",
      "Epoch 944/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4150 - accuracy: 0.8249 - val_loss: 0.3738 - val_accuracy: 0.8639\n",
      "Epoch 945/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4281 - accuracy: 0.8188 - val_loss: 0.3762 - val_accuracy: 0.8610\n",
      "Epoch 946/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4090 - accuracy: 0.8301 - val_loss: 0.3611 - val_accuracy: 0.8712\n",
      "Epoch 947/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8313 - val_loss: 0.3712 - val_accuracy: 0.8703\n",
      "Epoch 948/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4000 - accuracy: 0.8330 - val_loss: 0.3544 - val_accuracy: 0.8728\n",
      "Epoch 949/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4114 - accuracy: 0.8289 - val_loss: 0.3587 - val_accuracy: 0.8698\n",
      "Epoch 950/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4304 - accuracy: 0.8173 - val_loss: 0.3593 - val_accuracy: 0.8705\n",
      "Epoch 951/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4182 - accuracy: 0.8254 - val_loss: 0.3704 - val_accuracy: 0.8648\n",
      "Epoch 952/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4212 - accuracy: 0.8228 - val_loss: 0.3490 - val_accuracy: 0.8743\n",
      "Epoch 953/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8252 - val_loss: 0.3675 - val_accuracy: 0.8685\n",
      "Epoch 954/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4133 - accuracy: 0.8258 - val_loss: 0.3815 - val_accuracy: 0.8592\n",
      "Epoch 955/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4212 - accuracy: 0.8212 - val_loss: 0.3587 - val_accuracy: 0.8719\n",
      "Epoch 956/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4119 - accuracy: 0.8275 - val_loss: 0.3639 - val_accuracy: 0.8676\n",
      "Epoch 957/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8353 - val_loss: 0.3605 - val_accuracy: 0.8705\n",
      "Epoch 958/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4064 - accuracy: 0.8338 - val_loss: 0.3626 - val_accuracy: 0.8623\n",
      "Epoch 959/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4157 - accuracy: 0.8281 - val_loss: 0.3422 - val_accuracy: 0.8811\n",
      "Epoch 960/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4154 - accuracy: 0.8252 - val_loss: 0.3682 - val_accuracy: 0.8662\n",
      "Epoch 961/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4094 - accuracy: 0.8259 - val_loss: 0.3586 - val_accuracy: 0.8669\n",
      "Epoch 962/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4063 - accuracy: 0.8310 - val_loss: 0.3622 - val_accuracy: 0.8750\n",
      "Epoch 963/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4199 - accuracy: 0.8218 - val_loss: 0.3563 - val_accuracy: 0.8737\n",
      "Epoch 964/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3978 - accuracy: 0.8351 - val_loss: 0.3674 - val_accuracy: 0.8655\n",
      "Epoch 965/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4084 - accuracy: 0.8245 - val_loss: 0.3512 - val_accuracy: 0.8698\n",
      "Epoch 966/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4103 - accuracy: 0.8296 - val_loss: 0.3659 - val_accuracy: 0.8623\n",
      "Epoch 967/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4131 - accuracy: 0.8289 - val_loss: 0.3735 - val_accuracy: 0.8633\n",
      "Epoch 968/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4050 - accuracy: 0.8272 - val_loss: 0.3864 - val_accuracy: 0.8528\n",
      "Epoch 969/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4114 - accuracy: 0.8252 - val_loss: 0.3759 - val_accuracy: 0.8628\n",
      "Epoch 970/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4073 - accuracy: 0.8308 - val_loss: 0.3642 - val_accuracy: 0.8700\n",
      "Epoch 971/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4171 - accuracy: 0.8217 - val_loss: 0.3526 - val_accuracy: 0.8746\n",
      "Epoch 972/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4154 - accuracy: 0.8235 - val_loss: 0.3713 - val_accuracy: 0.8594\n",
      "Epoch 973/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4084 - accuracy: 0.8289 - val_loss: 0.3696 - val_accuracy: 0.8608\n",
      "Epoch 974/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4147 - accuracy: 0.8282 - val_loss: 0.3619 - val_accuracy: 0.8676\n",
      "Epoch 975/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4043 - accuracy: 0.8292 - val_loss: 0.3548 - val_accuracy: 0.8773\n",
      "Epoch 976/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4193 - accuracy: 0.8212 - val_loss: 0.3646 - val_accuracy: 0.8669\n",
      "Epoch 977/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4060 - accuracy: 0.8283 - val_loss: 0.3504 - val_accuracy: 0.8750\n",
      "Epoch 978/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4046 - accuracy: 0.8300 - val_loss: 0.3534 - val_accuracy: 0.8698\n",
      "Epoch 979/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4074 - accuracy: 0.8327 - val_loss: 0.3576 - val_accuracy: 0.8714\n",
      "Epoch 980/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4101 - accuracy: 0.8274 - val_loss: 0.3506 - val_accuracy: 0.8743\n",
      "Epoch 981/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4039 - accuracy: 0.8274 - val_loss: 0.3616 - val_accuracy: 0.8685\n",
      "Epoch 982/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4166 - accuracy: 0.8252 - val_loss: 0.3584 - val_accuracy: 0.8687\n",
      "Epoch 983/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4147 - accuracy: 0.8294 - val_loss: 0.3733 - val_accuracy: 0.8630\n",
      "Epoch 984/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4129 - accuracy: 0.8254 - val_loss: 0.3696 - val_accuracy: 0.8682\n",
      "Epoch 985/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4226 - accuracy: 0.8210 - val_loss: 0.3617 - val_accuracy: 0.8682\n",
      "Epoch 986/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4006 - accuracy: 0.8318 - val_loss: 0.4052 - val_accuracy: 0.8379\n",
      "Epoch 987/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4137 - accuracy: 0.8300 - val_loss: 0.3831 - val_accuracy: 0.8585\n",
      "Epoch 988/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4163 - accuracy: 0.8269 - val_loss: 0.3812 - val_accuracy: 0.8533\n",
      "Epoch 989/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4088 - accuracy: 0.8312 - val_loss: 0.3538 - val_accuracy: 0.8694\n",
      "Epoch 990/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4183 - accuracy: 0.8200 - val_loss: 0.3605 - val_accuracy: 0.8642\n",
      "Epoch 991/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4110 - accuracy: 0.8283 - val_loss: 0.3595 - val_accuracy: 0.8660\n",
      "Epoch 992/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4023 - accuracy: 0.8306 - val_loss: 0.3642 - val_accuracy: 0.8642\n",
      "Epoch 993/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4083 - accuracy: 0.8279 - val_loss: 0.3844 - val_accuracy: 0.8567\n",
      "Epoch 994/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4195 - accuracy: 0.8222 - val_loss: 0.3503 - val_accuracy: 0.8730\n",
      "Epoch 995/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4029 - accuracy: 0.8323 - val_loss: 0.3747 - val_accuracy: 0.8623\n",
      "Epoch 996/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4119 - accuracy: 0.8285 - val_loss: 0.3771 - val_accuracy: 0.8610\n",
      "Epoch 997/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4154 - accuracy: 0.8245 - val_loss: 0.3574 - val_accuracy: 0.8719\n",
      "Epoch 998/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4137 - accuracy: 0.8256 - val_loss: 0.3592 - val_accuracy: 0.8725\n",
      "Epoch 999/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4045 - accuracy: 0.8327 - val_loss: 0.3634 - val_accuracy: 0.8669\n",
      "Epoch 1000/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4056 - accuracy: 0.8284 - val_loss: 0.3675 - val_accuracy: 0.8637\n",
      "Epoch 1001/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4084 - accuracy: 0.8290 - val_loss: 0.3483 - val_accuracy: 0.8796\n",
      "Epoch 1002/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4151 - accuracy: 0.8292 - val_loss: 0.3645 - val_accuracy: 0.8723\n",
      "Epoch 1003/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4148 - accuracy: 0.8225 - val_loss: 0.3385 - val_accuracy: 0.8807\n",
      "Epoch 1004/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4141 - accuracy: 0.8273 - val_loss: 0.3520 - val_accuracy: 0.8732\n",
      "Epoch 1005/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4080 - accuracy: 0.8309 - val_loss: 0.3740 - val_accuracy: 0.8596\n",
      "Epoch 1006/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4085 - accuracy: 0.8282 - val_loss: 0.3500 - val_accuracy: 0.8743\n",
      "Epoch 1007/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3976 - accuracy: 0.8319 - val_loss: 0.3452 - val_accuracy: 0.8759\n",
      "Epoch 1008/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4169 - accuracy: 0.8243 - val_loss: 0.3755 - val_accuracy: 0.8653\n",
      "Epoch 1009/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4096 - accuracy: 0.8282 - val_loss: 0.3657 - val_accuracy: 0.8678\n",
      "Epoch 1010/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4077 - accuracy: 0.8264 - val_loss: 0.3620 - val_accuracy: 0.8698\n",
      "Epoch 1011/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4051 - accuracy: 0.8304 - val_loss: 0.3544 - val_accuracy: 0.8746\n",
      "Epoch 1012/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4233 - accuracy: 0.8227 - val_loss: 0.3502 - val_accuracy: 0.8757\n",
      "Epoch 1013/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4095 - accuracy: 0.8274 - val_loss: 0.3550 - val_accuracy: 0.8716\n",
      "Epoch 1014/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4062 - accuracy: 0.8321 - val_loss: 0.3569 - val_accuracy: 0.8716\n",
      "Epoch 1015/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4073 - accuracy: 0.8287 - val_loss: 0.3513 - val_accuracy: 0.8723\n",
      "Epoch 1016/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4045 - accuracy: 0.8280 - val_loss: 0.3429 - val_accuracy: 0.8798\n",
      "Epoch 1017/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4029 - accuracy: 0.8316 - val_loss: 0.3481 - val_accuracy: 0.8782\n",
      "Epoch 1018/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4121 - accuracy: 0.8232 - val_loss: 0.3566 - val_accuracy: 0.8680\n",
      "Epoch 1019/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3917 - accuracy: 0.8352 - val_loss: 0.3659 - val_accuracy: 0.8662\n",
      "Epoch 1020/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4030 - accuracy: 0.8299 - val_loss: 0.3636 - val_accuracy: 0.8651\n",
      "Epoch 1021/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4166 - accuracy: 0.8227 - val_loss: 0.3701 - val_accuracy: 0.8587\n",
      "Epoch 1022/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4143 - accuracy: 0.8262 - val_loss: 0.3606 - val_accuracy: 0.8687\n",
      "Epoch 1023/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4166 - accuracy: 0.8253 - val_loss: 0.3460 - val_accuracy: 0.8780\n",
      "Epoch 1024/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4213 - accuracy: 0.8232 - val_loss: 0.3548 - val_accuracy: 0.8732\n",
      "Epoch 1025/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4157 - accuracy: 0.8281 - val_loss: 0.3546 - val_accuracy: 0.8698\n",
      "Epoch 1026/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3864 - accuracy: 0.8383 - val_loss: 0.3570 - val_accuracy: 0.8662\n",
      "Epoch 1027/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4022 - accuracy: 0.8277 - val_loss: 0.3583 - val_accuracy: 0.8676\n",
      "Epoch 1028/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8300 - val_loss: 0.3638 - val_accuracy: 0.8678\n",
      "Epoch 1029/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4104 - accuracy: 0.8322 - val_loss: 0.3483 - val_accuracy: 0.8703\n",
      "Epoch 1030/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8272 - val_loss: 0.3799 - val_accuracy: 0.8585\n",
      "Epoch 1031/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4179 - accuracy: 0.8260 - val_loss: 0.3547 - val_accuracy: 0.8714\n",
      "Epoch 1032/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8261 - val_loss: 0.3520 - val_accuracy: 0.8734\n",
      "Epoch 1033/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4085 - accuracy: 0.8262 - val_loss: 0.3546 - val_accuracy: 0.8689\n",
      "Epoch 1034/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4042 - accuracy: 0.8299 - val_loss: 0.3699 - val_accuracy: 0.8664\n",
      "Epoch 1035/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4121 - accuracy: 0.8270 - val_loss: 0.3538 - val_accuracy: 0.8705\n",
      "Epoch 1036/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4070 - accuracy: 0.8293 - val_loss: 0.3484 - val_accuracy: 0.8746\n",
      "Epoch 1037/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4085 - accuracy: 0.8286 - val_loss: 0.3502 - val_accuracy: 0.8748\n",
      "Epoch 1038/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3990 - accuracy: 0.8311 - val_loss: 0.3576 - val_accuracy: 0.8694\n",
      "Epoch 1039/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4151 - accuracy: 0.8224 - val_loss: 0.3476 - val_accuracy: 0.8759\n",
      "Epoch 1040/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8324 - val_loss: 0.3462 - val_accuracy: 0.8796\n",
      "Epoch 1041/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4118 - accuracy: 0.8232 - val_loss: 0.3435 - val_accuracy: 0.8816\n",
      "Epoch 1042/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4074 - accuracy: 0.8300 - val_loss: 0.3399 - val_accuracy: 0.8764\n",
      "Epoch 1043/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4140 - accuracy: 0.8285 - val_loss: 0.3524 - val_accuracy: 0.8725\n",
      "Epoch 1044/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4121 - accuracy: 0.8222 - val_loss: 0.3531 - val_accuracy: 0.8712\n",
      "Epoch 1045/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4031 - accuracy: 0.8309 - val_loss: 0.3497 - val_accuracy: 0.8721\n",
      "Epoch 1046/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4051 - accuracy: 0.8306 - val_loss: 0.3456 - val_accuracy: 0.8737\n",
      "Epoch 1047/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.8229 - val_loss: 0.3509 - val_accuracy: 0.8757\n",
      "Epoch 1048/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4129 - accuracy: 0.8283 - val_loss: 0.3321 - val_accuracy: 0.8809\n",
      "Epoch 1049/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4124 - accuracy: 0.8272 - val_loss: 0.3585 - val_accuracy: 0.8664\n",
      "Epoch 1050/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4019 - accuracy: 0.8340 - val_loss: 0.3633 - val_accuracy: 0.8687\n",
      "Epoch 1051/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4258 - accuracy: 0.8233 - val_loss: 0.3595 - val_accuracy: 0.8680\n",
      "Epoch 1052/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4058 - accuracy: 0.8303 - val_loss: 0.3406 - val_accuracy: 0.8802\n",
      "Epoch 1053/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4025 - accuracy: 0.8312 - val_loss: 0.3438 - val_accuracy: 0.8759\n",
      "Epoch 1054/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3985 - accuracy: 0.8323 - val_loss: 0.3497 - val_accuracy: 0.8762\n",
      "Epoch 1055/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4068 - accuracy: 0.8262 - val_loss: 0.3621 - val_accuracy: 0.8705\n",
      "Epoch 1056/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.8335 - val_loss: 0.3580 - val_accuracy: 0.8716\n",
      "Epoch 1057/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4205 - accuracy: 0.8288 - val_loss: 0.3641 - val_accuracy: 0.8723\n",
      "Epoch 1058/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4087 - accuracy: 0.8265 - val_loss: 0.3408 - val_accuracy: 0.8782\n",
      "Epoch 1059/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4103 - accuracy: 0.8282 - val_loss: 0.3614 - val_accuracy: 0.8716\n",
      "Epoch 1060/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4184 - accuracy: 0.8234 - val_loss: 0.3392 - val_accuracy: 0.8839\n",
      "Epoch 1061/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4026 - accuracy: 0.8270 - val_loss: 0.3380 - val_accuracy: 0.8782\n",
      "Epoch 1062/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4118 - accuracy: 0.8309 - val_loss: 0.3475 - val_accuracy: 0.8705\n",
      "Epoch 1063/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4085 - accuracy: 0.8298 - val_loss: 0.3703 - val_accuracy: 0.8626\n",
      "Epoch 1064/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8308 - val_loss: 0.3549 - val_accuracy: 0.8712\n",
      "Epoch 1065/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3927 - accuracy: 0.8338 - val_loss: 0.3522 - val_accuracy: 0.8707\n",
      "Epoch 1066/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4187 - accuracy: 0.8277 - val_loss: 0.3496 - val_accuracy: 0.8762\n",
      "Epoch 1067/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4046 - accuracy: 0.8316 - val_loss: 0.3473 - val_accuracy: 0.8721\n",
      "Epoch 1068/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3957 - accuracy: 0.8350 - val_loss: 0.3473 - val_accuracy: 0.8714\n",
      "Epoch 1069/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3907 - accuracy: 0.8354 - val_loss: 0.3329 - val_accuracy: 0.8845\n",
      "Epoch 1070/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8322 - val_loss: 0.3491 - val_accuracy: 0.8746\n",
      "Epoch 1071/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4081 - accuracy: 0.8244 - val_loss: 0.3576 - val_accuracy: 0.8682\n",
      "Epoch 1072/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4020 - accuracy: 0.8324 - val_loss: 0.3811 - val_accuracy: 0.8565\n",
      "Epoch 1073/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4008 - accuracy: 0.8301 - val_loss: 0.3510 - val_accuracy: 0.8748\n",
      "Epoch 1074/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3980 - accuracy: 0.8320 - val_loss: 0.3689 - val_accuracy: 0.8667\n",
      "Epoch 1075/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4103 - accuracy: 0.8268 - val_loss: 0.3684 - val_accuracy: 0.8678\n",
      "Epoch 1076/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4039 - accuracy: 0.8290 - val_loss: 0.3490 - val_accuracy: 0.8789\n",
      "Epoch 1077/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3957 - accuracy: 0.8304 - val_loss: 0.3713 - val_accuracy: 0.8716\n",
      "Epoch 1078/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4067 - accuracy: 0.8289 - val_loss: 0.3446 - val_accuracy: 0.8814\n",
      "Epoch 1079/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3977 - accuracy: 0.8302 - val_loss: 0.3572 - val_accuracy: 0.8723\n",
      "Epoch 1080/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4119 - accuracy: 0.8274 - val_loss: 0.3502 - val_accuracy: 0.8739\n",
      "Epoch 1081/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4039 - accuracy: 0.8321 - val_loss: 0.3660 - val_accuracy: 0.8685\n",
      "Epoch 1082/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3962 - accuracy: 0.8303 - val_loss: 0.3483 - val_accuracy: 0.8710\n",
      "Epoch 1083/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4076 - accuracy: 0.8253 - val_loss: 0.3433 - val_accuracy: 0.8737\n",
      "Epoch 1084/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4057 - accuracy: 0.8278 - val_loss: 0.3591 - val_accuracy: 0.8687\n",
      "Epoch 1085/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4214 - accuracy: 0.8234 - val_loss: 0.3473 - val_accuracy: 0.8712\n",
      "Epoch 1086/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3927 - accuracy: 0.8370 - val_loss: 0.3481 - val_accuracy: 0.8728\n",
      "Epoch 1087/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3946 - accuracy: 0.8349 - val_loss: 0.3579 - val_accuracy: 0.8667\n",
      "Epoch 1088/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4012 - accuracy: 0.8345 - val_loss: 0.3414 - val_accuracy: 0.8789\n",
      "Epoch 1089/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4069 - accuracy: 0.8322 - val_loss: 0.3629 - val_accuracy: 0.8664\n",
      "Epoch 1090/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3981 - accuracy: 0.8334 - val_loss: 0.3540 - val_accuracy: 0.8696\n",
      "Epoch 1091/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4035 - accuracy: 0.8290 - val_loss: 0.3439 - val_accuracy: 0.8759\n",
      "Epoch 1092/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3933 - accuracy: 0.8370 - val_loss: 0.3572 - val_accuracy: 0.8673\n",
      "Epoch 1093/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4080 - accuracy: 0.8288 - val_loss: 0.3467 - val_accuracy: 0.8789\n",
      "Epoch 1094/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4138 - accuracy: 0.8275 - val_loss: 0.3493 - val_accuracy: 0.8719\n",
      "Epoch 1095/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3968 - accuracy: 0.8369 - val_loss: 0.3512 - val_accuracy: 0.8703\n",
      "Epoch 1096/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3979 - accuracy: 0.8337 - val_loss: 0.3369 - val_accuracy: 0.8800\n",
      "Epoch 1097/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4066 - accuracy: 0.8273 - val_loss: 0.3880 - val_accuracy: 0.8528\n",
      "Epoch 1098/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3951 - accuracy: 0.8360 - val_loss: 0.3630 - val_accuracy: 0.8687\n",
      "Epoch 1099/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8338 - val_loss: 0.3524 - val_accuracy: 0.8737\n",
      "Epoch 1100/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8320 - val_loss: 0.3556 - val_accuracy: 0.8710\n",
      "Epoch 1101/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4138 - accuracy: 0.8276 - val_loss: 0.3411 - val_accuracy: 0.8789\n",
      "Epoch 1102/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4077 - accuracy: 0.8274 - val_loss: 0.3534 - val_accuracy: 0.8721\n",
      "Epoch 1103/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4128 - accuracy: 0.8265 - val_loss: 0.3541 - val_accuracy: 0.8696\n",
      "Epoch 1104/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3987 - accuracy: 0.8280 - val_loss: 0.3705 - val_accuracy: 0.8648\n",
      "Epoch 1105/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4108 - accuracy: 0.8237 - val_loss: 0.3500 - val_accuracy: 0.8787\n",
      "Epoch 1106/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3986 - accuracy: 0.8320 - val_loss: 0.3557 - val_accuracy: 0.8719\n",
      "Epoch 1107/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8341 - val_loss: 0.3660 - val_accuracy: 0.8691\n",
      "Epoch 1108/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4006 - accuracy: 0.8320 - val_loss: 0.3401 - val_accuracy: 0.8773\n",
      "Epoch 1109/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4110 - accuracy: 0.8295 - val_loss: 0.3285 - val_accuracy: 0.8843\n",
      "Epoch 1110/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4044 - accuracy: 0.8311 - val_loss: 0.3375 - val_accuracy: 0.8798\n",
      "Epoch 1111/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3954 - accuracy: 0.8343 - val_loss: 0.3461 - val_accuracy: 0.8750\n",
      "Epoch 1112/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3995 - accuracy: 0.8306 - val_loss: 0.3587 - val_accuracy: 0.8737\n",
      "Epoch 1113/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8320 - val_loss: 0.3569 - val_accuracy: 0.8621\n",
      "Epoch 1114/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8353 - val_loss: 0.3421 - val_accuracy: 0.8780\n",
      "Epoch 1115/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3970 - accuracy: 0.8346 - val_loss: 0.3632 - val_accuracy: 0.8676\n",
      "Epoch 1116/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3998 - accuracy: 0.8316 - val_loss: 0.3399 - val_accuracy: 0.8807\n",
      "Epoch 1117/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3934 - accuracy: 0.8345 - val_loss: 0.3411 - val_accuracy: 0.8811\n",
      "Epoch 1118/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3891 - accuracy: 0.8401 - val_loss: 0.3533 - val_accuracy: 0.8725\n",
      "Epoch 1119/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4098 - accuracy: 0.8277 - val_loss: 0.3527 - val_accuracy: 0.8698\n",
      "Epoch 1120/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3913 - accuracy: 0.8351 - val_loss: 0.3439 - val_accuracy: 0.8782\n",
      "Epoch 1121/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8296 - val_loss: 0.3310 - val_accuracy: 0.8877\n",
      "Epoch 1122/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4113 - accuracy: 0.8256 - val_loss: 0.3488 - val_accuracy: 0.8759\n",
      "Epoch 1123/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3918 - accuracy: 0.8380 - val_loss: 0.3539 - val_accuracy: 0.8716\n",
      "Epoch 1124/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4008 - accuracy: 0.8272 - val_loss: 0.3449 - val_accuracy: 0.8782\n",
      "Epoch 1125/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4061 - accuracy: 0.8296 - val_loss: 0.3458 - val_accuracy: 0.8762\n",
      "Epoch 1126/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3993 - accuracy: 0.8328 - val_loss: 0.3394 - val_accuracy: 0.8798\n",
      "Epoch 1127/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4053 - accuracy: 0.8351 - val_loss: 0.3480 - val_accuracy: 0.8771\n",
      "Epoch 1128/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4015 - accuracy: 0.8295 - val_loss: 0.3529 - val_accuracy: 0.8714\n",
      "Epoch 1129/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4194 - accuracy: 0.8214 - val_loss: 0.3671 - val_accuracy: 0.8653\n",
      "Epoch 1130/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8312 - val_loss: 0.3505 - val_accuracy: 0.8719\n",
      "Epoch 1131/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3974 - accuracy: 0.8354 - val_loss: 0.3400 - val_accuracy: 0.8791\n",
      "Epoch 1132/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4066 - accuracy: 0.8262 - val_loss: 0.3431 - val_accuracy: 0.8775\n",
      "Epoch 1133/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4039 - accuracy: 0.8313 - val_loss: 0.3644 - val_accuracy: 0.8707\n",
      "Epoch 1134/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3897 - accuracy: 0.8368 - val_loss: 0.3378 - val_accuracy: 0.8780\n",
      "Epoch 1135/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4054 - accuracy: 0.8274 - val_loss: 0.3459 - val_accuracy: 0.8734\n",
      "Epoch 1136/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3835 - accuracy: 0.8411 - val_loss: 0.3574 - val_accuracy: 0.8669\n",
      "Epoch 1137/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3980 - accuracy: 0.8328 - val_loss: 0.3578 - val_accuracy: 0.8703\n",
      "Epoch 1138/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4037 - accuracy: 0.8271 - val_loss: 0.3738 - val_accuracy: 0.8610\n",
      "Epoch 1139/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3884 - accuracy: 0.8375 - val_loss: 0.3619 - val_accuracy: 0.8712\n",
      "Epoch 1140/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3993 - accuracy: 0.8312 - val_loss: 0.3607 - val_accuracy: 0.8655\n",
      "Epoch 1141/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8313 - val_loss: 0.3524 - val_accuracy: 0.8705\n",
      "Epoch 1142/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4067 - accuracy: 0.8333 - val_loss: 0.3663 - val_accuracy: 0.8642\n",
      "Epoch 1143/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4117 - accuracy: 0.8258 - val_loss: 0.3694 - val_accuracy: 0.8621\n",
      "Epoch 1144/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3970 - accuracy: 0.8360 - val_loss: 0.3496 - val_accuracy: 0.8698\n",
      "Epoch 1145/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4050 - accuracy: 0.8270 - val_loss: 0.3386 - val_accuracy: 0.8802\n",
      "Epoch 1146/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4042 - accuracy: 0.8277 - val_loss: 0.3432 - val_accuracy: 0.8773\n",
      "Epoch 1147/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4140 - accuracy: 0.8242 - val_loss: 0.3544 - val_accuracy: 0.8748\n",
      "Epoch 1148/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4109 - accuracy: 0.8260 - val_loss: 0.3524 - val_accuracy: 0.8687\n",
      "Epoch 1149/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3887 - accuracy: 0.8380 - val_loss: 0.3604 - val_accuracy: 0.8685\n",
      "Epoch 1150/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3903 - accuracy: 0.8315 - val_loss: 0.3509 - val_accuracy: 0.8757\n",
      "Epoch 1151/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4021 - accuracy: 0.8316 - val_loss: 0.3566 - val_accuracy: 0.8712\n",
      "Epoch 1152/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4096 - accuracy: 0.8252 - val_loss: 0.3503 - val_accuracy: 0.8723\n",
      "Epoch 1153/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3996 - accuracy: 0.8354 - val_loss: 0.3401 - val_accuracy: 0.8784\n",
      "Epoch 1154/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8357 - val_loss: 0.3413 - val_accuracy: 0.8764\n",
      "Epoch 1155/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4118 - accuracy: 0.8268 - val_loss: 0.3439 - val_accuracy: 0.8791\n",
      "Epoch 1156/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4024 - accuracy: 0.8298 - val_loss: 0.3398 - val_accuracy: 0.8777\n",
      "Epoch 1157/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8318 - val_loss: 0.3558 - val_accuracy: 0.8789\n",
      "Epoch 1158/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4090 - accuracy: 0.8286 - val_loss: 0.3443 - val_accuracy: 0.8725\n",
      "Epoch 1159/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3920 - accuracy: 0.8365 - val_loss: 0.3593 - val_accuracy: 0.8743\n",
      "Epoch 1160/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4008 - accuracy: 0.8290 - val_loss: 0.3375 - val_accuracy: 0.8789\n",
      "Epoch 1161/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4169 - accuracy: 0.8264 - val_loss: 0.3231 - val_accuracy: 0.8891\n",
      "Epoch 1162/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3955 - accuracy: 0.8336 - val_loss: 0.3591 - val_accuracy: 0.8671\n",
      "Epoch 1163/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.4047 - accuracy: 0.8316 - val_loss: 0.3339 - val_accuracy: 0.8825\n",
      "Epoch 1164/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4040 - accuracy: 0.8343 - val_loss: 0.3545 - val_accuracy: 0.8685\n",
      "Epoch 1165/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3958 - accuracy: 0.8345 - val_loss: 0.3475 - val_accuracy: 0.8732\n",
      "Epoch 1166/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4120 - accuracy: 0.8298 - val_loss: 0.3373 - val_accuracy: 0.8768\n",
      "Epoch 1167/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3915 - accuracy: 0.8350 - val_loss: 0.3534 - val_accuracy: 0.8768\n",
      "Epoch 1168/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3881 - accuracy: 0.8388 - val_loss: 0.3481 - val_accuracy: 0.8782\n",
      "Epoch 1169/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4120 - accuracy: 0.8266 - val_loss: 0.3602 - val_accuracy: 0.8712\n",
      "Epoch 1170/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4084 - accuracy: 0.8285 - val_loss: 0.3396 - val_accuracy: 0.8798\n",
      "Epoch 1171/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4082 - accuracy: 0.8296 - val_loss: 0.3359 - val_accuracy: 0.8796\n",
      "Epoch 1172/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4037 - accuracy: 0.8302 - val_loss: 0.3566 - val_accuracy: 0.8694\n",
      "Epoch 1173/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3883 - accuracy: 0.8364 - val_loss: 0.3454 - val_accuracy: 0.8734\n",
      "Epoch 1174/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3954 - accuracy: 0.8357 - val_loss: 0.3466 - val_accuracy: 0.8755\n",
      "Epoch 1175/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3930 - accuracy: 0.8348 - val_loss: 0.3502 - val_accuracy: 0.8737\n",
      "Epoch 1176/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3985 - accuracy: 0.8320 - val_loss: 0.3472 - val_accuracy: 0.8734\n",
      "Epoch 1177/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3868 - accuracy: 0.8399 - val_loss: 0.3409 - val_accuracy: 0.8750\n",
      "Epoch 1178/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3881 - accuracy: 0.8383 - val_loss: 0.3670 - val_accuracy: 0.8608\n",
      "Epoch 1179/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4083 - accuracy: 0.8277 - val_loss: 0.3557 - val_accuracy: 0.8759\n",
      "Epoch 1180/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4109 - accuracy: 0.8258 - val_loss: 0.3391 - val_accuracy: 0.8825\n",
      "Epoch 1181/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3985 - accuracy: 0.8343 - val_loss: 0.3536 - val_accuracy: 0.8710\n",
      "Epoch 1182/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3979 - accuracy: 0.8327 - val_loss: 0.3467 - val_accuracy: 0.8710\n",
      "Epoch 1183/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8360 - val_loss: 0.3400 - val_accuracy: 0.8798\n",
      "Epoch 1184/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4140 - accuracy: 0.8258 - val_loss: 0.3383 - val_accuracy: 0.8768\n",
      "Epoch 1185/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4004 - accuracy: 0.8326 - val_loss: 0.3388 - val_accuracy: 0.8730\n",
      "Epoch 1186/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3932 - accuracy: 0.8330 - val_loss: 0.3422 - val_accuracy: 0.8814\n",
      "Epoch 1187/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3988 - accuracy: 0.8289 - val_loss: 0.3431 - val_accuracy: 0.8771\n",
      "Epoch 1188/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4062 - accuracy: 0.8266 - val_loss: 0.3377 - val_accuracy: 0.8816\n",
      "Epoch 1189/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3988 - accuracy: 0.8347 - val_loss: 0.3461 - val_accuracy: 0.8730\n",
      "Epoch 1190/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3995 - accuracy: 0.8334 - val_loss: 0.3395 - val_accuracy: 0.8782\n",
      "Epoch 1191/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4032 - accuracy: 0.8330 - val_loss: 0.3494 - val_accuracy: 0.8723\n",
      "Epoch 1192/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3990 - accuracy: 0.8321 - val_loss: 0.3672 - val_accuracy: 0.8655\n",
      "Epoch 1193/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8321 - val_loss: 0.3431 - val_accuracy: 0.8739\n",
      "Epoch 1194/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3976 - accuracy: 0.8308 - val_loss: 0.3633 - val_accuracy: 0.8678\n",
      "Epoch 1195/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8326 - val_loss: 0.3655 - val_accuracy: 0.8667\n",
      "Epoch 1196/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3999 - accuracy: 0.8327 - val_loss: 0.3460 - val_accuracy: 0.8827\n",
      "Epoch 1197/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3903 - accuracy: 0.8331 - val_loss: 0.3327 - val_accuracy: 0.8800\n",
      "Epoch 1198/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4023 - accuracy: 0.8295 - val_loss: 0.3483 - val_accuracy: 0.8764\n",
      "Epoch 1199/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8317 - val_loss: 0.3533 - val_accuracy: 0.8642\n",
      "Epoch 1200/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3948 - accuracy: 0.8354 - val_loss: 0.3369 - val_accuracy: 0.8809\n",
      "Epoch 1201/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4051 - accuracy: 0.8312 - val_loss: 0.3398 - val_accuracy: 0.8782\n",
      "Epoch 1202/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4002 - accuracy: 0.8308 - val_loss: 0.3439 - val_accuracy: 0.8793\n",
      "Epoch 1203/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4083 - accuracy: 0.8283 - val_loss: 0.3521 - val_accuracy: 0.8685\n",
      "Epoch 1204/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8330 - val_loss: 0.3319 - val_accuracy: 0.8802\n",
      "Epoch 1205/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3983 - accuracy: 0.8327 - val_loss: 0.3656 - val_accuracy: 0.8601\n",
      "Epoch 1206/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8341 - val_loss: 0.3333 - val_accuracy: 0.8809\n",
      "Epoch 1207/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3914 - accuracy: 0.8374 - val_loss: 0.3257 - val_accuracy: 0.8857\n",
      "Epoch 1208/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4071 - accuracy: 0.8321 - val_loss: 0.3335 - val_accuracy: 0.8839\n",
      "Epoch 1209/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4080 - accuracy: 0.8274 - val_loss: 0.3357 - val_accuracy: 0.8843\n",
      "Epoch 1210/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8366 - val_loss: 0.3240 - val_accuracy: 0.8866\n",
      "Epoch 1211/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4003 - accuracy: 0.8308 - val_loss: 0.3502 - val_accuracy: 0.8762\n",
      "Epoch 1212/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3968 - accuracy: 0.8376 - val_loss: 0.3400 - val_accuracy: 0.8775\n",
      "Epoch 1213/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4104 - accuracy: 0.8269 - val_loss: 0.3441 - val_accuracy: 0.8768\n",
      "Epoch 1214/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3924 - accuracy: 0.8370 - val_loss: 0.3372 - val_accuracy: 0.8814\n",
      "Epoch 1215/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3910 - accuracy: 0.8378 - val_loss: 0.3552 - val_accuracy: 0.8721\n",
      "Epoch 1216/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3986 - accuracy: 0.8370 - val_loss: 0.3370 - val_accuracy: 0.8789\n",
      "Epoch 1217/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4084 - accuracy: 0.8258 - val_loss: 0.3344 - val_accuracy: 0.8787\n",
      "Epoch 1218/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3901 - accuracy: 0.8364 - val_loss: 0.3492 - val_accuracy: 0.8789\n",
      "Epoch 1219/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4026 - accuracy: 0.8305 - val_loss: 0.3385 - val_accuracy: 0.8807\n",
      "Epoch 1220/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4071 - accuracy: 0.8289 - val_loss: 0.3489 - val_accuracy: 0.8716\n",
      "Epoch 1221/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3996 - accuracy: 0.8346 - val_loss: 0.3350 - val_accuracy: 0.8809\n",
      "Epoch 1222/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4018 - accuracy: 0.8319 - val_loss: 0.3337 - val_accuracy: 0.8848\n",
      "Epoch 1223/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4042 - accuracy: 0.8286 - val_loss: 0.3386 - val_accuracy: 0.8753\n",
      "Epoch 1224/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3968 - accuracy: 0.8359 - val_loss: 0.3306 - val_accuracy: 0.8836\n",
      "Epoch 1225/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3921 - accuracy: 0.8404 - val_loss: 0.3388 - val_accuracy: 0.8827\n",
      "Epoch 1226/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3939 - accuracy: 0.8338 - val_loss: 0.3412 - val_accuracy: 0.8818\n",
      "Epoch 1227/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3999 - accuracy: 0.8302 - val_loss: 0.3523 - val_accuracy: 0.8691\n",
      "Epoch 1228/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4116 - accuracy: 0.8267 - val_loss: 0.3378 - val_accuracy: 0.8800\n",
      "Epoch 1229/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3991 - accuracy: 0.8310 - val_loss: 0.3400 - val_accuracy: 0.8802\n",
      "Epoch 1230/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4057 - accuracy: 0.8295 - val_loss: 0.3298 - val_accuracy: 0.8848\n",
      "Epoch 1231/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4038 - accuracy: 0.8305 - val_loss: 0.3458 - val_accuracy: 0.8748\n",
      "Epoch 1232/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4001 - accuracy: 0.8322 - val_loss: 0.3445 - val_accuracy: 0.8809\n",
      "Epoch 1233/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3922 - accuracy: 0.8347 - val_loss: 0.3316 - val_accuracy: 0.8818\n",
      "Epoch 1234/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3916 - accuracy: 0.8366 - val_loss: 0.3372 - val_accuracy: 0.8811\n",
      "Epoch 1235/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3916 - accuracy: 0.8328 - val_loss: 0.3374 - val_accuracy: 0.8757\n",
      "Epoch 1236/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4058 - accuracy: 0.8305 - val_loss: 0.3340 - val_accuracy: 0.8820\n",
      "Epoch 1237/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3945 - accuracy: 0.8337 - val_loss: 0.3551 - val_accuracy: 0.8730\n",
      "Epoch 1238/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3921 - accuracy: 0.8364 - val_loss: 0.3490 - val_accuracy: 0.8766\n",
      "Epoch 1239/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3935 - accuracy: 0.8323 - val_loss: 0.3452 - val_accuracy: 0.8777\n",
      "Epoch 1240/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3927 - accuracy: 0.8380 - val_loss: 0.3204 - val_accuracy: 0.8902\n",
      "Epoch 1241/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4074 - accuracy: 0.8288 - val_loss: 0.3428 - val_accuracy: 0.8852\n",
      "Epoch 1242/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8294 - val_loss: 0.3346 - val_accuracy: 0.8775\n",
      "Epoch 1243/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3978 - accuracy: 0.8343 - val_loss: 0.4027 - val_accuracy: 0.8433\n",
      "Epoch 1244/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4046 - accuracy: 0.8309 - val_loss: 0.3514 - val_accuracy: 0.8710\n",
      "Epoch 1245/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8368 - val_loss: 0.3209 - val_accuracy: 0.8891\n",
      "Epoch 1246/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3962 - accuracy: 0.8347 - val_loss: 0.3304 - val_accuracy: 0.8816\n",
      "Epoch 1247/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3927 - accuracy: 0.8391 - val_loss: 0.3354 - val_accuracy: 0.8823\n",
      "Epoch 1248/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3997 - accuracy: 0.8343 - val_loss: 0.3310 - val_accuracy: 0.8870\n",
      "Epoch 1249/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3939 - accuracy: 0.8371 - val_loss: 0.3402 - val_accuracy: 0.8832\n",
      "Epoch 1250/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3962 - accuracy: 0.8381 - val_loss: 0.3295 - val_accuracy: 0.8809\n",
      "Epoch 1251/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3961 - accuracy: 0.8347 - val_loss: 0.3347 - val_accuracy: 0.8859\n",
      "Epoch 1252/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3872 - accuracy: 0.8384 - val_loss: 0.3576 - val_accuracy: 0.8676\n",
      "Epoch 1253/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4069 - accuracy: 0.8274 - val_loss: 0.3381 - val_accuracy: 0.8791\n",
      "Epoch 1254/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3837 - accuracy: 0.8435 - val_loss: 0.3353 - val_accuracy: 0.8848\n",
      "Epoch 1255/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3884 - accuracy: 0.8361 - val_loss: 0.3525 - val_accuracy: 0.8712\n",
      "Epoch 1256/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3835 - accuracy: 0.8429 - val_loss: 0.3273 - val_accuracy: 0.8861\n",
      "Epoch 1257/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3957 - accuracy: 0.8368 - val_loss: 0.3422 - val_accuracy: 0.8766\n",
      "Epoch 1258/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4082 - accuracy: 0.8291 - val_loss: 0.3493 - val_accuracy: 0.8764\n",
      "Epoch 1259/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3944 - accuracy: 0.8368 - val_loss: 0.3444 - val_accuracy: 0.8789\n",
      "Epoch 1260/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3896 - accuracy: 0.8353 - val_loss: 0.3355 - val_accuracy: 0.8818\n",
      "Epoch 1261/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4008 - accuracy: 0.8314 - val_loss: 0.3338 - val_accuracy: 0.8839\n",
      "Epoch 1262/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3964 - accuracy: 0.8339 - val_loss: 0.3317 - val_accuracy: 0.8827\n",
      "Epoch 1263/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3946 - accuracy: 0.8365 - val_loss: 0.3225 - val_accuracy: 0.8884\n",
      "Epoch 1264/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3929 - accuracy: 0.8369 - val_loss: 0.3417 - val_accuracy: 0.8773\n",
      "Epoch 1265/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4025 - accuracy: 0.8272 - val_loss: 0.3363 - val_accuracy: 0.8789\n",
      "Epoch 1266/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3947 - accuracy: 0.8355 - val_loss: 0.3564 - val_accuracy: 0.8766\n",
      "Epoch 1267/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3971 - accuracy: 0.8355 - val_loss: 0.3447 - val_accuracy: 0.8753\n",
      "Epoch 1268/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3977 - accuracy: 0.8324 - val_loss: 0.3334 - val_accuracy: 0.8859\n",
      "Epoch 1269/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3927 - accuracy: 0.8382 - val_loss: 0.3384 - val_accuracy: 0.8807\n",
      "Epoch 1270/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3880 - accuracy: 0.8362 - val_loss: 0.3323 - val_accuracy: 0.8811\n",
      "Epoch 1271/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8300 - val_loss: 0.3333 - val_accuracy: 0.8809\n",
      "Epoch 1272/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.8318 - val_loss: 0.3443 - val_accuracy: 0.8753\n",
      "Epoch 1273/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3820 - accuracy: 0.8418 - val_loss: 0.3475 - val_accuracy: 0.8773\n",
      "Epoch 1274/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3887 - accuracy: 0.8361 - val_loss: 0.3299 - val_accuracy: 0.8870\n",
      "Epoch 1275/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3933 - accuracy: 0.8372 - val_loss: 0.3420 - val_accuracy: 0.8809\n",
      "Epoch 1276/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3926 - accuracy: 0.8342 - val_loss: 0.3402 - val_accuracy: 0.8777\n",
      "Epoch 1277/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8312 - val_loss: 0.3489 - val_accuracy: 0.8743\n",
      "Epoch 1278/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3952 - accuracy: 0.8286 - val_loss: 0.3416 - val_accuracy: 0.8793\n",
      "Epoch 1279/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3928 - accuracy: 0.8326 - val_loss: 0.3365 - val_accuracy: 0.8850\n",
      "Epoch 1280/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8336 - val_loss: 0.3382 - val_accuracy: 0.8848\n",
      "Epoch 1281/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4135 - accuracy: 0.8255 - val_loss: 0.3325 - val_accuracy: 0.8854\n",
      "Epoch 1282/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3872 - accuracy: 0.8389 - val_loss: 0.3299 - val_accuracy: 0.8850\n",
      "Epoch 1283/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3897 - accuracy: 0.8377 - val_loss: 0.3444 - val_accuracy: 0.8755\n",
      "Epoch 1284/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.8303 - val_loss: 0.3305 - val_accuracy: 0.8839\n",
      "Epoch 1285/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3850 - accuracy: 0.8347 - val_loss: 0.3339 - val_accuracy: 0.8868\n",
      "Epoch 1286/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3983 - accuracy: 0.8331 - val_loss: 0.3450 - val_accuracy: 0.8782\n",
      "Epoch 1287/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3980 - accuracy: 0.8314 - val_loss: 0.3273 - val_accuracy: 0.8863\n",
      "Epoch 1288/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8304 - val_loss: 0.3357 - val_accuracy: 0.8791\n",
      "Epoch 1289/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3994 - accuracy: 0.8309 - val_loss: 0.3331 - val_accuracy: 0.8850\n",
      "Epoch 1290/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3924 - accuracy: 0.8363 - val_loss: 0.3448 - val_accuracy: 0.8787\n",
      "Epoch 1291/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8266 - val_loss: 0.3570 - val_accuracy: 0.8730\n",
      "Epoch 1292/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3951 - accuracy: 0.8364 - val_loss: 0.3553 - val_accuracy: 0.8691\n",
      "Epoch 1293/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3870 - accuracy: 0.8395 - val_loss: 0.3459 - val_accuracy: 0.8777\n",
      "Epoch 1294/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3907 - accuracy: 0.8350 - val_loss: 0.3363 - val_accuracy: 0.8820\n",
      "Epoch 1295/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4028 - accuracy: 0.8347 - val_loss: 0.3405 - val_accuracy: 0.8775\n",
      "Epoch 1296/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3864 - accuracy: 0.8400 - val_loss: 0.3373 - val_accuracy: 0.8857\n",
      "Epoch 1297/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3925 - accuracy: 0.8366 - val_loss: 0.3369 - val_accuracy: 0.8805\n",
      "Epoch 1298/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8335 - val_loss: 0.3307 - val_accuracy: 0.8805\n",
      "Epoch 1299/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4041 - accuracy: 0.8310 - val_loss: 0.3238 - val_accuracy: 0.8877\n",
      "Epoch 1300/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4053 - accuracy: 0.8319 - val_loss: 0.3386 - val_accuracy: 0.8793\n",
      "Epoch 1301/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3830 - accuracy: 0.8430 - val_loss: 0.3365 - val_accuracy: 0.8818\n",
      "Epoch 1302/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3966 - accuracy: 0.8361 - val_loss: 0.3375 - val_accuracy: 0.8784\n",
      "Epoch 1303/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3857 - accuracy: 0.8415 - val_loss: 0.3274 - val_accuracy: 0.8857\n",
      "Epoch 1304/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3937 - accuracy: 0.8362 - val_loss: 0.3522 - val_accuracy: 0.8777\n",
      "Epoch 1305/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3914 - accuracy: 0.8377 - val_loss: 0.3344 - val_accuracy: 0.8791\n",
      "Epoch 1306/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3898 - accuracy: 0.8372 - val_loss: 0.3373 - val_accuracy: 0.8796\n",
      "Epoch 1307/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3877 - accuracy: 0.8388 - val_loss: 0.3342 - val_accuracy: 0.8825\n",
      "Epoch 1308/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3941 - accuracy: 0.8322 - val_loss: 0.3303 - val_accuracy: 0.8875\n",
      "Epoch 1309/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3844 - accuracy: 0.8401 - val_loss: 0.3473 - val_accuracy: 0.8775\n",
      "Epoch 1310/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3952 - accuracy: 0.8382 - val_loss: 0.3396 - val_accuracy: 0.8807\n",
      "Epoch 1311/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3869 - accuracy: 0.8379 - val_loss: 0.3340 - val_accuracy: 0.8857\n",
      "Epoch 1312/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3884 - accuracy: 0.8345 - val_loss: 0.3330 - val_accuracy: 0.8845\n",
      "Epoch 1313/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3953 - accuracy: 0.8311 - val_loss: 0.3637 - val_accuracy: 0.8639\n",
      "Epoch 1314/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3811 - accuracy: 0.8367 - val_loss: 0.3536 - val_accuracy: 0.8723\n",
      "Epoch 1315/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3928 - accuracy: 0.8368 - val_loss: 0.3489 - val_accuracy: 0.8746\n",
      "Epoch 1316/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4004 - accuracy: 0.8343 - val_loss: 0.3367 - val_accuracy: 0.8859\n",
      "Epoch 1317/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3969 - accuracy: 0.8355 - val_loss: 0.3409 - val_accuracy: 0.8753\n",
      "Epoch 1318/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3946 - accuracy: 0.8394 - val_loss: 0.3394 - val_accuracy: 0.8757\n",
      "Epoch 1319/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3980 - accuracy: 0.8361 - val_loss: 0.3294 - val_accuracy: 0.8825\n",
      "Epoch 1320/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3904 - accuracy: 0.8382 - val_loss: 0.3367 - val_accuracy: 0.8839\n",
      "Epoch 1321/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3775 - accuracy: 0.8445 - val_loss: 0.3349 - val_accuracy: 0.8820\n",
      "Epoch 1322/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3938 - accuracy: 0.8344 - val_loss: 0.3480 - val_accuracy: 0.8748\n",
      "Epoch 1323/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3978 - accuracy: 0.8342 - val_loss: 0.3259 - val_accuracy: 0.8841\n",
      "Epoch 1324/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3867 - accuracy: 0.8420 - val_loss: 0.3472 - val_accuracy: 0.8712\n",
      "Epoch 1325/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3884 - accuracy: 0.8337 - val_loss: 0.3206 - val_accuracy: 0.8884\n",
      "Epoch 1326/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3986 - accuracy: 0.8294 - val_loss: 0.3240 - val_accuracy: 0.8882\n",
      "Epoch 1327/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3969 - accuracy: 0.8390 - val_loss: 0.3403 - val_accuracy: 0.8796\n",
      "Epoch 1328/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3989 - accuracy: 0.8356 - val_loss: 0.3258 - val_accuracy: 0.8893\n",
      "Epoch 1329/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3906 - accuracy: 0.8351 - val_loss: 0.3330 - val_accuracy: 0.8845\n",
      "Epoch 1330/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8358 - val_loss: 0.3498 - val_accuracy: 0.8750\n",
      "Epoch 1331/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3999 - accuracy: 0.8342 - val_loss: 0.3159 - val_accuracy: 0.8920\n",
      "Epoch 1332/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8384 - val_loss: 0.3414 - val_accuracy: 0.8834\n",
      "Epoch 1333/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3921 - accuracy: 0.8341 - val_loss: 0.3417 - val_accuracy: 0.8773\n",
      "Epoch 1334/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3876 - accuracy: 0.8376 - val_loss: 0.3309 - val_accuracy: 0.8852\n",
      "Epoch 1335/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3926 - accuracy: 0.8358 - val_loss: 0.3482 - val_accuracy: 0.8739\n",
      "Epoch 1336/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8396 - val_loss: 0.3262 - val_accuracy: 0.8888\n",
      "Epoch 1337/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3954 - accuracy: 0.8346 - val_loss: 0.3327 - val_accuracy: 0.8891\n",
      "Epoch 1338/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4013 - accuracy: 0.8325 - val_loss: 0.3303 - val_accuracy: 0.8879\n",
      "Epoch 1339/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3929 - accuracy: 0.8365 - val_loss: 0.3189 - val_accuracy: 0.8920\n",
      "Epoch 1340/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3855 - accuracy: 0.8387 - val_loss: 0.3373 - val_accuracy: 0.8857\n",
      "Epoch 1341/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4042 - accuracy: 0.8314 - val_loss: 0.3281 - val_accuracy: 0.8879\n",
      "Epoch 1342/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3739 - accuracy: 0.8421 - val_loss: 0.3303 - val_accuracy: 0.8802\n",
      "Epoch 1343/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3842 - accuracy: 0.8404 - val_loss: 0.3433 - val_accuracy: 0.8782\n",
      "Epoch 1344/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4026 - accuracy: 0.8293 - val_loss: 0.3356 - val_accuracy: 0.8798\n",
      "Epoch 1345/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3923 - accuracy: 0.8374 - val_loss: 0.3396 - val_accuracy: 0.8741\n",
      "Epoch 1346/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8358 - val_loss: 0.3315 - val_accuracy: 0.8836\n",
      "Epoch 1347/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3813 - accuracy: 0.8414 - val_loss: 0.3356 - val_accuracy: 0.8773\n",
      "Epoch 1348/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3808 - accuracy: 0.8425 - val_loss: 0.3184 - val_accuracy: 0.8911\n",
      "Epoch 1349/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3765 - accuracy: 0.8474 - val_loss: 0.3229 - val_accuracy: 0.8900\n",
      "Epoch 1350/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3865 - accuracy: 0.8388 - val_loss: 0.3493 - val_accuracy: 0.8743\n",
      "Epoch 1351/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3924 - accuracy: 0.8363 - val_loss: 0.3214 - val_accuracy: 0.8897\n",
      "Epoch 1352/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3990 - accuracy: 0.8342 - val_loss: 0.3235 - val_accuracy: 0.8877\n",
      "Epoch 1353/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3867 - accuracy: 0.8396 - val_loss: 0.3393 - val_accuracy: 0.8809\n",
      "Epoch 1354/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3858 - accuracy: 0.8439 - val_loss: 0.3318 - val_accuracy: 0.8854\n",
      "Epoch 1355/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3846 - accuracy: 0.8370 - val_loss: 0.3252 - val_accuracy: 0.8897\n",
      "Epoch 1356/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3838 - accuracy: 0.8417 - val_loss: 0.3273 - val_accuracy: 0.8870\n",
      "Epoch 1357/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3908 - accuracy: 0.8363 - val_loss: 0.3479 - val_accuracy: 0.8730\n",
      "Epoch 1358/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3962 - accuracy: 0.8354 - val_loss: 0.3322 - val_accuracy: 0.8825\n",
      "Epoch 1359/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8357 - val_loss: 0.3324 - val_accuracy: 0.8850\n",
      "Epoch 1360/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3850 - accuracy: 0.8396 - val_loss: 0.3260 - val_accuracy: 0.8906\n",
      "Epoch 1361/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4029 - accuracy: 0.8348 - val_loss: 0.3245 - val_accuracy: 0.8861\n",
      "Epoch 1362/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.3190 - val_accuracy: 0.8827\n",
      "Epoch 1363/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8304 - val_loss: 0.3294 - val_accuracy: 0.8827\n",
      "Epoch 1364/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3972 - accuracy: 0.8357 - val_loss: 0.3311 - val_accuracy: 0.8827\n",
      "Epoch 1365/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3873 - accuracy: 0.8365 - val_loss: 0.3353 - val_accuracy: 0.8798\n",
      "Epoch 1366/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3955 - accuracy: 0.8365 - val_loss: 0.3245 - val_accuracy: 0.8879\n",
      "Epoch 1367/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3855 - accuracy: 0.8380 - val_loss: 0.3424 - val_accuracy: 0.8757\n",
      "Epoch 1368/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3862 - accuracy: 0.8412 - val_loss: 0.3278 - val_accuracy: 0.8873\n",
      "Epoch 1369/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3893 - accuracy: 0.8390 - val_loss: 0.3394 - val_accuracy: 0.8777\n",
      "Epoch 1370/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3948 - accuracy: 0.8316 - val_loss: 0.3236 - val_accuracy: 0.8886\n",
      "Epoch 1371/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3958 - accuracy: 0.8340 - val_loss: 0.3283 - val_accuracy: 0.8825\n",
      "Epoch 1372/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4024 - accuracy: 0.8324 - val_loss: 0.3251 - val_accuracy: 0.8841\n",
      "Epoch 1373/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3818 - accuracy: 0.8426 - val_loss: 0.3213 - val_accuracy: 0.8884\n",
      "Epoch 1374/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3856 - accuracy: 0.8386 - val_loss: 0.3286 - val_accuracy: 0.8870\n",
      "Epoch 1375/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3974 - accuracy: 0.8344 - val_loss: 0.3262 - val_accuracy: 0.8879\n",
      "Epoch 1376/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3802 - accuracy: 0.8393 - val_loss: 0.3469 - val_accuracy: 0.8721\n",
      "Epoch 1377/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3837 - accuracy: 0.8367 - val_loss: 0.3460 - val_accuracy: 0.8762\n",
      "Epoch 1378/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4013 - accuracy: 0.8313 - val_loss: 0.3382 - val_accuracy: 0.8820\n",
      "Epoch 1379/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3934 - accuracy: 0.8376 - val_loss: 0.3400 - val_accuracy: 0.8787\n",
      "Epoch 1380/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3884 - accuracy: 0.8379 - val_loss: 0.3471 - val_accuracy: 0.8716\n",
      "Epoch 1381/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4018 - accuracy: 0.8342 - val_loss: 0.3324 - val_accuracy: 0.8854\n",
      "Epoch 1382/1500\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4067 - accuracy: 0.8324 - val_loss: 0.3337 - val_accuracy: 0.8764\n",
      "Epoch 1383/1500\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3893 - accuracy: 0.8420 - val_loss: 0.3424 - val_accuracy: 0.8764\n",
      "Epoch 1384/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3945 - accuracy: 0.8337 - val_loss: 0.3449 - val_accuracy: 0.8791\n",
      "Epoch 1385/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3788 - accuracy: 0.8449 - val_loss: 0.3210 - val_accuracy: 0.8877\n",
      "Epoch 1386/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8422 - val_loss: 0.3309 - val_accuracy: 0.8805\n",
      "Epoch 1387/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3792 - accuracy: 0.8435 - val_loss: 0.3297 - val_accuracy: 0.8841\n",
      "Epoch 1388/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3930 - accuracy: 0.8350 - val_loss: 0.3393 - val_accuracy: 0.8805\n",
      "Epoch 1389/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3785 - accuracy: 0.8440 - val_loss: 0.3321 - val_accuracy: 0.8820\n",
      "Epoch 1390/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3840 - accuracy: 0.8402 - val_loss: 0.3346 - val_accuracy: 0.8809\n",
      "Epoch 1391/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3922 - accuracy: 0.8350 - val_loss: 0.3137 - val_accuracy: 0.8922\n",
      "Epoch 1392/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3880 - accuracy: 0.8379 - val_loss: 0.3282 - val_accuracy: 0.8897\n",
      "Epoch 1393/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3876 - accuracy: 0.8361 - val_loss: 0.3374 - val_accuracy: 0.8764\n",
      "Epoch 1394/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3945 - accuracy: 0.8386 - val_loss: 0.3450 - val_accuracy: 0.8719\n",
      "Epoch 1395/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3909 - accuracy: 0.8360 - val_loss: 0.3336 - val_accuracy: 0.8841\n",
      "Epoch 1396/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3983 - accuracy: 0.8320 - val_loss: 0.3358 - val_accuracy: 0.8825\n",
      "Epoch 1397/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3923 - accuracy: 0.8314 - val_loss: 0.3445 - val_accuracy: 0.8734\n",
      "Epoch 1398/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3859 - accuracy: 0.8374 - val_loss: 0.3327 - val_accuracy: 0.8782\n",
      "Epoch 1399/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3954 - accuracy: 0.8363 - val_loss: 0.3300 - val_accuracy: 0.8818\n",
      "Epoch 1400/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3879 - accuracy: 0.8384 - val_loss: 0.3320 - val_accuracy: 0.8818\n",
      "Epoch 1401/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3836 - accuracy: 0.8365 - val_loss: 0.3327 - val_accuracy: 0.8775\n",
      "Epoch 1402/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3794 - accuracy: 0.8424 - val_loss: 0.3253 - val_accuracy: 0.8834\n",
      "Epoch 1403/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3824 - accuracy: 0.8374 - val_loss: 0.3280 - val_accuracy: 0.8834\n",
      "Epoch 1404/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3901 - accuracy: 0.8371 - val_loss: 0.3441 - val_accuracy: 0.8762\n",
      "Epoch 1405/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3929 - accuracy: 0.8346 - val_loss: 0.3525 - val_accuracy: 0.8698\n",
      "Epoch 1406/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3855 - accuracy: 0.8389 - val_loss: 0.3344 - val_accuracy: 0.8854\n",
      "Epoch 1407/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3869 - accuracy: 0.8387 - val_loss: 0.3248 - val_accuracy: 0.8897\n",
      "Epoch 1408/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3827 - accuracy: 0.8407 - val_loss: 0.3491 - val_accuracy: 0.8753\n",
      "Epoch 1409/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3899 - accuracy: 0.8396 - val_loss: 0.3266 - val_accuracy: 0.8859\n",
      "Epoch 1410/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3730 - accuracy: 0.8454 - val_loss: 0.3342 - val_accuracy: 0.8771\n",
      "Epoch 1411/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3828 - accuracy: 0.8421 - val_loss: 0.3361 - val_accuracy: 0.8841\n",
      "Epoch 1412/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3871 - accuracy: 0.8399 - val_loss: 0.3356 - val_accuracy: 0.8805\n",
      "Epoch 1413/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3869 - accuracy: 0.8342 - val_loss: 0.3288 - val_accuracy: 0.8827\n",
      "Epoch 1414/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8355 - val_loss: 0.3293 - val_accuracy: 0.8850\n",
      "Epoch 1415/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3810 - accuracy: 0.8417 - val_loss: 0.3264 - val_accuracy: 0.8863\n",
      "Epoch 1416/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3838 - accuracy: 0.8430 - val_loss: 0.3364 - val_accuracy: 0.8768\n",
      "Epoch 1417/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3955 - accuracy: 0.8330 - val_loss: 0.3445 - val_accuracy: 0.8816\n",
      "Epoch 1418/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8383 - val_loss: 0.3265 - val_accuracy: 0.8823\n",
      "Epoch 1419/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3812 - accuracy: 0.8412 - val_loss: 0.3284 - val_accuracy: 0.8823\n",
      "Epoch 1420/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3782 - accuracy: 0.8415 - val_loss: 0.3380 - val_accuracy: 0.8796\n",
      "Epoch 1421/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3914 - accuracy: 0.8353 - val_loss: 0.3321 - val_accuracy: 0.8811\n",
      "Epoch 1422/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3828 - accuracy: 0.8400 - val_loss: 0.3285 - val_accuracy: 0.8854\n",
      "Epoch 1423/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8378 - val_loss: 0.3179 - val_accuracy: 0.8929\n",
      "Epoch 1424/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3925 - accuracy: 0.8357 - val_loss: 0.3180 - val_accuracy: 0.8934\n",
      "Epoch 1425/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3897 - accuracy: 0.8355 - val_loss: 0.3251 - val_accuracy: 0.8793\n",
      "Epoch 1426/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3892 - accuracy: 0.8407 - val_loss: 0.3364 - val_accuracy: 0.8791\n",
      "Epoch 1427/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3920 - accuracy: 0.8370 - val_loss: 0.3243 - val_accuracy: 0.8854\n",
      "Epoch 1428/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3934 - accuracy: 0.8393 - val_loss: 0.3310 - val_accuracy: 0.8827\n",
      "Epoch 1429/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3784 - accuracy: 0.8426 - val_loss: 0.3304 - val_accuracy: 0.8811\n",
      "Epoch 1430/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3913 - accuracy: 0.8365 - val_loss: 0.3248 - val_accuracy: 0.8863\n",
      "Epoch 1431/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3800 - accuracy: 0.8445 - val_loss: 0.3092 - val_accuracy: 0.8929\n",
      "Epoch 1432/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3847 - accuracy: 0.8427 - val_loss: 0.3377 - val_accuracy: 0.8814\n",
      "Epoch 1433/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3941 - accuracy: 0.8331 - val_loss: 0.3366 - val_accuracy: 0.8832\n",
      "Epoch 1434/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3846 - accuracy: 0.8407 - val_loss: 0.3556 - val_accuracy: 0.8694\n",
      "Epoch 1435/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3767 - accuracy: 0.8436 - val_loss: 0.3293 - val_accuracy: 0.8834\n",
      "Epoch 1436/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3993 - accuracy: 0.8342 - val_loss: 0.3233 - val_accuracy: 0.8870\n",
      "Epoch 1437/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3899 - accuracy: 0.8401 - val_loss: 0.3332 - val_accuracy: 0.8811\n",
      "Epoch 1438/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3879 - accuracy: 0.8414 - val_loss: 0.3291 - val_accuracy: 0.8891\n",
      "Epoch 1439/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3727 - accuracy: 0.8445 - val_loss: 0.3543 - val_accuracy: 0.8691\n",
      "Epoch 1440/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8341 - val_loss: 0.3263 - val_accuracy: 0.8866\n",
      "Epoch 1441/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3866 - accuracy: 0.8425 - val_loss: 0.3334 - val_accuracy: 0.8873\n",
      "Epoch 1442/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4007 - accuracy: 0.8337 - val_loss: 0.3268 - val_accuracy: 0.8891\n",
      "Epoch 1443/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.8305 - val_loss: 0.3240 - val_accuracy: 0.8884\n",
      "Epoch 1444/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3855 - accuracy: 0.8414 - val_loss: 0.3347 - val_accuracy: 0.8866\n",
      "Epoch 1445/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3735 - accuracy: 0.8454 - val_loss: 0.3288 - val_accuracy: 0.8848\n",
      "Epoch 1446/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3885 - accuracy: 0.8396 - val_loss: 0.3157 - val_accuracy: 0.8906\n",
      "Epoch 1447/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3919 - accuracy: 0.8363 - val_loss: 0.3124 - val_accuracy: 0.8913\n",
      "Epoch 1448/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3970 - accuracy: 0.8336 - val_loss: 0.3254 - val_accuracy: 0.8895\n",
      "Epoch 1449/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3950 - accuracy: 0.8355 - val_loss: 0.3325 - val_accuracy: 0.8859\n",
      "Epoch 1450/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3780 - accuracy: 0.8412 - val_loss: 0.3257 - val_accuracy: 0.8861\n",
      "Epoch 1451/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3974 - accuracy: 0.8391 - val_loss: 0.3442 - val_accuracy: 0.8755\n",
      "Epoch 1452/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3910 - accuracy: 0.8351 - val_loss: 0.3342 - val_accuracy: 0.8811\n",
      "Epoch 1453/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3801 - accuracy: 0.8419 - val_loss: 0.3461 - val_accuracy: 0.8780\n",
      "Epoch 1454/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3937 - accuracy: 0.8358 - val_loss: 0.3302 - val_accuracy: 0.8827\n",
      "Epoch 1455/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3950 - accuracy: 0.8370 - val_loss: 0.3569 - val_accuracy: 0.8660\n",
      "Epoch 1456/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3892 - accuracy: 0.8369 - val_loss: 0.3352 - val_accuracy: 0.8834\n",
      "Epoch 1457/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3821 - accuracy: 0.8401 - val_loss: 0.3227 - val_accuracy: 0.8859\n",
      "Epoch 1458/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3767 - accuracy: 0.8451 - val_loss: 0.3346 - val_accuracy: 0.8750\n",
      "Epoch 1459/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3876 - accuracy: 0.8365 - val_loss: 0.3386 - val_accuracy: 0.8823\n",
      "Epoch 1460/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4003 - accuracy: 0.8299 - val_loss: 0.3255 - val_accuracy: 0.8895\n",
      "Epoch 1461/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3789 - accuracy: 0.8435 - val_loss: 0.3182 - val_accuracy: 0.8886\n",
      "Epoch 1462/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3795 - accuracy: 0.8451 - val_loss: 0.3417 - val_accuracy: 0.8823\n",
      "Epoch 1463/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4019 - accuracy: 0.8276 - val_loss: 0.3360 - val_accuracy: 0.8823\n",
      "Epoch 1464/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3804 - accuracy: 0.8421 - val_loss: 0.3309 - val_accuracy: 0.8796\n",
      "Epoch 1465/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3937 - accuracy: 0.8378 - val_loss: 0.3242 - val_accuracy: 0.8886\n",
      "Epoch 1466/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3846 - accuracy: 0.8400 - val_loss: 0.3196 - val_accuracy: 0.8886\n",
      "Epoch 1467/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3877 - accuracy: 0.8396 - val_loss: 0.3217 - val_accuracy: 0.8888\n",
      "Epoch 1468/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3842 - accuracy: 0.8389 - val_loss: 0.3358 - val_accuracy: 0.8816\n",
      "Epoch 1469/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3820 - accuracy: 0.8426 - val_loss: 0.3176 - val_accuracy: 0.8884\n",
      "Epoch 1470/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8383 - val_loss: 0.3287 - val_accuracy: 0.8839\n",
      "Epoch 1471/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3688 - accuracy: 0.8445 - val_loss: 0.3232 - val_accuracy: 0.8868\n",
      "Epoch 1472/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3878 - accuracy: 0.8419 - val_loss: 0.3336 - val_accuracy: 0.8843\n",
      "Epoch 1473/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3885 - accuracy: 0.8402 - val_loss: 0.3369 - val_accuracy: 0.8827\n",
      "Epoch 1474/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3836 - accuracy: 0.8421 - val_loss: 0.3367 - val_accuracy: 0.8782\n",
      "Epoch 1475/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3885 - accuracy: 0.8405 - val_loss: 0.3242 - val_accuracy: 0.8891\n",
      "Epoch 1476/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3792 - accuracy: 0.8392 - val_loss: 0.3212 - val_accuracy: 0.8884\n",
      "Epoch 1477/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3754 - accuracy: 0.8437 - val_loss: 0.3235 - val_accuracy: 0.8925\n",
      "Epoch 1478/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3914 - accuracy: 0.8366 - val_loss: 0.3147 - val_accuracy: 0.8974\n",
      "Epoch 1479/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3695 - accuracy: 0.8467 - val_loss: 0.3326 - val_accuracy: 0.8836\n",
      "Epoch 1480/1500\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3758 - accuracy: 0.8457 - val_loss: 0.3272 - val_accuracy: 0.8877\n",
      "Epoch 1481/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3947 - accuracy: 0.8335 - val_loss: 0.3312 - val_accuracy: 0.8825\n",
      "Epoch 1482/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3782 - accuracy: 0.8432 - val_loss: 0.3311 - val_accuracy: 0.8841\n",
      "Epoch 1483/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3846 - accuracy: 0.8430 - val_loss: 0.3427 - val_accuracy: 0.8780\n",
      "Epoch 1484/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3901 - accuracy: 0.8382 - val_loss: 0.3315 - val_accuracy: 0.8859\n",
      "Epoch 1485/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3820 - accuracy: 0.8425 - val_loss: 0.3277 - val_accuracy: 0.8891\n",
      "Epoch 1486/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8325 - val_loss: 0.3376 - val_accuracy: 0.8800\n",
      "Epoch 1487/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3844 - accuracy: 0.8383 - val_loss: 0.3325 - val_accuracy: 0.8814\n",
      "Epoch 1488/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3871 - accuracy: 0.8416 - val_loss: 0.3129 - val_accuracy: 0.8931\n",
      "Epoch 1489/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3799 - accuracy: 0.8405 - val_loss: 0.3186 - val_accuracy: 0.8913\n",
      "Epoch 1490/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3902 - accuracy: 0.8358 - val_loss: 0.3205 - val_accuracy: 0.8906\n",
      "Epoch 1491/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3891 - accuracy: 0.8372 - val_loss: 0.3242 - val_accuracy: 0.8882\n",
      "Epoch 1492/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3869 - accuracy: 0.8348 - val_loss: 0.3361 - val_accuracy: 0.8834\n",
      "Epoch 1493/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3912 - accuracy: 0.8357 - val_loss: 0.3223 - val_accuracy: 0.8866\n",
      "Epoch 1494/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3967 - accuracy: 0.8353 - val_loss: 0.3233 - val_accuracy: 0.8879\n",
      "Epoch 1495/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.3233 - val_accuracy: 0.8895\n",
      "Epoch 1496/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3790 - accuracy: 0.8430 - val_loss: 0.3279 - val_accuracy: 0.8873\n",
      "Epoch 1497/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3917 - accuracy: 0.8353 - val_loss: 0.3355 - val_accuracy: 0.8800\n",
      "Epoch 1498/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3818 - accuracy: 0.8412 - val_loss: 0.3461 - val_accuracy: 0.8773\n",
      "Epoch 1499/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3745 - accuracy: 0.8439 - val_loss: 0.3272 - val_accuracy: 0.8879\n",
      "Epoch 1500/1500\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3898 - accuracy: 0.8365 - val_loss: 0.3228 - val_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avik\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "h1 = final_estimator.fit(edited_train.iloc[:,:39] , edited_train['Genetic Disorder'] , epochs=1500, verbose=1, batch_size = 32,\n",
    "                   validation_data = (valid_data.iloc[:,:39] , valid_data['Genetic Disorder']) )\n",
    "# plot history\n",
    "plt.plot(h1.history['accuracy'], label='train')\n",
    "plt.plot(h1.history['val_accuracy'], label='test')\n",
    "plt.legend(loc ='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(xlabel=\"epochs\")\n",
    "plt.ylabel(ylabel=\"accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# making prediction in test data :\n",
    "Genetic_Disorder_pred = final_estimator.predict(edited_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation : On full train data accuracy is 0.836 approx. \n",
    "## Plot reveals that the model is performing better and giving a prediction accuracy of 0.892 approximately on validation data . \n",
    "## Finally we have make prediction 'Genetic_Disorder_pred' in encoded format for the original test data and then rolling back the prediction in categorical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Multifactorial genetic inheritance disorders',\n",
       "       'Mitochondrial genetic inheritance disorders',\n",
       "       'Mitochondrial genetic inheritance disorders', ...,\n",
       "       'Mitochondrial genetic inheritance disorders',\n",
       "       'Single-gene inheritance diseases',\n",
       "       'Multifactorial genetic inheritance disorders'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genetic_Disorder = encoder1.inverse_transform(Genetic_Disorder_pred)\n",
    "Genetic_Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_test['Genetic_Disorder'] = Genetic_Disorder_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 : 'Disorder Subclass' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"344pt\" height=\"876pt\" viewBox=\"0.00 0.00 413.00 1051.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.833333 0.833333) rotate(0) translate(4 1047)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1047 409,-1047 409,4 -4,4\"/>\n",
       "<!-- 1757917417920 -->\n",
       "<g id=\"node1\" class=\"node\"><title>1757917417920</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-996.5 44.5,-1042.5 360.5,-1042.5 360.5,-996.5 44.5,-996.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"131.5\" y=\"-1015.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">flatten_19_input: InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"218.5,-996.5 218.5,-1042.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"246.5\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"218.5,-1019.5 274.5,-1019.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"246.5\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"274.5,-996.5 274.5,-1042.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-1027.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 40)]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"274.5,-1019.5 360.5,-1019.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-1004.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[(None, 40)]</text>\n",
       "</g>\n",
       "<!-- 1758094148416 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1758094148416</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"78,-913.5 78,-959.5 327,-959.5 327,-913.5 78,-913.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-932.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">flatten_19: Flatten</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"194,-913.5 194,-959.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"194,-936.5 250,-936.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-913.5 250,-959.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-944.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 40)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"250,-936.5 327,-936.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"288.5\" y=\"-921.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 40)</text>\n",
       "</g>\n",
       "<!-- 1757917417920&#45;&gt;1758094148416 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>1757917417920-&gt;1758094148416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-996.366C202.5,-988.152 202.5,-978.658 202.5,-969.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-969.607 202.5,-959.607 199,-969.607 206,-969.607\"/>\n",
       "</g>\n",
       "<!-- 1757841229568 -->\n",
       "<g id=\"node3\" class=\"node\"><title>1757841229568</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-830.5 3,-876.5 402,-876.5 402,-830.5 3,-830.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-849.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_76: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-830.5 269,-876.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-853.5 325,-853.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-830.5 325,-876.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-861.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 40)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-853.5 402,-853.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-838.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 40)</text>\n",
       "</g>\n",
       "<!-- 1758094148416&#45;&gt;1757841229568 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1758094148416-&gt;1757841229568</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-913.366C202.5,-905.152 202.5,-895.658 202.5,-886.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-886.607 202.5,-876.607 199,-886.607 206,-886.607\"/>\n",
       "</g>\n",
       "<!-- 1758094214240 -->\n",
       "<g id=\"node4\" class=\"node\"><title>1758094214240</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-747.5 77.5,-793.5 327.5,-793.5 327.5,-747.5 77.5,-747.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-766.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_76: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-747.5 188.5,-793.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-770.5 244.5,-770.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-747.5 244.5,-793.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-778.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 40)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-770.5 327.5,-770.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-755.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1757841229568&#45;&gt;1758094214240 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1757841229568-&gt;1758094214240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-830.366C202.5,-822.152 202.5,-812.658 202.5,-803.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-803.607 202.5,-793.607 199,-803.607 206,-803.607\"/>\n",
       "</g>\n",
       "<!-- 1757507356896 -->\n",
       "<g id=\"node5\" class=\"node\"><title>1757507356896</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-664.5 0,-710.5 405,-710.5 405,-664.5 0,-664.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-683.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_77: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266,-664.5 266,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"266,-687.5 322,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"294\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"322,-664.5 322,-710.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-695.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"322,-687.5 405,-687.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-672.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1758094214240&#45;&gt;1757507356896 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1758094214240-&gt;1757507356896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-747.366C202.5,-739.152 202.5,-729.658 202.5,-720.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-720.607 202.5,-710.607 199,-720.607 206,-720.607\"/>\n",
       "</g>\n",
       "<!-- 1758095222000 -->\n",
       "<g id=\"node6\" class=\"node\"><title>1758095222000</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"30,-581.5 30,-627.5 375,-627.5 375,-581.5 30,-581.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-600.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_57: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-581.5 236,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"236,-604.5 292,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"264\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"292,-581.5 292,-627.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-612.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"292,-604.5 375,-604.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-589.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 1757507356896&#45;&gt;1758095222000 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>1757507356896-&gt;1758095222000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-664.366C202.5,-656.152 202.5,-646.658 202.5,-637.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-637.607 202.5,-627.607 199,-637.607 206,-637.607\"/>\n",
       "</g>\n",
       "<!-- 1758094234672 -->\n",
       "<g id=\"node7\" class=\"node\"><title>1758094234672</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-498.5 77.5,-544.5 327.5,-544.5 327.5,-498.5 77.5,-498.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133\" y=\"-517.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_77: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-498.5 188.5,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"188.5,-521.5 244.5,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-498.5 244.5,-544.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-529.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 512)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"244.5,-521.5 327.5,-521.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1758095222000&#45;&gt;1758094234672 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>1758095222000-&gt;1758094234672</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-581.366C202.5,-573.152 202.5,-563.658 202.5,-554.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-554.607 202.5,-544.607 199,-554.607 206,-554.607\"/>\n",
       "</g>\n",
       "<!-- 1758094373552 -->\n",
       "<g id=\"node8\" class=\"node\"><title>1758094373552</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-415.5 3,-461.5 402,-461.5 402,-415.5 3,-415.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-434.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_78: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-415.5 269,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-438.5 325,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-415.5 325,-461.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-446.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-438.5 402,-438.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-423.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1758094234672&#45;&gt;1758094373552 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>1758094234672-&gt;1758094373552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-498.366C202.5,-490.152 202.5,-480.658 202.5,-471.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-471.607 202.5,-461.607 199,-471.607 206,-471.607\"/>\n",
       "</g>\n",
       "<!-- 1757507357136 -->\n",
       "<g id=\"node9\" class=\"node\"><title>1757507357136</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-332.5 33,-378.5 372,-378.5 372,-332.5 33,-332.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-351.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_58: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-332.5 239,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-355.5 295,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-332.5 295,-378.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-363.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-355.5 372,-355.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-340.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1758094373552&#45;&gt;1757507357136 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>1758094373552-&gt;1757507357136</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-415.366C202.5,-407.152 202.5,-397.658 202.5,-388.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-388.607 202.5,-378.607 199,-388.607 206,-388.607\"/>\n",
       "</g>\n",
       "<!-- 1758094539408 -->\n",
       "<g id=\"node10\" class=\"node\"><title>1758094539408</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80.5,-249.5 80.5,-295.5 324.5,-295.5 324.5,-249.5 80.5,-249.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-268.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_78: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-249.5 191.5,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-272.5 247.5,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-249.5 247.5,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-280.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-272.5 324.5,-272.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-257.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1757507357136&#45;&gt;1758094539408 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>1757507357136-&gt;1758094539408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-332.366C202.5,-324.152 202.5,-314.658 202.5,-305.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-305.607 202.5,-295.607 199,-305.607 206,-305.607\"/>\n",
       "</g>\n",
       "<!-- 1758094421296 -->\n",
       "<g id=\"node11\" class=\"node\"><title>1758094421296</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3,-166.5 3,-212.5 402,-212.5 402,-166.5 3,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-185.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">batch_normalization_79: BatchNormalization</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-166.5 269,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"269,-189.5 325,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-166.5 325,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-197.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"325,-189.5 402,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1758094539408&#45;&gt;1758094421296 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>1758094539408-&gt;1758094421296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-249.366C202.5,-241.152 202.5,-231.658 202.5,-222.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-222.607 202.5,-212.607 199,-222.607 206,-222.607\"/>\n",
       "</g>\n",
       "<!-- 1758094216736 -->\n",
       "<g id=\"node12\" class=\"node\"><title>1758094216736</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"33,-83.5 33,-129.5 372,-129.5 372,-83.5 33,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-102.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">alpha_dropout_59: AlphaDropout</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-83.5 239,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"239,-106.5 295,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"267\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-83.5 295,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"295,-106.5 372,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 1758094421296&#45;&gt;1758094216736 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>1758094421296-&gt;1758094216736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-166.366C202.5,-158.152 202.5,-148.658 202.5,-139.725\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-139.607 202.5,-129.607 199,-139.607 206,-139.607\"/>\n",
       "</g>\n",
       "<!-- 1758094563360 -->\n",
       "<g id=\"node13\" class=\"node\"><title>1758094563360</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80.5,-0.5 80.5,-46.5 324.5,-46.5 324.5,-0.5 80.5,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-19.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dense_79: Dense</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-0.5 191.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"191.5,-23.5 247.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-0.5 247.5,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"247.5,-23.5 324.5,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"286\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">(None, 9)</text>\n",
       "</g>\n",
       "<!-- 1758094216736&#45;&gt;1758094563360 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>1758094216736-&gt;1758094563360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.5,-83.3664C202.5,-75.1516 202.5,-65.6579 202.5,-56.7252\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206,-56.6068 202.5,-46.6068 199,-56.6069 206,-56.6068\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(baseline_model2(), show_shapes=True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the estimator with the full data :\n",
    "\n",
    "final_estimator2 = KerasClassifier(build_fn=baseline_model2,  verbose = 1 , shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disorder Subclass Prediction utilizing full train data for the test data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/910\n",
      "691/691 [==============================] - 6s 5ms/step - loss: 1.1300 - accuracy: 0.5823 - val_loss: 0.6533 - val_accuracy: 0.7138\n",
      "Epoch 2/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7316 - accuracy: 0.7097 - val_loss: 0.6584 - val_accuracy: 0.7156\n",
      "Epoch 3/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7137 - accuracy: 0.7187 - val_loss: 0.6407 - val_accuracy: 0.7231\n",
      "Epoch 4/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.7106 - accuracy: 0.7185 - val_loss: 0.6450 - val_accuracy: 0.7231\n",
      "Epoch 5/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6848 - accuracy: 0.7279 - val_loss: 0.6226 - val_accuracy: 0.7263\n",
      "Epoch 6/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6823 - accuracy: 0.7315 - val_loss: 0.6293 - val_accuracy: 0.7206\n",
      "Epoch 7/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6758 - accuracy: 0.7300 - val_loss: 0.6305 - val_accuracy: 0.7218\n",
      "Epoch 8/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6710 - accuracy: 0.7269 - val_loss: 0.6309 - val_accuracy: 0.7247\n",
      "Epoch 9/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6687 - accuracy: 0.7314 - val_loss: 0.6339 - val_accuracy: 0.7247\n",
      "Epoch 10/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6830 - accuracy: 0.7241 - val_loss: 0.6312 - val_accuracy: 0.7181\n",
      "Epoch 11/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6715 - accuracy: 0.7301 - val_loss: 0.6246 - val_accuracy: 0.7270\n",
      "Epoch 12/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6638 - accuracy: 0.7268 - val_loss: 0.6251 - val_accuracy: 0.7211\n",
      "Epoch 13/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6568 - accuracy: 0.7355 - val_loss: 0.6276 - val_accuracy: 0.7213\n",
      "Epoch 14/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6527 - accuracy: 0.7363 - val_loss: 0.6222 - val_accuracy: 0.7270\n",
      "Epoch 15/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6434 - accuracy: 0.7358 - val_loss: 0.6284 - val_accuracy: 0.7193\n",
      "Epoch 16/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6558 - accuracy: 0.7304 - val_loss: 0.6329 - val_accuracy: 0.7215\n",
      "Epoch 17/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.6651 - accuracy: 0.7362 - val_loss: 0.6100 - val_accuracy: 0.7326\n",
      "Epoch 18/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6539 - accuracy: 0.7310 - val_loss: 0.6110 - val_accuracy: 0.7310\n",
      "Epoch 19/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6510 - accuracy: 0.7325 - val_loss: 0.6095 - val_accuracy: 0.7308\n",
      "Epoch 20/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6443 - accuracy: 0.7376 - val_loss: 0.6002 - val_accuracy: 0.7340\n",
      "Epoch 21/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6321 - accuracy: 0.7343 - val_loss: 0.6171 - val_accuracy: 0.7301\n",
      "Epoch 22/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6425 - accuracy: 0.7351 - val_loss: 0.6015 - val_accuracy: 0.7283\n",
      "Epoch 23/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6361 - accuracy: 0.7404 - val_loss: 0.5954 - val_accuracy: 0.7338\n",
      "Epoch 24/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6428 - accuracy: 0.7360 - val_loss: 0.6074 - val_accuracy: 0.7306\n",
      "Epoch 25/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6239 - accuracy: 0.7434 - val_loss: 0.6016 - val_accuracy: 0.7333\n",
      "Epoch 26/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6391 - accuracy: 0.7384 - val_loss: 0.6006 - val_accuracy: 0.7335\n",
      "Epoch 27/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6234 - accuracy: 0.7407 - val_loss: 0.6094 - val_accuracy: 0.7331\n",
      "Epoch 28/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6272 - accuracy: 0.7411 - val_loss: 0.5944 - val_accuracy: 0.7347\n",
      "Epoch 29/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6332 - accuracy: 0.7412 - val_loss: 0.5891 - val_accuracy: 0.7369\n",
      "Epoch 30/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6218 - accuracy: 0.7451 - val_loss: 0.6028 - val_accuracy: 0.7347\n",
      "Epoch 31/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6344 - accuracy: 0.7356 - val_loss: 0.5979 - val_accuracy: 0.7378\n",
      "Epoch 32/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6197 - accuracy: 0.7434 - val_loss: 0.5997 - val_accuracy: 0.7322\n",
      "Epoch 33/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6206 - accuracy: 0.7434 - val_loss: 0.5911 - val_accuracy: 0.7351\n",
      "Epoch 34/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6185 - accuracy: 0.7444 - val_loss: 0.5917 - val_accuracy: 0.7317\n",
      "Epoch 35/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6088 - accuracy: 0.7465 - val_loss: 0.5927 - val_accuracy: 0.7369\n",
      "Epoch 36/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6083 - accuracy: 0.7450 - val_loss: 0.5877 - val_accuracy: 0.7358\n",
      "Epoch 37/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.6137 - accuracy: 0.7451 - val_loss: 0.6010 - val_accuracy: 0.7365\n",
      "Epoch 38/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6117 - accuracy: 0.7462 - val_loss: 0.5953 - val_accuracy: 0.7349\n",
      "Epoch 39/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6058 - accuracy: 0.7448 - val_loss: 0.5967 - val_accuracy: 0.7310\n",
      "Epoch 40/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6080 - accuracy: 0.7467 - val_loss: 0.5871 - val_accuracy: 0.7376\n",
      "Epoch 41/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.6084 - accuracy: 0.7464 - val_loss: 0.5815 - val_accuracy: 0.7433\n",
      "Epoch 42/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5843 - accuracy: 0.7555 - val_loss: 0.5771 - val_accuracy: 0.7460\n",
      "Epoch 43/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5948 - accuracy: 0.7538 - val_loss: 0.5842 - val_accuracy: 0.7426\n",
      "Epoch 44/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5940 - accuracy: 0.7529 - val_loss: 0.5724 - val_accuracy: 0.7467\n",
      "Epoch 45/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7559 - val_loss: 0.5895 - val_accuracy: 0.7390\n",
      "Epoch 46/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5903 - accuracy: 0.7499 - val_loss: 0.5795 - val_accuracy: 0.7446\n",
      "Epoch 47/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5984 - accuracy: 0.7498 - val_loss: 0.5949 - val_accuracy: 0.7433\n",
      "Epoch 48/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5905 - accuracy: 0.7567 - val_loss: 0.5734 - val_accuracy: 0.7408\n",
      "Epoch 49/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5822 - accuracy: 0.7594 - val_loss: 0.5782 - val_accuracy: 0.7387\n",
      "Epoch 50/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5826 - accuracy: 0.7582 - val_loss: 0.5760 - val_accuracy: 0.7473\n",
      "Epoch 51/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5931 - accuracy: 0.7490 - val_loss: 0.5782 - val_accuracy: 0.7415\n",
      "Epoch 52/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5872 - accuracy: 0.7516 - val_loss: 0.5672 - val_accuracy: 0.7473\n",
      "Epoch 53/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5829 - accuracy: 0.7549 - val_loss: 0.5639 - val_accuracy: 0.7505\n",
      "Epoch 54/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5701 - accuracy: 0.7613 - val_loss: 0.5814 - val_accuracy: 0.7362\n",
      "Epoch 55/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5758 - accuracy: 0.7569 - val_loss: 0.5694 - val_accuracy: 0.7469\n",
      "Epoch 56/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5833 - accuracy: 0.7549 - val_loss: 0.5680 - val_accuracy: 0.7460\n",
      "Epoch 57/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5755 - accuracy: 0.7596 - val_loss: 0.5595 - val_accuracy: 0.7480\n",
      "Epoch 58/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5799 - accuracy: 0.7561 - val_loss: 0.5696 - val_accuracy: 0.7480\n",
      "Epoch 59/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5775 - accuracy: 0.7612 - val_loss: 0.5706 - val_accuracy: 0.7448\n",
      "Epoch 60/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.7679 - val_loss: 0.5789 - val_accuracy: 0.7372\n",
      "Epoch 61/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5635 - accuracy: 0.7640 - val_loss: 0.5743 - val_accuracy: 0.7501\n",
      "Epoch 62/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5606 - accuracy: 0.7584 - val_loss: 0.5684 - val_accuracy: 0.7521\n",
      "Epoch 63/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5579 - accuracy: 0.7666 - val_loss: 0.5681 - val_accuracy: 0.7503\n",
      "Epoch 64/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5737 - accuracy: 0.7618 - val_loss: 0.5766 - val_accuracy: 0.7390\n",
      "Epoch 65/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5654 - accuracy: 0.7573 - val_loss: 0.5634 - val_accuracy: 0.7519\n",
      "Epoch 66/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5604 - accuracy: 0.7605 - val_loss: 0.5704 - val_accuracy: 0.7568\n",
      "Epoch 67/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5549 - accuracy: 0.7653 - val_loss: 0.5661 - val_accuracy: 0.7555\n",
      "Epoch 68/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5608 - accuracy: 0.7626 - val_loss: 0.5644 - val_accuracy: 0.7523\n",
      "Epoch 69/910\n",
      "691/691 [==============================] - 2s 4ms/step - loss: 0.5734 - accuracy: 0.7577 - val_loss: 0.5643 - val_accuracy: 0.7503\n",
      "Epoch 70/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5683 - accuracy: 0.7605 - val_loss: 0.5641 - val_accuracy: 0.7555\n",
      "Epoch 71/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.5678 - accuracy: 0.7598 - val_loss: 0.5661 - val_accuracy: 0.7505\n",
      "Epoch 72/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5608 - accuracy: 0.7607 - val_loss: 0.5837 - val_accuracy: 0.7451\n",
      "Epoch 73/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5618 - accuracy: 0.7609 - val_loss: 0.5686 - val_accuracy: 0.7473\n",
      "Epoch 74/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5548 - accuracy: 0.7640 - val_loss: 0.5794 - val_accuracy: 0.7503\n",
      "Epoch 75/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5559 - accuracy: 0.7684 - val_loss: 0.5548 - val_accuracy: 0.7525\n",
      "Epoch 76/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5448 - accuracy: 0.7677 - val_loss: 0.5636 - val_accuracy: 0.7514\n",
      "Epoch 77/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5571 - accuracy: 0.7639 - val_loss: 0.5662 - val_accuracy: 0.7505\n",
      "Epoch 78/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5387 - accuracy: 0.7709 - val_loss: 0.5469 - val_accuracy: 0.7612\n",
      "Epoch 79/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5536 - accuracy: 0.7630 - val_loss: 0.5637 - val_accuracy: 0.7591\n",
      "Epoch 80/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5467 - accuracy: 0.7695 - val_loss: 0.5652 - val_accuracy: 0.7521\n",
      "Epoch 81/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5478 - accuracy: 0.7694 - val_loss: 0.5651 - val_accuracy: 0.7539\n",
      "Epoch 82/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5397 - accuracy: 0.7726 - val_loss: 0.5920 - val_accuracy: 0.7505\n",
      "Epoch 83/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5474 - accuracy: 0.7667 - val_loss: 0.5585 - val_accuracy: 0.7578\n",
      "Epoch 84/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5311 - accuracy: 0.7773 - val_loss: 0.5609 - val_accuracy: 0.7573\n",
      "Epoch 85/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5396 - accuracy: 0.7691 - val_loss: 0.5562 - val_accuracy: 0.7612\n",
      "Epoch 86/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5354 - accuracy: 0.7733 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
      "Epoch 87/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5408 - accuracy: 0.7719 - val_loss: 0.5590 - val_accuracy: 0.7578\n",
      "Epoch 88/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5365 - accuracy: 0.7743 - val_loss: 0.5662 - val_accuracy: 0.7498\n",
      "Epoch 89/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7715 - val_loss: 0.5486 - val_accuracy: 0.7519\n",
      "Epoch 90/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7681 - val_loss: 0.5569 - val_accuracy: 0.7605\n",
      "Epoch 91/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7731 - val_loss: 0.5546 - val_accuracy: 0.7587\n",
      "Epoch 92/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5291 - accuracy: 0.7723 - val_loss: 0.5624 - val_accuracy: 0.7528\n",
      "Epoch 93/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7697 - val_loss: 0.5565 - val_accuracy: 0.7630\n",
      "Epoch 94/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5319 - accuracy: 0.7698 - val_loss: 0.5609 - val_accuracy: 0.7589\n",
      "Epoch 95/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5307 - accuracy: 0.7734 - val_loss: 0.5474 - val_accuracy: 0.7596\n",
      "Epoch 96/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5133 - accuracy: 0.7885 - val_loss: 0.5541 - val_accuracy: 0.7568\n",
      "Epoch 97/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5388 - accuracy: 0.7736 - val_loss: 0.5723 - val_accuracy: 0.7510\n",
      "Epoch 98/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5299 - accuracy: 0.7688 - val_loss: 0.5613 - val_accuracy: 0.7559\n",
      "Epoch 99/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5239 - accuracy: 0.7741 - val_loss: 0.5525 - val_accuracy: 0.7612\n",
      "Epoch 100/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5313 - accuracy: 0.7746 - val_loss: 0.5657 - val_accuracy: 0.7537\n",
      "Epoch 101/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5242 - accuracy: 0.7796 - val_loss: 0.5548 - val_accuracy: 0.7548\n",
      "Epoch 102/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5257 - accuracy: 0.7789 - val_loss: 0.5801 - val_accuracy: 0.7512\n",
      "Epoch 103/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5287 - accuracy: 0.7724 - val_loss: 0.5400 - val_accuracy: 0.7625\n",
      "Epoch 104/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5191 - accuracy: 0.7774 - val_loss: 0.5553 - val_accuracy: 0.7612\n",
      "Epoch 105/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5206 - accuracy: 0.7804 - val_loss: 0.5597 - val_accuracy: 0.7573\n",
      "Epoch 106/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5193 - accuracy: 0.7763 - val_loss: 0.5479 - val_accuracy: 0.7636\n",
      "Epoch 107/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5125 - accuracy: 0.7823 - val_loss: 0.5475 - val_accuracy: 0.7664\n",
      "Epoch 108/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5309 - accuracy: 0.7775 - val_loss: 0.5382 - val_accuracy: 0.7645\n",
      "Epoch 109/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5167 - accuracy: 0.7781 - val_loss: 0.5452 - val_accuracy: 0.7657\n",
      "Epoch 110/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5163 - accuracy: 0.7783 - val_loss: 0.5445 - val_accuracy: 0.7645\n",
      "Epoch 111/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5260 - accuracy: 0.7746 - val_loss: 0.5641 - val_accuracy: 0.7584\n",
      "Epoch 112/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5092 - accuracy: 0.7793 - val_loss: 0.5634 - val_accuracy: 0.7539\n",
      "Epoch 113/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5128 - accuracy: 0.7818 - val_loss: 0.5537 - val_accuracy: 0.7639\n",
      "Epoch 114/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5145 - accuracy: 0.7828 - val_loss: 0.5466 - val_accuracy: 0.7657\n",
      "Epoch 115/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5171 - accuracy: 0.7824 - val_loss: 0.5515 - val_accuracy: 0.7688\n",
      "Epoch 116/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5150 - accuracy: 0.7788 - val_loss: 0.5494 - val_accuracy: 0.7607\n",
      "Epoch 117/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5141 - accuracy: 0.7809 - val_loss: 0.5433 - val_accuracy: 0.7630\n",
      "Epoch 118/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5121 - accuracy: 0.7800 - val_loss: 0.5381 - val_accuracy: 0.7659\n",
      "Epoch 119/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5126 - accuracy: 0.7838 - val_loss: 0.5444 - val_accuracy: 0.7648\n",
      "Epoch 120/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4939 - accuracy: 0.7899 - val_loss: 0.5410 - val_accuracy: 0.7677\n",
      "Epoch 121/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5025 - accuracy: 0.7818 - val_loss: 0.5477 - val_accuracy: 0.7598\n",
      "Epoch 122/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5087 - accuracy: 0.7832 - val_loss: 0.5597 - val_accuracy: 0.7650\n",
      "Epoch 123/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5043 - accuracy: 0.7810 - val_loss: 0.5619 - val_accuracy: 0.7598\n",
      "Epoch 124/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5098 - accuracy: 0.7798 - val_loss: 0.5447 - val_accuracy: 0.7655\n",
      "Epoch 125/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5095 - accuracy: 0.7796 - val_loss: 0.5654 - val_accuracy: 0.7564\n",
      "Epoch 126/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5117 - accuracy: 0.7789 - val_loss: 0.5481 - val_accuracy: 0.7634\n",
      "Epoch 127/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5113 - accuracy: 0.7811 - val_loss: 0.5383 - val_accuracy: 0.7684\n",
      "Epoch 128/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4952 - accuracy: 0.7903 - val_loss: 0.5464 - val_accuracy: 0.7657\n",
      "Epoch 129/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5050 - accuracy: 0.7803 - val_loss: 0.5479 - val_accuracy: 0.7645\n",
      "Epoch 130/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5018 - accuracy: 0.7881 - val_loss: 0.5394 - val_accuracy: 0.7670\n",
      "Epoch 131/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4956 - accuracy: 0.7890 - val_loss: 0.5508 - val_accuracy: 0.7605\n",
      "Epoch 132/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4981 - accuracy: 0.7864 - val_loss: 0.5475 - val_accuracy: 0.7641\n",
      "Epoch 133/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4968 - accuracy: 0.7842 - val_loss: 0.5495 - val_accuracy: 0.7582\n",
      "Epoch 134/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4920 - accuracy: 0.7911 - val_loss: 0.5520 - val_accuracy: 0.7682\n",
      "Epoch 135/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4930 - accuracy: 0.7900 - val_loss: 0.5345 - val_accuracy: 0.7648\n",
      "Epoch 136/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4969 - accuracy: 0.7835 - val_loss: 0.5572 - val_accuracy: 0.7596\n",
      "Epoch 137/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4947 - accuracy: 0.7875 - val_loss: 0.5344 - val_accuracy: 0.7711\n",
      "Epoch 138/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4938 - accuracy: 0.7872 - val_loss: 0.5502 - val_accuracy: 0.7639\n",
      "Epoch 139/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4991 - accuracy: 0.7876 - val_loss: 0.5668 - val_accuracy: 0.7480\n",
      "Epoch 140/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.5081 - accuracy: 0.7840 - val_loss: 0.5484 - val_accuracy: 0.7688\n",
      "Epoch 141/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4983 - accuracy: 0.7902 - val_loss: 0.5376 - val_accuracy: 0.7666\n",
      "Epoch 142/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.5068 - accuracy: 0.7864 - val_loss: 0.5476 - val_accuracy: 0.7632\n",
      "Epoch 143/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4966 - accuracy: 0.7910 - val_loss: 0.5310 - val_accuracy: 0.7691\n",
      "Epoch 144/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4842 - accuracy: 0.7923 - val_loss: 0.5510 - val_accuracy: 0.7688\n",
      "Epoch 145/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4843 - accuracy: 0.7935 - val_loss: 0.5346 - val_accuracy: 0.7754\n",
      "Epoch 146/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4935 - accuracy: 0.7852 - val_loss: 0.5687 - val_accuracy: 0.7580\n",
      "Epoch 147/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4921 - accuracy: 0.7843 - val_loss: 0.5534 - val_accuracy: 0.7679\n",
      "Epoch 148/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4985 - accuracy: 0.7855 - val_loss: 0.5304 - val_accuracy: 0.7693\n",
      "Epoch 149/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4734 - accuracy: 0.7939 - val_loss: 0.5429 - val_accuracy: 0.7661\n",
      "Epoch 150/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4926 - accuracy: 0.7914 - val_loss: 0.5365 - val_accuracy: 0.7688\n",
      "Epoch 151/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4891 - accuracy: 0.7921 - val_loss: 0.5646 - val_accuracy: 0.7632\n",
      "Epoch 152/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4795 - accuracy: 0.7937 - val_loss: 0.5487 - val_accuracy: 0.7704\n",
      "Epoch 153/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4914 - accuracy: 0.7895 - val_loss: 0.5487 - val_accuracy: 0.7761\n",
      "Epoch 154/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4811 - accuracy: 0.7958 - val_loss: 0.5488 - val_accuracy: 0.7641\n",
      "Epoch 155/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4816 - accuracy: 0.7902 - val_loss: 0.5364 - val_accuracy: 0.7684\n",
      "Epoch 156/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4839 - accuracy: 0.7935 - val_loss: 0.5501 - val_accuracy: 0.7668\n",
      "Epoch 157/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4903 - accuracy: 0.7935 - val_loss: 0.5543 - val_accuracy: 0.7670\n",
      "Epoch 158/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4739 - accuracy: 0.7966 - val_loss: 0.5364 - val_accuracy: 0.7725\n",
      "Epoch 159/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4823 - accuracy: 0.7898 - val_loss: 0.5432 - val_accuracy: 0.7716\n",
      "Epoch 160/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4819 - accuracy: 0.7958 - val_loss: 0.5365 - val_accuracy: 0.7632\n",
      "Epoch 161/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4706 - accuracy: 0.7981 - val_loss: 0.5473 - val_accuracy: 0.7650\n",
      "Epoch 162/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4706 - accuracy: 0.7913 - val_loss: 0.5393 - val_accuracy: 0.7670\n",
      "Epoch 163/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4760 - accuracy: 0.7933 - val_loss: 0.5385 - val_accuracy: 0.7711\n",
      "Epoch 164/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4808 - accuracy: 0.7917 - val_loss: 0.5240 - val_accuracy: 0.7720\n",
      "Epoch 165/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4763 - accuracy: 0.7948 - val_loss: 0.5543 - val_accuracy: 0.7709\n",
      "Epoch 166/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4769 - accuracy: 0.7932 - val_loss: 0.5391 - val_accuracy: 0.7741\n",
      "Epoch 167/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4817 - accuracy: 0.7906 - val_loss: 0.6080 - val_accuracy: 0.7455\n",
      "Epoch 168/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4790 - accuracy: 0.7934 - val_loss: 0.5359 - val_accuracy: 0.7781\n",
      "Epoch 169/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4774 - accuracy: 0.7959 - val_loss: 0.5405 - val_accuracy: 0.7657\n",
      "Epoch 170/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4854 - accuracy: 0.7954 - val_loss: 0.5226 - val_accuracy: 0.7786\n",
      "Epoch 171/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4561 - accuracy: 0.8014 - val_loss: 0.5348 - val_accuracy: 0.7765\n",
      "Epoch 172/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7966 - val_loss: 0.5334 - val_accuracy: 0.7777\n",
      "Epoch 173/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4675 - accuracy: 0.7998 - val_loss: 0.5520 - val_accuracy: 0.7636\n",
      "Epoch 174/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4742 - accuracy: 0.7899 - val_loss: 0.5296 - val_accuracy: 0.7736\n",
      "Epoch 175/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4693 - accuracy: 0.7987 - val_loss: 0.5402 - val_accuracy: 0.7729\n",
      "Epoch 176/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4640 - accuracy: 0.8022 - val_loss: 0.5397 - val_accuracy: 0.7727\n",
      "Epoch 177/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4701 - accuracy: 0.7987 - val_loss: 0.5310 - val_accuracy: 0.7793\n",
      "Epoch 178/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4679 - accuracy: 0.8003 - val_loss: 0.5364 - val_accuracy: 0.7675\n",
      "Epoch 179/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4641 - accuracy: 0.7978 - val_loss: 0.5740 - val_accuracy: 0.7587\n",
      "Epoch 180/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4773 - accuracy: 0.7936 - val_loss: 0.5394 - val_accuracy: 0.7677\n",
      "Epoch 181/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4712 - accuracy: 0.7966 - val_loss: 0.5339 - val_accuracy: 0.7747\n",
      "Epoch 182/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4787 - accuracy: 0.7951 - val_loss: 0.5321 - val_accuracy: 0.7670\n",
      "Epoch 183/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4631 - accuracy: 0.8000 - val_loss: 0.5352 - val_accuracy: 0.7722\n",
      "Epoch 184/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4631 - accuracy: 0.7967 - val_loss: 0.5156 - val_accuracy: 0.7756\n",
      "Epoch 185/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.7985 - val_loss: 0.5167 - val_accuracy: 0.7702\n",
      "Epoch 186/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4727 - accuracy: 0.7963 - val_loss: 0.5481 - val_accuracy: 0.7738\n",
      "Epoch 187/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4620 - accuracy: 0.7997 - val_loss: 0.5458 - val_accuracy: 0.7729\n",
      "Epoch 188/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4784 - accuracy: 0.7973 - val_loss: 0.5440 - val_accuracy: 0.7729\n",
      "Epoch 189/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4584 - accuracy: 0.8005 - val_loss: 0.5367 - val_accuracy: 0.7711\n",
      "Epoch 190/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4538 - accuracy: 0.8061 - val_loss: 0.5315 - val_accuracy: 0.7731\n",
      "Epoch 191/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.5320 - val_accuracy: 0.7786\n",
      "Epoch 192/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4502 - accuracy: 0.8076 - val_loss: 0.5316 - val_accuracy: 0.7720\n",
      "Epoch 193/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4629 - accuracy: 0.8000 - val_loss: 0.5397 - val_accuracy: 0.7729\n",
      "Epoch 194/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4510 - accuracy: 0.8074 - val_loss: 0.5324 - val_accuracy: 0.7786\n",
      "Epoch 195/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4703 - accuracy: 0.8016 - val_loss: 0.5272 - val_accuracy: 0.7761\n",
      "Epoch 196/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.8042 - val_loss: 0.5158 - val_accuracy: 0.7768\n",
      "Epoch 197/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4649 - accuracy: 0.8015 - val_loss: 0.5676 - val_accuracy: 0.7584\n",
      "Epoch 198/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4671 - accuracy: 0.7989 - val_loss: 0.5335 - val_accuracy: 0.7736\n",
      "Epoch 199/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4513 - accuracy: 0.8035 - val_loss: 0.5286 - val_accuracy: 0.7702\n",
      "Epoch 200/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4448 - accuracy: 0.8035 - val_loss: 0.5436 - val_accuracy: 0.7639\n",
      "Epoch 201/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4542 - accuracy: 0.8008 - val_loss: 0.5299 - val_accuracy: 0.7772\n",
      "Epoch 202/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4534 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7763\n",
      "Epoch 203/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4570 - accuracy: 0.8050 - val_loss: 0.5251 - val_accuracy: 0.7731\n",
      "Epoch 204/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4592 - accuracy: 0.8034 - val_loss: 0.5265 - val_accuracy: 0.7874\n",
      "Epoch 205/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4597 - accuracy: 0.7997 - val_loss: 0.5411 - val_accuracy: 0.7804\n",
      "Epoch 206/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.8071 - val_loss: 0.5395 - val_accuracy: 0.7693\n",
      "Epoch 207/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4548 - accuracy: 0.8033 - val_loss: 0.5418 - val_accuracy: 0.7711\n",
      "Epoch 208/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4588 - accuracy: 0.8020 - val_loss: 0.5184 - val_accuracy: 0.7867\n",
      "Epoch 209/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4492 - accuracy: 0.8075 - val_loss: 0.5224 - val_accuracy: 0.7824\n",
      "Epoch 210/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4611 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7840\n",
      "Epoch 211/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4481 - accuracy: 0.8098 - val_loss: 0.5077 - val_accuracy: 0.7861\n",
      "Epoch 212/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4807 - accuracy: 0.7988 - val_loss: 0.5267 - val_accuracy: 0.7829\n",
      "Epoch 213/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4507 - accuracy: 0.8053 - val_loss: 0.5115 - val_accuracy: 0.7872\n",
      "Epoch 214/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4539 - accuracy: 0.8110 - val_loss: 0.5330 - val_accuracy: 0.7842\n",
      "Epoch 215/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4590 - accuracy: 0.8019 - val_loss: 0.5287 - val_accuracy: 0.7741\n",
      "Epoch 216/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4588 - accuracy: 0.8064 - val_loss: 0.5301 - val_accuracy: 0.7811\n",
      "Epoch 217/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4391 - accuracy: 0.8137 - val_loss: 0.5272 - val_accuracy: 0.7842\n",
      "Epoch 218/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.8094 - val_loss: 0.5225 - val_accuracy: 0.7840\n",
      "Epoch 219/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4622 - accuracy: 0.7985 - val_loss: 0.5188 - val_accuracy: 0.7827\n",
      "Epoch 220/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4472 - accuracy: 0.8039 - val_loss: 0.5093 - val_accuracy: 0.7836\n",
      "Epoch 221/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4482 - accuracy: 0.8105 - val_loss: 0.5370 - val_accuracy: 0.7849\n",
      "Epoch 222/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4527 - accuracy: 0.8019 - val_loss: 0.5404 - val_accuracy: 0.7840\n",
      "Epoch 223/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4590 - accuracy: 0.8041 - val_loss: 0.5211 - val_accuracy: 0.7808\n",
      "Epoch 224/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4401 - accuracy: 0.8110 - val_loss: 0.5056 - val_accuracy: 0.7829\n",
      "Epoch 225/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4458 - accuracy: 0.8090 - val_loss: 0.5023 - val_accuracy: 0.7890\n",
      "Epoch 226/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4450 - accuracy: 0.8111 - val_loss: 0.5126 - val_accuracy: 0.7863\n",
      "Epoch 227/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4378 - accuracy: 0.8087 - val_loss: 0.5158 - val_accuracy: 0.7822\n",
      "Epoch 228/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4479 - accuracy: 0.8101 - val_loss: 0.5212 - val_accuracy: 0.7865\n",
      "Epoch 229/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4423 - accuracy: 0.8107 - val_loss: 0.5446 - val_accuracy: 0.7808\n",
      "Epoch 230/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4373 - accuracy: 0.8117 - val_loss: 0.5183 - val_accuracy: 0.7845\n",
      "Epoch 231/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4557 - accuracy: 0.8021 - val_loss: 0.5364 - val_accuracy: 0.7856\n",
      "Epoch 232/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4347 - accuracy: 0.8106 - val_loss: 0.5267 - val_accuracy: 0.7913\n",
      "Epoch 233/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4411 - accuracy: 0.8131 - val_loss: 0.5983 - val_accuracy: 0.7492\n",
      "Epoch 234/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4384 - accuracy: 0.8124 - val_loss: 0.5303 - val_accuracy: 0.7750\n",
      "Epoch 235/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4441 - accuracy: 0.8100 - val_loss: 0.5248 - val_accuracy: 0.7861\n",
      "Epoch 236/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4401 - accuracy: 0.8110 - val_loss: 0.5264 - val_accuracy: 0.7876\n",
      "Epoch 237/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4419 - accuracy: 0.8087 - val_loss: 0.5281 - val_accuracy: 0.7885\n",
      "Epoch 238/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4412 - accuracy: 0.8116 - val_loss: 0.5228 - val_accuracy: 0.7881\n",
      "Epoch 239/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4515 - accuracy: 0.8088 - val_loss: 0.5193 - val_accuracy: 0.7813\n",
      "Epoch 240/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4276 - accuracy: 0.8132 - val_loss: 0.5294 - val_accuracy: 0.7856\n",
      "Epoch 241/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4466 - accuracy: 0.8128 - val_loss: 0.5198 - val_accuracy: 0.7861\n",
      "Epoch 242/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4360 - accuracy: 0.8170 - val_loss: 0.5118 - val_accuracy: 0.7815\n",
      "Epoch 243/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4336 - accuracy: 0.8144 - val_loss: 0.5139 - val_accuracy: 0.7931\n",
      "Epoch 244/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4388 - accuracy: 0.8106 - val_loss: 0.5277 - val_accuracy: 0.7747\n",
      "Epoch 245/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4346 - accuracy: 0.8096 - val_loss: 0.5276 - val_accuracy: 0.7917\n",
      "Epoch 246/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4314 - accuracy: 0.8133 - val_loss: 0.5121 - val_accuracy: 0.7915\n",
      "Epoch 247/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4336 - accuracy: 0.8127 - val_loss: 0.5122 - val_accuracy: 0.7865\n",
      "Epoch 248/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4427 - accuracy: 0.8099 - val_loss: 0.5018 - val_accuracy: 0.7926\n",
      "Epoch 249/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4300 - accuracy: 0.8159 - val_loss: 0.5071 - val_accuracy: 0.7956\n",
      "Epoch 250/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4414 - accuracy: 0.8082 - val_loss: 0.5286 - val_accuracy: 0.7865\n",
      "Epoch 251/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4288 - accuracy: 0.8182 - val_loss: 0.5142 - val_accuracy: 0.7924\n",
      "Epoch 252/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4351 - accuracy: 0.8130 - val_loss: 0.5286 - val_accuracy: 0.7931\n",
      "Epoch 253/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4401 - accuracy: 0.8144 - val_loss: 0.5273 - val_accuracy: 0.7811\n",
      "Epoch 254/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4378 - accuracy: 0.8122 - val_loss: 0.5286 - val_accuracy: 0.7897\n",
      "Epoch 255/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4390 - accuracy: 0.8071 - val_loss: 0.5152 - val_accuracy: 0.7892\n",
      "Epoch 256/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8168 - val_loss: 0.5227 - val_accuracy: 0.7879\n",
      "Epoch 257/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4343 - accuracy: 0.8163 - val_loss: 0.4965 - val_accuracy: 0.7951\n",
      "Epoch 258/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4366 - accuracy: 0.8118 - val_loss: 0.5054 - val_accuracy: 0.7894\n",
      "Epoch 259/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4308 - accuracy: 0.8143 - val_loss: 0.4996 - val_accuracy: 0.7890\n",
      "Epoch 260/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4230 - accuracy: 0.8191 - val_loss: 0.4940 - val_accuracy: 0.7971\n",
      "Epoch 261/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4275 - accuracy: 0.8164 - val_loss: 0.4976 - val_accuracy: 0.7831\n",
      "Epoch 262/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4278 - accuracy: 0.8201 - val_loss: 0.5012 - val_accuracy: 0.7958\n",
      "Epoch 263/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4305 - accuracy: 0.8156 - val_loss: 0.5350 - val_accuracy: 0.7818\n",
      "Epoch 264/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4384 - accuracy: 0.8129 - val_loss: 0.5026 - val_accuracy: 0.7926\n",
      "Epoch 265/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4344 - accuracy: 0.8108 - val_loss: 0.4971 - val_accuracy: 0.7981\n",
      "Epoch 266/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4227 - accuracy: 0.8203 - val_loss: 0.4997 - val_accuracy: 0.7947\n",
      "Epoch 267/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4203 - accuracy: 0.8232 - val_loss: 0.5087 - val_accuracy: 0.7908\n",
      "Epoch 268/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4192 - accuracy: 0.8226 - val_loss: 0.5277 - val_accuracy: 0.7845\n",
      "Epoch 269/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4308 - accuracy: 0.8156 - val_loss: 0.4982 - val_accuracy: 0.7940\n",
      "Epoch 270/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4256 - accuracy: 0.8175 - val_loss: 0.5038 - val_accuracy: 0.7894\n",
      "Epoch 271/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4474 - accuracy: 0.8098 - val_loss: 0.4940 - val_accuracy: 0.7978\n",
      "Epoch 272/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4421 - accuracy: 0.8136 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
      "Epoch 273/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4163 - accuracy: 0.8187 - val_loss: 0.4957 - val_accuracy: 0.7922\n",
      "Epoch 274/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4226 - accuracy: 0.8233 - val_loss: 0.5497 - val_accuracy: 0.7804\n",
      "Epoch 275/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4278 - accuracy: 0.8136 - val_loss: 0.5106 - val_accuracy: 0.7876\n",
      "Epoch 276/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4196 - accuracy: 0.8195 - val_loss: 0.5329 - val_accuracy: 0.7994\n",
      "Epoch 277/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4370 - accuracy: 0.8151 - val_loss: 0.4943 - val_accuracy: 0.8026\n",
      "Epoch 278/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4284 - accuracy: 0.8193 - val_loss: 0.4855 - val_accuracy: 0.8030\n",
      "Epoch 279/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4268 - accuracy: 0.8178 - val_loss: 0.5243 - val_accuracy: 0.7899\n",
      "Epoch 280/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4114 - accuracy: 0.8214 - val_loss: 0.5143 - val_accuracy: 0.7856\n",
      "Epoch 281/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4183 - accuracy: 0.8193 - val_loss: 0.5219 - val_accuracy: 0.7849\n",
      "Epoch 282/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4310 - accuracy: 0.8146 - val_loss: 0.5203 - val_accuracy: 0.7919\n",
      "Epoch 283/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4299 - accuracy: 0.8133 - val_loss: 0.5191 - val_accuracy: 0.7881\n",
      "Epoch 284/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4287 - accuracy: 0.8148 - val_loss: 0.4886 - val_accuracy: 0.7983\n",
      "Epoch 285/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4271 - accuracy: 0.8211 - val_loss: 0.5128 - val_accuracy: 0.7917\n",
      "Epoch 286/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4152 - accuracy: 0.8254 - val_loss: 0.4938 - val_accuracy: 0.8008\n",
      "Epoch 287/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4193 - accuracy: 0.8245 - val_loss: 0.4951 - val_accuracy: 0.7949\n",
      "Epoch 288/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4298 - accuracy: 0.8169 - val_loss: 0.5013 - val_accuracy: 0.7983\n",
      "Epoch 289/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4129 - accuracy: 0.8204 - val_loss: 0.4995 - val_accuracy: 0.7971\n",
      "Epoch 290/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4163 - accuracy: 0.8215 - val_loss: 0.4954 - val_accuracy: 0.8024\n",
      "Epoch 291/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4252 - accuracy: 0.8163 - val_loss: 0.5162 - val_accuracy: 0.8014\n",
      "Epoch 292/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4148 - accuracy: 0.8234 - val_loss: 0.5137 - val_accuracy: 0.7904\n",
      "Epoch 293/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4167 - accuracy: 0.8201 - val_loss: 0.5079 - val_accuracy: 0.7999\n",
      "Epoch 294/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4156 - accuracy: 0.8223 - val_loss: 0.5143 - val_accuracy: 0.7922\n",
      "Epoch 295/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4117 - accuracy: 0.8238 - val_loss: 0.5210 - val_accuracy: 0.7861\n",
      "Epoch 296/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4180 - accuracy: 0.8231 - val_loss: 0.5090 - val_accuracy: 0.7894\n",
      "Epoch 297/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4160 - accuracy: 0.8205 - val_loss: 0.5280 - val_accuracy: 0.7931\n",
      "Epoch 298/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4219 - accuracy: 0.8195 - val_loss: 0.4964 - val_accuracy: 0.7942\n",
      "Epoch 299/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4227 - accuracy: 0.8264 - val_loss: 0.4977 - val_accuracy: 0.7994\n",
      "Epoch 300/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4107 - accuracy: 0.8249 - val_loss: 0.5128 - val_accuracy: 0.7922\n",
      "Epoch 301/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4268 - accuracy: 0.8164 - val_loss: 0.4904 - val_accuracy: 0.8035\n",
      "Epoch 302/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4297 - accuracy: 0.8185 - val_loss: 0.4948 - val_accuracy: 0.7974\n",
      "Epoch 303/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4101 - accuracy: 0.8260 - val_loss: 0.5149 - val_accuracy: 0.7974\n",
      "Epoch 304/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4189 - accuracy: 0.8245 - val_loss: 0.5040 - val_accuracy: 0.7978\n",
      "Epoch 305/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4128 - accuracy: 0.8223 - val_loss: 0.4883 - val_accuracy: 0.8019\n",
      "Epoch 306/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4150 - accuracy: 0.8241 - val_loss: 0.4921 - val_accuracy: 0.8062\n",
      "Epoch 307/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8231 - val_loss: 0.4958 - val_accuracy: 0.7953\n",
      "Epoch 308/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4213 - accuracy: 0.8210 - val_loss: 0.5197 - val_accuracy: 0.7901\n",
      "Epoch 309/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4100 - accuracy: 0.8269 - val_loss: 0.5062 - val_accuracy: 0.8039\n",
      "Epoch 310/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4139 - accuracy: 0.8234 - val_loss: 0.5106 - val_accuracy: 0.7958\n",
      "Epoch 311/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8201 - val_loss: 0.4941 - val_accuracy: 0.7996\n",
      "Epoch 312/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4201 - accuracy: 0.8202 - val_loss: 0.4983 - val_accuracy: 0.7976\n",
      "Epoch 313/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4085 - accuracy: 0.8229 - val_loss: 0.4942 - val_accuracy: 0.7942\n",
      "Epoch 314/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4123 - accuracy: 0.8261 - val_loss: 0.5232 - val_accuracy: 0.7924\n",
      "Epoch 315/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4093 - accuracy: 0.8299 - val_loss: 0.5120 - val_accuracy: 0.8044\n",
      "Epoch 316/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4148 - accuracy: 0.8192 - val_loss: 0.4887 - val_accuracy: 0.8046\n",
      "Epoch 317/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4068 - accuracy: 0.8290 - val_loss: 0.4863 - val_accuracy: 0.7996\n",
      "Epoch 318/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4178 - accuracy: 0.8213 - val_loss: 0.4963 - val_accuracy: 0.7992\n",
      "Epoch 319/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4093 - accuracy: 0.8256 - val_loss: 0.4654 - val_accuracy: 0.8046\n",
      "Epoch 320/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4178 - accuracy: 0.8247 - val_loss: 0.4982 - val_accuracy: 0.7985\n",
      "Epoch 321/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4071 - accuracy: 0.8268 - val_loss: 0.4958 - val_accuracy: 0.8005\n",
      "Epoch 322/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4166 - accuracy: 0.8266 - val_loss: 0.4879 - val_accuracy: 0.8089\n",
      "Epoch 323/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4014 - accuracy: 0.8243 - val_loss: 0.4859 - val_accuracy: 0.8001\n",
      "Epoch 324/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3977 - accuracy: 0.8288 - val_loss: 0.4943 - val_accuracy: 0.7894\n",
      "Epoch 325/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4120 - accuracy: 0.8272 - val_loss: 0.5084 - val_accuracy: 0.7890\n",
      "Epoch 326/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4249 - accuracy: 0.8177 - val_loss: 0.5048 - val_accuracy: 0.7951\n",
      "Epoch 327/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4090 - accuracy: 0.8226 - val_loss: 0.5071 - val_accuracy: 0.7956\n",
      "Epoch 328/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4116 - accuracy: 0.8293 - val_loss: 0.4912 - val_accuracy: 0.8024\n",
      "Epoch 329/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4078 - accuracy: 0.8263 - val_loss: 0.5107 - val_accuracy: 0.8021\n",
      "Epoch 330/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4113 - accuracy: 0.8239 - val_loss: 0.4957 - val_accuracy: 0.8067\n",
      "Epoch 331/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4171 - accuracy: 0.8246 - val_loss: 0.4820 - val_accuracy: 0.8048\n",
      "Epoch 332/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8273 - val_loss: 0.4912 - val_accuracy: 0.8067\n",
      "Epoch 333/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4040 - accuracy: 0.8306 - val_loss: 0.4753 - val_accuracy: 0.8087\n",
      "Epoch 334/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4161 - accuracy: 0.8237 - val_loss: 0.4916 - val_accuracy: 0.7958\n",
      "Epoch 335/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4034 - accuracy: 0.8257 - val_loss: 0.4995 - val_accuracy: 0.8082\n",
      "Epoch 336/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4001 - accuracy: 0.8294 - val_loss: 0.5137 - val_accuracy: 0.7908\n",
      "Epoch 337/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4133 - accuracy: 0.8210 - val_loss: 0.5012 - val_accuracy: 0.8019\n",
      "Epoch 338/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4023 - accuracy: 0.8305 - val_loss: 0.4855 - val_accuracy: 0.7978\n",
      "Epoch 339/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4041 - accuracy: 0.8297 - val_loss: 0.4866 - val_accuracy: 0.8005\n",
      "Epoch 340/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4128 - accuracy: 0.8265 - val_loss: 0.5075 - val_accuracy: 0.7956\n",
      "Epoch 341/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4043 - accuracy: 0.8296 - val_loss: 0.4837 - val_accuracy: 0.8116\n",
      "Epoch 342/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4059 - accuracy: 0.8261 - val_loss: 0.4812 - val_accuracy: 0.8069\n",
      "Epoch 343/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8288 - val_loss: 0.4730 - val_accuracy: 0.8042\n",
      "Epoch 344/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3959 - accuracy: 0.8306 - val_loss: 0.4915 - val_accuracy: 0.8030\n",
      "Epoch 345/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3995 - accuracy: 0.8312 - val_loss: 0.4898 - val_accuracy: 0.8024\n",
      "Epoch 346/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3986 - accuracy: 0.8290 - val_loss: 0.4941 - val_accuracy: 0.7974\n",
      "Epoch 347/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8271 - val_loss: 0.5041 - val_accuracy: 0.7983\n",
      "Epoch 348/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3936 - accuracy: 0.8308 - val_loss: 0.4822 - val_accuracy: 0.8058\n",
      "Epoch 349/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3974 - accuracy: 0.8317 - val_loss: 0.5020 - val_accuracy: 0.8076\n",
      "Epoch 350/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4076 - accuracy: 0.8279 - val_loss: 0.4890 - val_accuracy: 0.8060\n",
      "Epoch 351/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4101 - accuracy: 0.8264 - val_loss: 0.4772 - val_accuracy: 0.8053\n",
      "Epoch 352/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4088 - accuracy: 0.8287 - val_loss: 0.4669 - val_accuracy: 0.8132\n",
      "Epoch 353/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3976 - accuracy: 0.8344 - val_loss: 0.4802 - val_accuracy: 0.8064\n",
      "Epoch 354/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3867 - accuracy: 0.8348 - val_loss: 0.4844 - val_accuracy: 0.8076\n",
      "Epoch 355/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4112 - accuracy: 0.8281 - val_loss: 0.4949 - val_accuracy: 0.8024\n",
      "Epoch 356/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3964 - accuracy: 0.8304 - val_loss: 0.4945 - val_accuracy: 0.8035\n",
      "Epoch 357/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.4118 - accuracy: 0.8227 - val_loss: 0.4980 - val_accuracy: 0.7985\n",
      "Epoch 358/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4104 - accuracy: 0.8289 - val_loss: 0.5079 - val_accuracy: 0.8044\n",
      "Epoch 359/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3925 - accuracy: 0.8349 - val_loss: 0.4776 - val_accuracy: 0.8173\n",
      "Epoch 360/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3932 - accuracy: 0.8324 - val_loss: 0.4903 - val_accuracy: 0.8112\n",
      "Epoch 361/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4080 - accuracy: 0.8260 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 362/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.4051 - accuracy: 0.8260 - val_loss: 0.4809 - val_accuracy: 0.8121\n",
      "Epoch 363/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3911 - accuracy: 0.8272 - val_loss: 0.4830 - val_accuracy: 0.8035\n",
      "Epoch 364/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3966 - accuracy: 0.8282 - val_loss: 0.4954 - val_accuracy: 0.7981\n",
      "Epoch 365/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3986 - accuracy: 0.8284 - val_loss: 0.4874 - val_accuracy: 0.8012\n",
      "Epoch 366/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4036 - accuracy: 0.8272 - val_loss: 0.4855 - val_accuracy: 0.8060\n",
      "Epoch 367/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3903 - accuracy: 0.8351 - val_loss: 0.4803 - val_accuracy: 0.8051\n",
      "Epoch 368/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3973 - accuracy: 0.8309 - val_loss: 0.5029 - val_accuracy: 0.8094\n",
      "Epoch 369/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4026 - accuracy: 0.8316 - val_loss: 0.4751 - val_accuracy: 0.8091\n",
      "Epoch 370/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3990 - accuracy: 0.8335 - val_loss: 0.4954 - val_accuracy: 0.8080\n",
      "Epoch 371/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8267 - val_loss: 0.4832 - val_accuracy: 0.8062\n",
      "Epoch 372/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3953 - accuracy: 0.8330 - val_loss: 0.4932 - val_accuracy: 0.8096\n",
      "Epoch 373/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4045 - accuracy: 0.8279 - val_loss: 0.4907 - val_accuracy: 0.8067\n",
      "Epoch 374/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4070 - accuracy: 0.8308 - val_loss: 0.4851 - val_accuracy: 0.8078\n",
      "Epoch 375/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3919 - accuracy: 0.8380 - val_loss: 0.4939 - val_accuracy: 0.8069\n",
      "Epoch 376/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3968 - accuracy: 0.8310 - val_loss: 0.4923 - val_accuracy: 0.7990\n",
      "Epoch 377/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3964 - accuracy: 0.8317 - val_loss: 0.4920 - val_accuracy: 0.8073\n",
      "Epoch 378/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8328 - val_loss: 0.4757 - val_accuracy: 0.8148\n",
      "Epoch 379/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3882 - accuracy: 0.8336 - val_loss: 0.4736 - val_accuracy: 0.8157\n",
      "Epoch 380/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3894 - accuracy: 0.8333 - val_loss: 0.4926 - val_accuracy: 0.8137\n",
      "Epoch 381/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3854 - accuracy: 0.8390 - val_loss: 0.4770 - val_accuracy: 0.8123\n",
      "Epoch 382/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3943 - accuracy: 0.8355 - val_loss: 0.4965 - val_accuracy: 0.8134\n",
      "Epoch 383/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3931 - accuracy: 0.8353 - val_loss: 0.4834 - val_accuracy: 0.8150\n",
      "Epoch 384/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3957 - accuracy: 0.8331 - val_loss: 0.4926 - val_accuracy: 0.8069\n",
      "Epoch 385/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3988 - accuracy: 0.8328 - val_loss: 0.5076 - val_accuracy: 0.8073\n",
      "Epoch 386/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3926 - accuracy: 0.8333 - val_loss: 0.4748 - val_accuracy: 0.8051\n",
      "Epoch 387/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3931 - accuracy: 0.8298 - val_loss: 0.4999 - val_accuracy: 0.8028\n",
      "Epoch 388/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3937 - accuracy: 0.8316 - val_loss: 0.4895 - val_accuracy: 0.8078\n",
      "Epoch 389/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4038 - accuracy: 0.8317 - val_loss: 0.4733 - val_accuracy: 0.8132\n",
      "Epoch 390/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3990 - accuracy: 0.8297 - val_loss: 0.4790 - val_accuracy: 0.8060\n",
      "Epoch 391/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3918 - accuracy: 0.8395 - val_loss: 0.5030 - val_accuracy: 0.8064\n",
      "Epoch 392/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3919 - accuracy: 0.8331 - val_loss: 0.4796 - val_accuracy: 0.8175\n",
      "Epoch 393/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3911 - accuracy: 0.8353 - val_loss: 0.4630 - val_accuracy: 0.8148\n",
      "Epoch 394/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8346 - val_loss: 0.5021 - val_accuracy: 0.8091\n",
      "Epoch 395/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3917 - accuracy: 0.8395 - val_loss: 0.4867 - val_accuracy: 0.8164\n",
      "Epoch 396/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3911 - accuracy: 0.8382 - val_loss: 0.4927 - val_accuracy: 0.8114\n",
      "Epoch 397/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.4010 - accuracy: 0.8355 - val_loss: 0.4958 - val_accuracy: 0.8080\n",
      "Epoch 398/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3948 - accuracy: 0.8336 - val_loss: 0.4749 - val_accuracy: 0.8098\n",
      "Epoch 399/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3998 - accuracy: 0.8350 - val_loss: 0.4659 - val_accuracy: 0.8209\n",
      "Epoch 400/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3978 - accuracy: 0.8301 - val_loss: 0.4616 - val_accuracy: 0.8225\n",
      "Epoch 401/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3928 - accuracy: 0.8333 - val_loss: 0.4731 - val_accuracy: 0.8155\n",
      "Epoch 402/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3915 - accuracy: 0.8345 - val_loss: 0.4885 - val_accuracy: 0.8103\n",
      "Epoch 403/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3792 - accuracy: 0.8415 - val_loss: 0.4582 - val_accuracy: 0.8150\n",
      "Epoch 404/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3818 - accuracy: 0.8381 - val_loss: 0.4747 - val_accuracy: 0.8085\n",
      "Epoch 405/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3893 - accuracy: 0.8326 - val_loss: 0.4628 - val_accuracy: 0.8180\n",
      "Epoch 406/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3849 - accuracy: 0.8376 - val_loss: 0.4835 - val_accuracy: 0.8121\n",
      "Epoch 407/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3954 - accuracy: 0.8346 - val_loss: 0.4762 - val_accuracy: 0.8071\n",
      "Epoch 408/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3895 - accuracy: 0.8315 - val_loss: 0.4691 - val_accuracy: 0.8164\n",
      "Epoch 409/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3846 - accuracy: 0.8377 - val_loss: 0.4728 - val_accuracy: 0.8173\n",
      "Epoch 410/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3854 - accuracy: 0.8390 - val_loss: 0.4829 - val_accuracy: 0.8119\n",
      "Epoch 411/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3872 - accuracy: 0.8329 - val_loss: 0.4848 - val_accuracy: 0.8123\n",
      "Epoch 412/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3807 - accuracy: 0.8380 - val_loss: 0.4619 - val_accuracy: 0.8200\n",
      "Epoch 413/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3766 - accuracy: 0.8398 - val_loss: 0.4589 - val_accuracy: 0.8146\n",
      "Epoch 414/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3919 - accuracy: 0.8360 - val_loss: 0.4812 - val_accuracy: 0.8189\n",
      "Epoch 415/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3912 - accuracy: 0.8356 - val_loss: 0.4787 - val_accuracy: 0.8044\n",
      "Epoch 416/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3864 - accuracy: 0.8377 - val_loss: 0.4639 - val_accuracy: 0.8139\n",
      "Epoch 417/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3981 - accuracy: 0.8343 - val_loss: 0.4684 - val_accuracy: 0.8139\n",
      "Epoch 418/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3906 - accuracy: 0.8342 - val_loss: 0.4785 - val_accuracy: 0.8098\n",
      "Epoch 419/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3876 - accuracy: 0.8372 - val_loss: 0.4804 - val_accuracy: 0.8101\n",
      "Epoch 420/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3666 - accuracy: 0.8453 - val_loss: 0.4967 - val_accuracy: 0.8159\n",
      "Epoch 421/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3756 - accuracy: 0.8432 - val_loss: 0.4895 - val_accuracy: 0.8019\n",
      "Epoch 422/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3907 - accuracy: 0.8348 - val_loss: 0.4965 - val_accuracy: 0.8085\n",
      "Epoch 423/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3858 - accuracy: 0.8387 - val_loss: 0.4699 - val_accuracy: 0.8232\n",
      "Epoch 424/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3831 - accuracy: 0.8383 - val_loss: 0.4673 - val_accuracy: 0.8091\n",
      "Epoch 425/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3865 - accuracy: 0.8402 - val_loss: 0.4908 - val_accuracy: 0.8132\n",
      "Epoch 426/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3788 - accuracy: 0.8387 - val_loss: 0.4742 - val_accuracy: 0.8182\n",
      "Epoch 427/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3935 - accuracy: 0.8386 - val_loss: 0.4797 - val_accuracy: 0.8132\n",
      "Epoch 428/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.4852 - val_accuracy: 0.8121\n",
      "Epoch 429/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3908 - accuracy: 0.8333 - val_loss: 0.4732 - val_accuracy: 0.8175\n",
      "Epoch 430/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3759 - accuracy: 0.8385 - val_loss: 0.4910 - val_accuracy: 0.8166\n",
      "Epoch 431/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3992 - accuracy: 0.8332 - val_loss: 0.4585 - val_accuracy: 0.8275\n",
      "Epoch 432/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3863 - accuracy: 0.8393 - val_loss: 0.4557 - val_accuracy: 0.8164\n",
      "Epoch 433/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3831 - accuracy: 0.8377 - val_loss: 0.4689 - val_accuracy: 0.8146\n",
      "Epoch 434/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3884 - accuracy: 0.8348 - val_loss: 0.4585 - val_accuracy: 0.8159\n",
      "Epoch 435/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3832 - accuracy: 0.8372 - val_loss: 0.4600 - val_accuracy: 0.8141\n",
      "Epoch 436/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3833 - accuracy: 0.8425 - val_loss: 0.4993 - val_accuracy: 0.8021\n",
      "Epoch 437/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3797 - accuracy: 0.8374 - val_loss: 0.4802 - val_accuracy: 0.8128\n",
      "Epoch 438/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3839 - accuracy: 0.8364 - val_loss: 0.4618 - val_accuracy: 0.8168\n",
      "Epoch 439/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3730 - accuracy: 0.8387 - val_loss: 0.4942 - val_accuracy: 0.8105\n",
      "Epoch 440/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3808 - accuracy: 0.8361 - val_loss: 0.4883 - val_accuracy: 0.8171\n",
      "Epoch 441/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3882 - accuracy: 0.8343 - val_loss: 0.4961 - val_accuracy: 0.8110\n",
      "Epoch 442/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3836 - accuracy: 0.8401 - val_loss: 0.4548 - val_accuracy: 0.8254\n",
      "Epoch 443/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3800 - accuracy: 0.8381 - val_loss: 0.4732 - val_accuracy: 0.8205\n",
      "Epoch 444/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3971 - accuracy: 0.8325 - val_loss: 0.4644 - val_accuracy: 0.8198\n",
      "Epoch 445/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3698 - accuracy: 0.8452 - val_loss: 0.4912 - val_accuracy: 0.8175\n",
      "Epoch 446/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3963 - accuracy: 0.8341 - val_loss: 0.4592 - val_accuracy: 0.8189\n",
      "Epoch 447/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3817 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.8137\n",
      "Epoch 448/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3860 - accuracy: 0.8386 - val_loss: 0.4559 - val_accuracy: 0.8193\n",
      "Epoch 449/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3834 - accuracy: 0.8353 - val_loss: 0.4506 - val_accuracy: 0.8211\n",
      "Epoch 450/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3772 - accuracy: 0.8423 - val_loss: 0.4665 - val_accuracy: 0.8150\n",
      "Epoch 451/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3806 - accuracy: 0.8426 - val_loss: 0.4674 - val_accuracy: 0.8164\n",
      "Epoch 452/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3791 - accuracy: 0.8398 - val_loss: 0.4492 - val_accuracy: 0.8193\n",
      "Epoch 453/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3816 - accuracy: 0.8414 - val_loss: 0.4719 - val_accuracy: 0.8121\n",
      "Epoch 454/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3791 - accuracy: 0.8409 - val_loss: 0.4762 - val_accuracy: 0.8175\n",
      "Epoch 455/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3805 - accuracy: 0.8420 - val_loss: 0.4713 - val_accuracy: 0.8198\n",
      "Epoch 456/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3867 - accuracy: 0.8364 - val_loss: 0.4710 - val_accuracy: 0.8164\n",
      "Epoch 457/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3812 - accuracy: 0.8455 - val_loss: 0.4723 - val_accuracy: 0.8112\n",
      "Epoch 458/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3903 - accuracy: 0.8337 - val_loss: 0.4684 - val_accuracy: 0.8216\n",
      "Epoch 459/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3729 - accuracy: 0.8427 - val_loss: 0.4539 - val_accuracy: 0.8236\n",
      "Epoch 460/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3726 - accuracy: 0.8439 - val_loss: 0.4619 - val_accuracy: 0.8175\n",
      "Epoch 461/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3791 - accuracy: 0.8387 - val_loss: 0.4494 - val_accuracy: 0.8252\n",
      "Epoch 462/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3734 - accuracy: 0.8426 - val_loss: 0.4629 - val_accuracy: 0.8196\n",
      "Epoch 463/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3750 - accuracy: 0.8375 - val_loss: 0.4746 - val_accuracy: 0.8187\n",
      "Epoch 464/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3702 - accuracy: 0.8457 - val_loss: 0.4669 - val_accuracy: 0.8198\n",
      "Epoch 465/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3875 - accuracy: 0.8370 - val_loss: 0.4546 - val_accuracy: 0.8216\n",
      "Epoch 466/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3724 - accuracy: 0.8447 - val_loss: 0.4802 - val_accuracy: 0.8209\n",
      "Epoch 467/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3861 - accuracy: 0.8388 - val_loss: 0.4671 - val_accuracy: 0.8200\n",
      "Epoch 468/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3836 - accuracy: 0.8370 - val_loss: 0.4565 - val_accuracy: 0.8223\n",
      "Epoch 469/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3827 - accuracy: 0.8397 - val_loss: 0.4652 - val_accuracy: 0.8148\n",
      "Epoch 470/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3782 - accuracy: 0.8429 - val_loss: 0.4707 - val_accuracy: 0.8209\n",
      "Epoch 471/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3788 - accuracy: 0.8399 - val_loss: 0.4887 - val_accuracy: 0.8223\n",
      "Epoch 472/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3767 - accuracy: 0.8428 - val_loss: 0.4593 - val_accuracy: 0.8223\n",
      "Epoch 473/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3872 - accuracy: 0.8363 - val_loss: 0.4520 - val_accuracy: 0.8225\n",
      "Epoch 474/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3704 - accuracy: 0.8428 - val_loss: 0.5085 - val_accuracy: 0.8085\n",
      "Epoch 475/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3722 - accuracy: 0.8420 - val_loss: 0.5005 - val_accuracy: 0.8177\n",
      "Epoch 476/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3847 - accuracy: 0.8419 - val_loss: 0.4519 - val_accuracy: 0.8245\n",
      "Epoch 477/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3798 - accuracy: 0.8408 - val_loss: 0.4720 - val_accuracy: 0.8252\n",
      "Epoch 478/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3790 - accuracy: 0.8405 - val_loss: 0.4527 - val_accuracy: 0.8248\n",
      "Epoch 479/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3803 - accuracy: 0.8417 - val_loss: 0.4622 - val_accuracy: 0.8270\n",
      "Epoch 480/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3779 - accuracy: 0.8423 - val_loss: 0.4641 - val_accuracy: 0.8236\n",
      "Epoch 481/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3827 - accuracy: 0.8399 - val_loss: 0.4513 - val_accuracy: 0.8252\n",
      "Epoch 482/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3688 - accuracy: 0.8449 - val_loss: 0.4909 - val_accuracy: 0.8171\n",
      "Epoch 483/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3689 - accuracy: 0.8479 - val_loss: 0.4682 - val_accuracy: 0.8270\n",
      "Epoch 484/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8363 - val_loss: 0.4634 - val_accuracy: 0.8313\n",
      "Epoch 485/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3706 - accuracy: 0.8435 - val_loss: 0.4546 - val_accuracy: 0.8264\n",
      "Epoch 486/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3750 - accuracy: 0.8460 - val_loss: 0.4772 - val_accuracy: 0.8134\n",
      "Epoch 487/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3805 - accuracy: 0.8415 - val_loss: 0.4603 - val_accuracy: 0.8211\n",
      "Epoch 488/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3734 - accuracy: 0.8480 - val_loss: 0.4857 - val_accuracy: 0.8243\n",
      "Epoch 489/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3690 - accuracy: 0.8490 - val_loss: 0.4627 - val_accuracy: 0.8207\n",
      "Epoch 490/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3789 - accuracy: 0.8363 - val_loss: 0.4675 - val_accuracy: 0.8236\n",
      "Epoch 491/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3730 - accuracy: 0.8451 - val_loss: 0.4523 - val_accuracy: 0.8320\n",
      "Epoch 492/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3659 - accuracy: 0.8475 - val_loss: 0.4479 - val_accuracy: 0.8209\n",
      "Epoch 493/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3592 - accuracy: 0.8475 - val_loss: 0.4609 - val_accuracy: 0.8268\n",
      "Epoch 494/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3768 - accuracy: 0.8440 - val_loss: 0.4615 - val_accuracy: 0.8211\n",
      "Epoch 495/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8420 - val_loss: 0.4533 - val_accuracy: 0.8227\n",
      "Epoch 496/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3726 - accuracy: 0.8493 - val_loss: 0.4732 - val_accuracy: 0.8291\n",
      "Epoch 497/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3581 - accuracy: 0.8495 - val_loss: 0.4828 - val_accuracy: 0.8184\n",
      "Epoch 498/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3678 - accuracy: 0.8471 - val_loss: 0.4543 - val_accuracy: 0.8241\n",
      "Epoch 499/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3619 - accuracy: 0.8473 - val_loss: 0.4490 - val_accuracy: 0.8284\n",
      "Epoch 500/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3793 - accuracy: 0.8423 - val_loss: 0.4721 - val_accuracy: 0.8125\n",
      "Epoch 501/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3627 - accuracy: 0.8458 - val_loss: 0.4615 - val_accuracy: 0.8162\n",
      "Epoch 502/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3710 - accuracy: 0.8469 - val_loss: 0.4636 - val_accuracy: 0.8304\n",
      "Epoch 503/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3740 - accuracy: 0.8419 - val_loss: 0.4581 - val_accuracy: 0.8275\n",
      "Epoch 504/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3786 - accuracy: 0.8410 - val_loss: 0.4563 - val_accuracy: 0.8202\n",
      "Epoch 505/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3701 - accuracy: 0.8411 - val_loss: 0.4660 - val_accuracy: 0.8236\n",
      "Epoch 506/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3680 - accuracy: 0.8473 - val_loss: 0.4823 - val_accuracy: 0.8146\n",
      "Epoch 507/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3751 - accuracy: 0.8402 - val_loss: 0.4694 - val_accuracy: 0.8270\n",
      "Epoch 508/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3637 - accuracy: 0.8483 - val_loss: 0.4659 - val_accuracy: 0.8275\n",
      "Epoch 509/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3634 - accuracy: 0.8479 - val_loss: 0.4599 - val_accuracy: 0.8279\n",
      "Epoch 510/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3604 - accuracy: 0.8478 - val_loss: 0.4651 - val_accuracy: 0.8209\n",
      "Epoch 511/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3689 - accuracy: 0.8453 - val_loss: 0.4655 - val_accuracy: 0.8221\n",
      "Epoch 512/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3620 - accuracy: 0.8467 - val_loss: 0.4644 - val_accuracy: 0.8162\n",
      "Epoch 513/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3713 - accuracy: 0.8459 - val_loss: 0.4659 - val_accuracy: 0.8273\n",
      "Epoch 514/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3689 - accuracy: 0.8467 - val_loss: 0.4620 - val_accuracy: 0.8141\n",
      "Epoch 515/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3827 - accuracy: 0.8364 - val_loss: 0.4794 - val_accuracy: 0.8241\n",
      "Epoch 516/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3625 - accuracy: 0.8480 - val_loss: 0.4440 - val_accuracy: 0.8264\n",
      "Epoch 517/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3768 - accuracy: 0.8415 - val_loss: 0.4537 - val_accuracy: 0.8266\n",
      "Epoch 518/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3673 - accuracy: 0.8466 - val_loss: 0.4596 - val_accuracy: 0.8209\n",
      "Epoch 519/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3655 - accuracy: 0.8496 - val_loss: 0.4481 - val_accuracy: 0.8300\n",
      "Epoch 520/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3663 - accuracy: 0.8455 - val_loss: 0.4552 - val_accuracy: 0.8309\n",
      "Epoch 521/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8456 - val_loss: 0.4539 - val_accuracy: 0.8216\n",
      "Epoch 522/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3644 - accuracy: 0.8461 - val_loss: 0.4563 - val_accuracy: 0.8264\n",
      "Epoch 523/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3615 - accuracy: 0.8488 - val_loss: 0.4677 - val_accuracy: 0.8284\n",
      "Epoch 524/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3652 - accuracy: 0.8480 - val_loss: 0.4507 - val_accuracy: 0.8288\n",
      "Epoch 525/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3763 - accuracy: 0.8460 - val_loss: 0.4555 - val_accuracy: 0.8300\n",
      "Epoch 526/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3715 - accuracy: 0.8445 - val_loss: 0.4438 - val_accuracy: 0.8245\n",
      "Epoch 527/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3563 - accuracy: 0.8514 - val_loss: 0.4631 - val_accuracy: 0.8150\n",
      "Epoch 528/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3747 - accuracy: 0.8402 - val_loss: 0.4693 - val_accuracy: 0.8264\n",
      "Epoch 529/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3603 - accuracy: 0.8505 - val_loss: 0.4558 - val_accuracy: 0.8334\n",
      "Epoch 530/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3755 - accuracy: 0.8391 - val_loss: 0.4607 - val_accuracy: 0.8329\n",
      "Epoch 531/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3712 - accuracy: 0.8494 - val_loss: 0.4650 - val_accuracy: 0.8166\n",
      "Epoch 532/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3651 - accuracy: 0.8454 - val_loss: 0.4614 - val_accuracy: 0.8218\n",
      "Epoch 533/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3565 - accuracy: 0.8491 - val_loss: 0.4646 - val_accuracy: 0.8225\n",
      "Epoch 534/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3686 - accuracy: 0.8473 - val_loss: 0.4678 - val_accuracy: 0.8196\n",
      "Epoch 535/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3682 - accuracy: 0.8435 - val_loss: 0.4688 - val_accuracy: 0.8302\n",
      "Epoch 536/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3603 - accuracy: 0.8527 - val_loss: 0.4569 - val_accuracy: 0.8311\n",
      "Epoch 537/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3720 - accuracy: 0.8422 - val_loss: 0.4653 - val_accuracy: 0.8254\n",
      "Epoch 538/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3695 - accuracy: 0.8439 - val_loss: 0.4584 - val_accuracy: 0.8218\n",
      "Epoch 539/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3650 - accuracy: 0.8501 - val_loss: 0.4678 - val_accuracy: 0.8275\n",
      "Epoch 540/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3637 - accuracy: 0.8463 - val_loss: 0.4566 - val_accuracy: 0.8257\n",
      "Epoch 541/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3645 - accuracy: 0.8468 - val_loss: 0.4406 - val_accuracy: 0.8327\n",
      "Epoch 542/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3668 - accuracy: 0.8500 - val_loss: 0.4616 - val_accuracy: 0.8297\n",
      "Epoch 543/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3768 - accuracy: 0.8421 - val_loss: 0.4592 - val_accuracy: 0.8343\n",
      "Epoch 544/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3646 - accuracy: 0.8433 - val_loss: 0.4574 - val_accuracy: 0.8322\n",
      "Epoch 545/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3551 - accuracy: 0.8505 - val_loss: 0.4795 - val_accuracy: 0.8248\n",
      "Epoch 546/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3589 - accuracy: 0.8478 - val_loss: 0.4519 - val_accuracy: 0.8248\n",
      "Epoch 547/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3714 - accuracy: 0.8414 - val_loss: 0.4533 - val_accuracy: 0.8359\n",
      "Epoch 548/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3535 - accuracy: 0.8555 - val_loss: 0.4551 - val_accuracy: 0.8189\n",
      "Epoch 549/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3625 - accuracy: 0.8455 - val_loss: 0.4688 - val_accuracy: 0.8216\n",
      "Epoch 550/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3621 - accuracy: 0.8467 - val_loss: 0.4703 - val_accuracy: 0.8164\n",
      "Epoch 551/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3695 - accuracy: 0.8408 - val_loss: 0.4712 - val_accuracy: 0.8159\n",
      "Epoch 552/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3674 - accuracy: 0.8467 - val_loss: 0.4884 - val_accuracy: 0.8264\n",
      "Epoch 553/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3602 - accuracy: 0.8485 - val_loss: 0.4622 - val_accuracy: 0.8225\n",
      "Epoch 554/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3747 - accuracy: 0.8440 - val_loss: 0.4574 - val_accuracy: 0.8230\n",
      "Epoch 555/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3625 - accuracy: 0.8461 - val_loss: 0.4738 - val_accuracy: 0.8214\n",
      "Epoch 556/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3662 - accuracy: 0.8478 - val_loss: 0.4565 - val_accuracy: 0.8304\n",
      "Epoch 557/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3644 - accuracy: 0.8481 - val_loss: 0.4677 - val_accuracy: 0.8221\n",
      "Epoch 558/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3677 - accuracy: 0.8447 - val_loss: 0.4538 - val_accuracy: 0.8297\n",
      "Epoch 559/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3644 - accuracy: 0.8446 - val_loss: 0.4496 - val_accuracy: 0.8277\n",
      "Epoch 560/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3566 - accuracy: 0.8544 - val_loss: 0.4348 - val_accuracy: 0.8325\n",
      "Epoch 561/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3630 - accuracy: 0.8469 - val_loss: 0.4400 - val_accuracy: 0.8350\n",
      "Epoch 562/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3504 - accuracy: 0.8527 - val_loss: 0.4480 - val_accuracy: 0.8270\n",
      "Epoch 563/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3602 - accuracy: 0.8520 - val_loss: 0.4555 - val_accuracy: 0.8307\n",
      "Epoch 564/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3484 - accuracy: 0.8538 - val_loss: 0.4877 - val_accuracy: 0.8177\n",
      "Epoch 565/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3722 - accuracy: 0.8447 - val_loss: 0.4724 - val_accuracy: 0.8196\n",
      "Epoch 566/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3664 - accuracy: 0.8487 - val_loss: 0.4585 - val_accuracy: 0.8331\n",
      "Epoch 567/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3722 - accuracy: 0.8439 - val_loss: 0.4643 - val_accuracy: 0.8241\n",
      "Epoch 568/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3615 - accuracy: 0.8491 - val_loss: 0.4581 - val_accuracy: 0.8334\n",
      "Epoch 569/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3627 - accuracy: 0.8503 - val_loss: 0.4498 - val_accuracy: 0.8302\n",
      "Epoch 570/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3618 - accuracy: 0.8503 - val_loss: 0.4665 - val_accuracy: 0.8309\n",
      "Epoch 571/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3509 - accuracy: 0.8521 - val_loss: 0.4569 - val_accuracy: 0.8273\n",
      "Epoch 572/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3673 - accuracy: 0.8452 - val_loss: 0.4596 - val_accuracy: 0.8264\n",
      "Epoch 573/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3668 - accuracy: 0.8480 - val_loss: 0.4492 - val_accuracy: 0.8277\n",
      "Epoch 574/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3583 - accuracy: 0.8491 - val_loss: 0.4400 - val_accuracy: 0.8318\n",
      "Epoch 575/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3525 - accuracy: 0.8519 - val_loss: 0.4563 - val_accuracy: 0.8334\n",
      "Epoch 576/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3539 - accuracy: 0.8533 - val_loss: 0.4579 - val_accuracy: 0.8325\n",
      "Epoch 577/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3485 - accuracy: 0.8551 - val_loss: 0.4338 - val_accuracy: 0.8336\n",
      "Epoch 578/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3580 - accuracy: 0.8519 - val_loss: 0.4550 - val_accuracy: 0.8331\n",
      "Epoch 579/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3557 - accuracy: 0.8505 - val_loss: 0.4592 - val_accuracy: 0.8264\n",
      "Epoch 580/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3622 - accuracy: 0.8472 - val_loss: 0.4672 - val_accuracy: 0.8225\n",
      "Epoch 581/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3654 - accuracy: 0.8466 - val_loss: 0.4744 - val_accuracy: 0.8282\n",
      "Epoch 582/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3635 - accuracy: 0.8491 - val_loss: 0.4510 - val_accuracy: 0.8386\n",
      "Epoch 583/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3752 - accuracy: 0.8448 - val_loss: 0.4420 - val_accuracy: 0.8293\n",
      "Epoch 584/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3515 - accuracy: 0.8562 - val_loss: 0.4759 - val_accuracy: 0.8230\n",
      "Epoch 585/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3643 - accuracy: 0.8485 - val_loss: 0.4450 - val_accuracy: 0.8264\n",
      "Epoch 586/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3628 - accuracy: 0.8460 - val_loss: 0.4291 - val_accuracy: 0.8388\n",
      "Epoch 587/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3677 - accuracy: 0.8488 - val_loss: 0.4427 - val_accuracy: 0.8338\n",
      "Epoch 588/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3572 - accuracy: 0.8488 - val_loss: 0.4416 - val_accuracy: 0.8354\n",
      "Epoch 589/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3521 - accuracy: 0.8533 - val_loss: 0.4428 - val_accuracy: 0.8329\n",
      "Epoch 590/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3588 - accuracy: 0.8500 - val_loss: 0.4491 - val_accuracy: 0.8155\n",
      "Epoch 591/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3645 - accuracy: 0.8476 - val_loss: 0.4447 - val_accuracy: 0.8325\n",
      "Epoch 592/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3562 - accuracy: 0.8502 - val_loss: 0.4618 - val_accuracy: 0.8311\n",
      "Epoch 593/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3601 - accuracy: 0.8498 - val_loss: 0.4616 - val_accuracy: 0.8363\n",
      "Epoch 594/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3618 - accuracy: 0.8493 - val_loss: 0.4488 - val_accuracy: 0.8329\n",
      "Epoch 595/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3628 - accuracy: 0.8506 - val_loss: 0.4441 - val_accuracy: 0.8329\n",
      "Epoch 596/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3527 - accuracy: 0.8524 - val_loss: 0.4359 - val_accuracy: 0.8291\n",
      "Epoch 597/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3551 - accuracy: 0.8500 - val_loss: 0.4604 - val_accuracy: 0.8300\n",
      "Epoch 598/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8510 - val_loss: 0.4447 - val_accuracy: 0.8354\n",
      "Epoch 599/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3615 - accuracy: 0.8520 - val_loss: 0.4547 - val_accuracy: 0.8320\n",
      "Epoch 600/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3579 - accuracy: 0.8518 - val_loss: 0.4558 - val_accuracy: 0.8356\n",
      "Epoch 601/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3613 - accuracy: 0.8531 - val_loss: 0.4432 - val_accuracy: 0.8393\n",
      "Epoch 602/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3595 - accuracy: 0.8511 - val_loss: 0.4385 - val_accuracy: 0.8266\n",
      "Epoch 603/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3549 - accuracy: 0.8525 - val_loss: 0.4474 - val_accuracy: 0.8384\n",
      "Epoch 604/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3565 - accuracy: 0.8524 - val_loss: 0.4490 - val_accuracy: 0.8352\n",
      "Epoch 605/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3524 - accuracy: 0.8555 - val_loss: 0.4550 - val_accuracy: 0.8320\n",
      "Epoch 606/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3572 - accuracy: 0.8494 - val_loss: 0.4682 - val_accuracy: 0.8180\n",
      "Epoch 607/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3430 - accuracy: 0.8596 - val_loss: 0.4735 - val_accuracy: 0.8309\n",
      "Epoch 608/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3496 - accuracy: 0.8560 - val_loss: 0.4491 - val_accuracy: 0.8384\n",
      "Epoch 609/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3629 - accuracy: 0.8478 - val_loss: 0.4497 - val_accuracy: 0.8288\n",
      "Epoch 610/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3641 - accuracy: 0.8458 - val_loss: 0.4429 - val_accuracy: 0.8277\n",
      "Epoch 611/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3426 - accuracy: 0.8592 - val_loss: 0.4511 - val_accuracy: 0.8354\n",
      "Epoch 612/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3478 - accuracy: 0.8564 - val_loss: 0.4524 - val_accuracy: 0.8268\n",
      "Epoch 613/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3487 - accuracy: 0.8591 - val_loss: 0.4551 - val_accuracy: 0.8381\n",
      "Epoch 614/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3611 - accuracy: 0.8509 - val_loss: 0.4641 - val_accuracy: 0.8214\n",
      "Epoch 615/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3506 - accuracy: 0.8515 - val_loss: 0.4380 - val_accuracy: 0.8411\n",
      "Epoch 616/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3502 - accuracy: 0.8562 - val_loss: 0.4540 - val_accuracy: 0.8223\n",
      "Epoch 617/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3433 - accuracy: 0.8552 - val_loss: 0.4416 - val_accuracy: 0.8399\n",
      "Epoch 618/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3511 - accuracy: 0.8527 - val_loss: 0.4644 - val_accuracy: 0.8338\n",
      "Epoch 619/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3725 - accuracy: 0.8447 - val_loss: 0.4316 - val_accuracy: 0.8336\n",
      "Epoch 620/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3462 - accuracy: 0.8539 - val_loss: 0.4463 - val_accuracy: 0.8309\n",
      "Epoch 621/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3531 - accuracy: 0.8530 - val_loss: 0.4447 - val_accuracy: 0.8350\n",
      "Epoch 622/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3539 - accuracy: 0.8538 - val_loss: 0.4516 - val_accuracy: 0.8354\n",
      "Epoch 623/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3462 - accuracy: 0.8565 - val_loss: 0.4583 - val_accuracy: 0.8377\n",
      "Epoch 624/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3600 - accuracy: 0.8520 - val_loss: 0.4434 - val_accuracy: 0.8354\n",
      "Epoch 625/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3487 - accuracy: 0.8557 - val_loss: 0.4707 - val_accuracy: 0.8320\n",
      "Epoch 626/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3506 - accuracy: 0.8512 - val_loss: 0.4474 - val_accuracy: 0.8347\n",
      "Epoch 627/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3531 - accuracy: 0.8538 - val_loss: 0.4360 - val_accuracy: 0.8402\n",
      "Epoch 628/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3567 - accuracy: 0.8498 - val_loss: 0.4546 - val_accuracy: 0.8368\n",
      "Epoch 629/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3559 - accuracy: 0.8564 - val_loss: 0.4536 - val_accuracy: 0.8309\n",
      "Epoch 630/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3505 - accuracy: 0.8544 - val_loss: 0.4484 - val_accuracy: 0.8347\n",
      "Epoch 631/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3451 - accuracy: 0.8595 - val_loss: 0.4482 - val_accuracy: 0.8302\n",
      "Epoch 632/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3491 - accuracy: 0.8525 - val_loss: 0.4336 - val_accuracy: 0.8379\n",
      "Epoch 633/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3586 - accuracy: 0.8545 - val_loss: 0.4679 - val_accuracy: 0.8302\n",
      "Epoch 634/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3524 - accuracy: 0.8520 - val_loss: 0.4421 - val_accuracy: 0.8352\n",
      "Epoch 635/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3483 - accuracy: 0.8486 - val_loss: 0.4589 - val_accuracy: 0.8313\n",
      "Epoch 636/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3531 - accuracy: 0.8529 - val_loss: 0.4463 - val_accuracy: 0.8302\n",
      "Epoch 637/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3500 - accuracy: 0.8555 - val_loss: 0.4433 - val_accuracy: 0.8370\n",
      "Epoch 638/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3538 - accuracy: 0.8523 - val_loss: 0.4451 - val_accuracy: 0.8313\n",
      "Epoch 639/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3583 - accuracy: 0.8485 - val_loss: 0.4549 - val_accuracy: 0.8361\n",
      "Epoch 640/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3596 - accuracy: 0.8502 - val_loss: 0.4561 - val_accuracy: 0.8322\n",
      "Epoch 641/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3683 - accuracy: 0.8494 - val_loss: 0.4401 - val_accuracy: 0.8322\n",
      "Epoch 642/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3443 - accuracy: 0.8556 - val_loss: 0.4386 - val_accuracy: 0.8327\n",
      "Epoch 643/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3536 - accuracy: 0.8546 - val_loss: 0.4471 - val_accuracy: 0.8424\n",
      "Epoch 644/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3394 - accuracy: 0.8610 - val_loss: 0.4502 - val_accuracy: 0.8325\n",
      "Epoch 645/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3431 - accuracy: 0.8584 - val_loss: 0.4409 - val_accuracy: 0.8399\n",
      "Epoch 646/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3533 - accuracy: 0.8549 - val_loss: 0.4457 - val_accuracy: 0.8341\n",
      "Epoch 647/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3488 - accuracy: 0.8539 - val_loss: 0.4563 - val_accuracy: 0.8307\n",
      "Epoch 648/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3500 - accuracy: 0.8520 - val_loss: 0.4431 - val_accuracy: 0.8356\n",
      "Epoch 649/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3481 - accuracy: 0.8564 - val_loss: 0.4398 - val_accuracy: 0.8343\n",
      "Epoch 650/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3470 - accuracy: 0.8572 - val_loss: 0.4426 - val_accuracy: 0.8381\n",
      "Epoch 651/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3431 - accuracy: 0.8594 - val_loss: 0.4476 - val_accuracy: 0.8279\n",
      "Epoch 652/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3543 - accuracy: 0.8524 - val_loss: 0.4274 - val_accuracy: 0.8470\n",
      "Epoch 653/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3554 - accuracy: 0.8522 - val_loss: 0.4453 - val_accuracy: 0.8354\n",
      "Epoch 654/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3501 - accuracy: 0.8541 - val_loss: 0.4313 - val_accuracy: 0.8329\n",
      "Epoch 655/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3446 - accuracy: 0.8559 - val_loss: 0.4514 - val_accuracy: 0.8356\n",
      "Epoch 656/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3627 - accuracy: 0.8507 - val_loss: 0.4381 - val_accuracy: 0.8427\n",
      "Epoch 657/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3430 - accuracy: 0.8619 - val_loss: 0.4431 - val_accuracy: 0.8384\n",
      "Epoch 658/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3508 - accuracy: 0.8537 - val_loss: 0.4379 - val_accuracy: 0.8411\n",
      "Epoch 659/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3527 - accuracy: 0.8580 - val_loss: 0.4541 - val_accuracy: 0.8350\n",
      "Epoch 660/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3456 - accuracy: 0.8543 - val_loss: 0.4490 - val_accuracy: 0.8309\n",
      "Epoch 661/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3427 - accuracy: 0.8565 - val_loss: 0.4541 - val_accuracy: 0.8266\n",
      "Epoch 662/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3363 - accuracy: 0.8589 - val_loss: 0.4321 - val_accuracy: 0.8386\n",
      "Epoch 663/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3528 - accuracy: 0.8572 - val_loss: 0.4454 - val_accuracy: 0.8363\n",
      "Epoch 664/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3397 - accuracy: 0.8604 - val_loss: 0.4391 - val_accuracy: 0.8374\n",
      "Epoch 665/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3425 - accuracy: 0.8565 - val_loss: 0.4336 - val_accuracy: 0.8372\n",
      "Epoch 666/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3330 - accuracy: 0.8608 - val_loss: 0.4459 - val_accuracy: 0.8390\n",
      "Epoch 667/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3581 - accuracy: 0.8495 - val_loss: 0.4515 - val_accuracy: 0.8356\n",
      "Epoch 668/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3471 - accuracy: 0.8551 - val_loss: 0.4943 - val_accuracy: 0.8128\n",
      "Epoch 669/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3557 - accuracy: 0.8501 - val_loss: 0.4434 - val_accuracy: 0.8438\n",
      "Epoch 670/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3456 - accuracy: 0.8582 - val_loss: 0.4448 - val_accuracy: 0.8359\n",
      "Epoch 671/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3378 - accuracy: 0.8631 - val_loss: 0.4523 - val_accuracy: 0.8354\n",
      "Epoch 672/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3461 - accuracy: 0.8592 - val_loss: 0.4420 - val_accuracy: 0.8345\n",
      "Epoch 673/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3600 - accuracy: 0.8499 - val_loss: 0.4402 - val_accuracy: 0.8374\n",
      "Epoch 674/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3416 - accuracy: 0.8560 - val_loss: 0.4445 - val_accuracy: 0.8374\n",
      "Epoch 675/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3557 - accuracy: 0.8511 - val_loss: 0.4625 - val_accuracy: 0.8286\n",
      "Epoch 676/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3453 - accuracy: 0.8549 - val_loss: 0.4431 - val_accuracy: 0.8381\n",
      "Epoch 677/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3509 - accuracy: 0.8527 - val_loss: 0.4495 - val_accuracy: 0.8381\n",
      "Epoch 678/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3333 - accuracy: 0.8646 - val_loss: 0.4539 - val_accuracy: 0.8334\n",
      "Epoch 679/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3457 - accuracy: 0.8545 - val_loss: 0.4573 - val_accuracy: 0.8331oss: 0.344\n",
      "Epoch 680/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3489 - accuracy: 0.8553 - val_loss: 0.4550 - val_accuracy: 0.8361\n",
      "Epoch 681/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3491 - accuracy: 0.8549 - val_loss: 0.4399 - val_accuracy: 0.8359\n",
      "Epoch 682/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3432 - accuracy: 0.8582 - val_loss: 0.4391 - val_accuracy: 0.8431\n",
      "Epoch 683/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3452 - accuracy: 0.8560 - val_loss: 0.4390 - val_accuracy: 0.8393\n",
      "Epoch 684/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3698 - accuracy: 0.8485 - val_loss: 0.4537 - val_accuracy: 0.8361\n",
      "Epoch 685/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3499 - accuracy: 0.8576 - val_loss: 0.4521 - val_accuracy: 0.8377\n",
      "Epoch 686/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3441 - accuracy: 0.8584 - val_loss: 0.4606 - val_accuracy: 0.8309\n",
      "Epoch 687/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3413 - accuracy: 0.8572 - val_loss: 0.4337 - val_accuracy: 0.8399\n",
      "Epoch 688/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3375 - accuracy: 0.8611 - val_loss: 0.4336 - val_accuracy: 0.8384\n",
      "Epoch 689/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3403 - accuracy: 0.8581 - val_loss: 0.4459 - val_accuracy: 0.8397\n",
      "Epoch 690/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3566 - accuracy: 0.8525 - val_loss: 0.4473 - val_accuracy: 0.8424\n",
      "Epoch 691/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3489 - accuracy: 0.8510 - val_loss: 0.4651 - val_accuracy: 0.8347\n",
      "Epoch 692/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3536 - accuracy: 0.8532 - val_loss: 0.4283 - val_accuracy: 0.8447\n",
      "Epoch 693/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3508 - accuracy: 0.8618 - val_loss: 0.4390 - val_accuracy: 0.8381\n",
      "Epoch 694/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3368 - accuracy: 0.8580 - val_loss: 0.4384 - val_accuracy: 0.8395\n",
      "Epoch 695/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3441 - accuracy: 0.8557 - val_loss: 0.4569 - val_accuracy: 0.8304\n",
      "Epoch 696/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3517 - accuracy: 0.8538 - val_loss: 0.4410 - val_accuracy: 0.8420\n",
      "Epoch 697/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3452 - accuracy: 0.8544 - val_loss: 0.4390 - val_accuracy: 0.8307\n",
      "Epoch 698/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3493 - accuracy: 0.8580 - val_loss: 0.4370 - val_accuracy: 0.8393\n",
      "Epoch 699/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3422 - accuracy: 0.8622 - val_loss: 0.4558 - val_accuracy: 0.8322\n",
      "Epoch 700/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3429 - accuracy: 0.8606 - val_loss: 0.4642 - val_accuracy: 0.8320\n",
      "Epoch 701/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3491 - accuracy: 0.8554 - val_loss: 0.4411 - val_accuracy: 0.8381\n",
      "Epoch 702/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3551 - accuracy: 0.8547 - val_loss: 0.4377 - val_accuracy: 0.8431\n",
      "Epoch 703/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3516 - accuracy: 0.8550 - val_loss: 0.4459 - val_accuracy: 0.8336\n",
      "Epoch 704/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3396 - accuracy: 0.8606 - val_loss: 0.4447 - val_accuracy: 0.8336\n",
      "Epoch 705/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3517 - accuracy: 0.8537 - val_loss: 0.4463 - val_accuracy: 0.8402\n",
      "Epoch 706/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3512 - accuracy: 0.8530 - val_loss: 0.4297 - val_accuracy: 0.8381\n",
      "Epoch 707/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3456 - accuracy: 0.8570 - val_loss: 0.4438 - val_accuracy: 0.8431\n",
      "Epoch 708/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3577 - accuracy: 0.8512 - val_loss: 0.4610 - val_accuracy: 0.8322\n",
      "Epoch 709/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3484 - accuracy: 0.8577 - val_loss: 0.4462 - val_accuracy: 0.8402\n",
      "Epoch 710/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3480 - accuracy: 0.8579 - val_loss: 0.4403 - val_accuracy: 0.8320\n",
      "Epoch 711/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3524 - accuracy: 0.8538 - val_loss: 0.4307 - val_accuracy: 0.8524\n",
      "Epoch 712/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3478 - accuracy: 0.8512 - val_loss: 0.4581 - val_accuracy: 0.8420\n",
      "Epoch 713/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3324 - accuracy: 0.8620 - val_loss: 0.4375 - val_accuracy: 0.8336\n",
      "Epoch 714/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3417 - accuracy: 0.8580 - val_loss: 0.4250 - val_accuracy: 0.8429\n",
      "Epoch 715/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3409 - accuracy: 0.8569 - val_loss: 0.4209 - val_accuracy: 0.8408\n",
      "Epoch 716/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3480 - accuracy: 0.8583 - val_loss: 0.4357 - val_accuracy: 0.8402\n",
      "Epoch 717/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3455 - accuracy: 0.8568 - val_loss: 0.4303 - val_accuracy: 0.8406\n",
      "Epoch 718/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3323 - accuracy: 0.8618 - val_loss: 0.4431 - val_accuracy: 0.8325\n",
      "Epoch 719/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3437 - accuracy: 0.8568 - val_loss: 0.4395 - val_accuracy: 0.8381\n",
      "Epoch 720/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3446 - accuracy: 0.8568 - val_loss: 0.4444 - val_accuracy: 0.8352\n",
      "Epoch 721/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3475 - accuracy: 0.8556 - val_loss: 0.4297 - val_accuracy: 0.8411\n",
      "Epoch 722/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3378 - accuracy: 0.8596 - val_loss: 0.4398 - val_accuracy: 0.8370\n",
      "Epoch 723/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3457 - accuracy: 0.8566 - val_loss: 0.4265 - val_accuracy: 0.8399\n",
      "Epoch 724/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.4500 - val_accuracy: 0.8384\n",
      "Epoch 725/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3427 - accuracy: 0.8585 - val_loss: 0.4353 - val_accuracy: 0.8395\n",
      "Epoch 726/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3460 - accuracy: 0.8559 - val_loss: 0.4567 - val_accuracy: 0.8309\n",
      "Epoch 727/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3345 - accuracy: 0.8629 - val_loss: 0.4501 - val_accuracy: 0.8359\n",
      "Epoch 728/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3424 - accuracy: 0.8581 - val_loss: 0.4298 - val_accuracy: 0.8415\n",
      "Epoch 729/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3535 - accuracy: 0.8577 - val_loss: 0.4247 - val_accuracy: 0.8399\n",
      "Epoch 730/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3435 - accuracy: 0.8538 - val_loss: 0.4521 - val_accuracy: 0.8297\n",
      "Epoch 731/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3443 - accuracy: 0.8533 - val_loss: 0.4331 - val_accuracy: 0.8365\n",
      "Epoch 732/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3425 - accuracy: 0.8583 - val_loss: 0.4342 - val_accuracy: 0.8413\n",
      "Epoch 733/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3428 - accuracy: 0.8559 - val_loss: 0.4305 - val_accuracy: 0.8397\n",
      "Epoch 734/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3531 - accuracy: 0.8517 - val_loss: 0.4609 - val_accuracy: 0.8248\n",
      "Epoch 735/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3343 - accuracy: 0.8646 - val_loss: 0.4391 - val_accuracy: 0.8356\n",
      "Epoch 736/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3419 - accuracy: 0.8582 - val_loss: 0.4385 - val_accuracy: 0.8368\n",
      "Epoch 737/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3472 - accuracy: 0.8547 - val_loss: 0.4594 - val_accuracy: 0.8309\n",
      "Epoch 738/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3493 - accuracy: 0.8574 - val_loss: 0.4349 - val_accuracy: 0.8427\n",
      "Epoch 739/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3393 - accuracy: 0.8597 - val_loss: 0.4348 - val_accuracy: 0.8445\n",
      "Epoch 740/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3434 - accuracy: 0.8550 - val_loss: 0.4674 - val_accuracy: 0.8388\n",
      "Epoch 741/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3402 - accuracy: 0.8561 - val_loss: 0.4217 - val_accuracy: 0.8433\n",
      "Epoch 742/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3554 - accuracy: 0.8516 - val_loss: 0.4527 - val_accuracy: 0.8307\n",
      "Epoch 743/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3482 - accuracy: 0.8537 - val_loss: 0.4532 - val_accuracy: 0.8325\n",
      "Epoch 744/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3304 - accuracy: 0.8629 - val_loss: 0.4415 - val_accuracy: 0.8440\n",
      "Epoch 745/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3362 - accuracy: 0.8639 - val_loss: 0.4359 - val_accuracy: 0.8422\n",
      "Epoch 746/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3439 - accuracy: 0.8569 - val_loss: 0.4388 - val_accuracy: 0.8361\n",
      "Epoch 747/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3372 - accuracy: 0.8589 - val_loss: 0.4384 - val_accuracy: 0.8377\n",
      "Epoch 748/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3320 - accuracy: 0.8627 - val_loss: 0.4369 - val_accuracy: 0.8402\n",
      "Epoch 749/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3404 - accuracy: 0.8590 - val_loss: 0.4363 - val_accuracy: 0.8420\n",
      "Epoch 750/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3341 - accuracy: 0.8607 - val_loss: 0.4561 - val_accuracy: 0.8368\n",
      "Epoch 751/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3324 - accuracy: 0.8643 - val_loss: 0.4357 - val_accuracy: 0.8377\n",
      "Epoch 752/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3420 - accuracy: 0.8596 - val_loss: 0.4389 - val_accuracy: 0.8429\n",
      "Epoch 753/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3439 - accuracy: 0.8585 - val_loss: 0.4605 - val_accuracy: 0.8279\n",
      "Epoch 754/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3594 - accuracy: 0.8525 - val_loss: 0.4393 - val_accuracy: 0.8372\n",
      "Epoch 755/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3468 - accuracy: 0.8591 - val_loss: 0.4222 - val_accuracy: 0.8379\n",
      "Epoch 756/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3346 - accuracy: 0.8637 - val_loss: 0.4239 - val_accuracy: 0.8431\n",
      "Epoch 757/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3437 - accuracy: 0.8598 - val_loss: 0.4269 - val_accuracy: 0.8508\n",
      "Epoch 758/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3529 - accuracy: 0.8518 - val_loss: 0.4554 - val_accuracy: 0.8384\n",
      "Epoch 759/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3413 - accuracy: 0.8568 - val_loss: 0.4209 - val_accuracy: 0.8465\n",
      "Epoch 760/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3374 - accuracy: 0.8586 - val_loss: 0.4446 - val_accuracy: 0.8399\n",
      "Epoch 761/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3463 - accuracy: 0.8593 - val_loss: 0.4439 - val_accuracy: 0.8381\n",
      "Epoch 762/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3420 - accuracy: 0.8577 - val_loss: 0.4311 - val_accuracy: 0.8447\n",
      "Epoch 763/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3373 - accuracy: 0.8606 - val_loss: 0.4444 - val_accuracy: 0.8372\n",
      "Epoch 764/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3410 - accuracy: 0.8608 - val_loss: 0.4634 - val_accuracy: 0.8365\n",
      "Epoch 765/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3353 - accuracy: 0.8583 - val_loss: 0.4305 - val_accuracy: 0.8408\n",
      "Epoch 766/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3370 - accuracy: 0.8623 - val_loss: 0.4275 - val_accuracy: 0.8454\n",
      "Epoch 767/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3423 - accuracy: 0.8607 - val_loss: 0.4410 - val_accuracy: 0.8427\n",
      "Epoch 768/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3292 - accuracy: 0.8612 - val_loss: 0.4553 - val_accuracy: 0.8345\n",
      "Epoch 769/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3390 - accuracy: 0.8613 - val_loss: 0.4454 - val_accuracy: 0.8379\n",
      "Epoch 770/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3279 - accuracy: 0.8623 - val_loss: 0.4386 - val_accuracy: 0.8429\n",
      "Epoch 771/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3321 - accuracy: 0.8651 - val_loss: 0.4448 - val_accuracy: 0.8447\n",
      "Epoch 772/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3474 - accuracy: 0.8580 - val_loss: 0.4283 - val_accuracy: 0.8465\n",
      "Epoch 773/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3155 - accuracy: 0.8703 - val_loss: 0.4386 - val_accuracy: 0.8411\n",
      "Epoch 774/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3430 - accuracy: 0.8605 - val_loss: 0.4278 - val_accuracy: 0.8431\n",
      "Epoch 775/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3273 - accuracy: 0.8646 - val_loss: 0.4620 - val_accuracy: 0.8304\n",
      "Epoch 776/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3382 - accuracy: 0.8594 - val_loss: 0.4314 - val_accuracy: 0.8476\n",
      "Epoch 777/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3417 - accuracy: 0.8570 - val_loss: 0.4427 - val_accuracy: 0.8386\n",
      "Epoch 778/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3326 - accuracy: 0.8629 - val_loss: 0.4421 - val_accuracy: 0.8442\n",
      "Epoch 779/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3434 - accuracy: 0.8553 - val_loss: 0.4386 - val_accuracy: 0.8447\n",
      "Epoch 780/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3426 - accuracy: 0.8572 - val_loss: 0.4293 - val_accuracy: 0.8506\n",
      "Epoch 781/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.4318 - val_accuracy: 0.8424\n",
      "Epoch 782/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3379 - accuracy: 0.8615 - val_loss: 0.4384 - val_accuracy: 0.8372\n",
      "Epoch 783/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3306 - accuracy: 0.8613 - val_loss: 0.4296 - val_accuracy: 0.8454\n",
      "Epoch 784/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3334 - accuracy: 0.8613 - val_loss: 0.4426 - val_accuracy: 0.8402\n",
      "Epoch 785/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3309 - accuracy: 0.8665 - val_loss: 0.4320 - val_accuracy: 0.8411\n",
      "Epoch 786/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3379 - accuracy: 0.8566 - val_loss: 0.4369 - val_accuracy: 0.8406\n",
      "Epoch 787/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3377 - accuracy: 0.8618 - val_loss: 0.4324 - val_accuracy: 0.8433\n",
      "Epoch 788/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3343 - accuracy: 0.8616 - val_loss: 0.4376 - val_accuracy: 0.8463\n",
      "Epoch 789/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3502 - accuracy: 0.8559 - val_loss: 0.4198 - val_accuracy: 0.8499\n",
      "Epoch 790/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3292 - accuracy: 0.8645 - val_loss: 0.4140 - val_accuracy: 0.8479\n",
      "Epoch 791/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3352 - accuracy: 0.8650 - val_loss: 0.4214 - val_accuracy: 0.8483\n",
      "Epoch 792/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3436 - accuracy: 0.8562 - val_loss: 0.4227 - val_accuracy: 0.8454\n",
      "Epoch 793/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3332 - accuracy: 0.8639 - val_loss: 0.4269 - val_accuracy: 0.8522\n",
      "Epoch 794/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3304 - accuracy: 0.8665 - val_loss: 0.4285 - val_accuracy: 0.8429\n",
      "Epoch 795/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3533 - accuracy: 0.8524 - val_loss: 0.4224 - val_accuracy: 0.8483\n",
      "Epoch 796/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3445 - accuracy: 0.8534 - val_loss: 0.4347 - val_accuracy: 0.8481\n",
      "Epoch 797/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3456 - accuracy: 0.8601 - val_loss: 0.4184 - val_accuracy: 0.8470\n",
      "Epoch 798/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3334 - accuracy: 0.8656 - val_loss: 0.4371 - val_accuracy: 0.8424\n",
      "Epoch 799/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3336 - accuracy: 0.8603 - val_loss: 0.4613 - val_accuracy: 0.8325\n",
      "Epoch 800/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3353 - accuracy: 0.8605 - val_loss: 0.4350 - val_accuracy: 0.8449\n",
      "Epoch 801/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3292 - accuracy: 0.8647 - val_loss: 0.4401 - val_accuracy: 0.8420\n",
      "Epoch 802/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3350 - accuracy: 0.8605 - val_loss: 0.4253 - val_accuracy: 0.8490\n",
      "Epoch 803/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3386 - accuracy: 0.8602 - val_loss: 0.4372 - val_accuracy: 0.8458\n",
      "Epoch 804/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3327 - accuracy: 0.8600 - val_loss: 0.4358 - val_accuracy: 0.8431\n",
      "Epoch 805/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3233 - accuracy: 0.8672 - val_loss: 0.4294 - val_accuracy: 0.8470\n",
      "Epoch 806/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3328 - accuracy: 0.8660 - val_loss: 0.4259 - val_accuracy: 0.8499\n",
      "Epoch 807/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3349 - accuracy: 0.8641 - val_loss: 0.4367 - val_accuracy: 0.8415\n",
      "Epoch 808/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3360 - accuracy: 0.8638 - val_loss: 0.4458 - val_accuracy: 0.8449\n",
      "Epoch 809/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3299 - accuracy: 0.8650 - val_loss: 0.4431 - val_accuracy: 0.8424\n",
      "Epoch 810/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3272 - accuracy: 0.8639 - val_loss: 0.4583 - val_accuracy: 0.8431\n",
      "Epoch 811/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3341 - accuracy: 0.8632 - val_loss: 0.4112 - val_accuracy: 0.8508\n",
      "Epoch 812/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3351 - accuracy: 0.8600 - val_loss: 0.4134 - val_accuracy: 0.8384\n",
      "Epoch 813/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3269 - accuracy: 0.8664 - val_loss: 0.4276 - val_accuracy: 0.8399\n",
      "Epoch 814/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3353 - accuracy: 0.8611 - val_loss: 0.4321 - val_accuracy: 0.8406\n",
      "Epoch 815/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8621 - val_loss: 0.4395 - val_accuracy: 0.8309\n",
      "Epoch 816/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3242 - accuracy: 0.8635 - val_loss: 0.4309 - val_accuracy: 0.8472\n",
      "Epoch 817/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3349 - accuracy: 0.8598 - val_loss: 0.4357 - val_accuracy: 0.8431\n",
      "Epoch 818/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3476 - accuracy: 0.8562 - val_loss: 0.4254 - val_accuracy: 0.8526\n",
      "Epoch 819/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3303 - accuracy: 0.8643 - val_loss: 0.4315 - val_accuracy: 0.8427\n",
      "Epoch 820/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3332 - accuracy: 0.8616 - val_loss: 0.4223 - val_accuracy: 0.8537\n",
      "Epoch 821/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3225 - accuracy: 0.8686 - val_loss: 0.4155 - val_accuracy: 0.8542\n",
      "Epoch 822/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3324 - accuracy: 0.8637 - val_loss: 0.4366 - val_accuracy: 0.8379\n",
      "Epoch 823/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3284 - accuracy: 0.8644 - val_loss: 0.4187 - val_accuracy: 0.8497\n",
      "Epoch 824/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3279 - accuracy: 0.8635 - val_loss: 0.4146 - val_accuracy: 0.8472\n",
      "Epoch 825/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3321 - accuracy: 0.8650 - val_loss: 0.4174 - val_accuracy: 0.8497\n",
      "Epoch 826/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3375 - accuracy: 0.8632 - val_loss: 0.4323 - val_accuracy: 0.8370\n",
      "Epoch 827/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3366 - accuracy: 0.8567 - val_loss: 0.4188 - val_accuracy: 0.8499\n",
      "Epoch 828/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3328 - accuracy: 0.8634 - val_loss: 0.4305 - val_accuracy: 0.8467\n",
      "Epoch 829/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3429 - accuracy: 0.8625 - val_loss: 0.4360 - val_accuracy: 0.8431\n",
      "Epoch 830/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3325 - accuracy: 0.8637 - val_loss: 0.4382 - val_accuracy: 0.8381\n",
      "Epoch 831/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3210 - accuracy: 0.8664 - val_loss: 0.4612 - val_accuracy: 0.8307\n",
      "Epoch 832/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3286 - accuracy: 0.8666 - val_loss: 0.4319 - val_accuracy: 0.8454\n",
      "Epoch 833/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3240 - accuracy: 0.8652 - val_loss: 0.4347 - val_accuracy: 0.8485\n",
      "Epoch 834/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3291 - accuracy: 0.8656 - val_loss: 0.4261 - val_accuracy: 0.8476\n",
      "Epoch 835/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3294 - accuracy: 0.8640 - val_loss: 0.4161 - val_accuracy: 0.8485\n",
      "Epoch 836/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3324 - accuracy: 0.8600 - val_loss: 0.4369 - val_accuracy: 0.8451\n",
      "Epoch 837/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3277 - accuracy: 0.8667 - val_loss: 0.4420 - val_accuracy: 0.8402\n",
      "Epoch 838/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3374 - accuracy: 0.8647 - val_loss: 0.4211 - val_accuracy: 0.8490\n",
      "Epoch 839/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3297 - accuracy: 0.8645 - val_loss: 0.4095 - val_accuracy: 0.8488\n",
      "Epoch 840/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3228 - accuracy: 0.8679 - val_loss: 0.4284 - val_accuracy: 0.8404\n",
      "Epoch 841/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3327 - accuracy: 0.8662 - val_loss: 0.4234 - val_accuracy: 0.8397\n",
      "Epoch 842/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3231 - accuracy: 0.8688 - val_loss: 0.4350 - val_accuracy: 0.8458\n",
      "Epoch 843/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3327 - accuracy: 0.8664 - val_loss: 0.4257 - val_accuracy: 0.8515\n",
      "Epoch 844/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3308 - accuracy: 0.8623 - val_loss: 0.4281 - val_accuracy: 0.8460\n",
      "Epoch 845/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3188 - accuracy: 0.8690 - val_loss: 0.4216 - val_accuracy: 0.8465\n",
      "Epoch 846/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3364 - accuracy: 0.8609 - val_loss: 0.4254 - val_accuracy: 0.8528\n",
      "Epoch 847/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3348 - accuracy: 0.8643 - val_loss: 0.4471 - val_accuracy: 0.8402\n",
      "Epoch 848/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3273 - accuracy: 0.8674 - val_loss: 0.4204 - val_accuracy: 0.8497\n",
      "Epoch 849/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3304 - accuracy: 0.8642 - val_loss: 0.4259 - val_accuracy: 0.8458\n",
      "Epoch 850/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3315 - accuracy: 0.8601 - val_loss: 0.4124 - val_accuracy: 0.8449\n",
      "Epoch 851/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3351 - accuracy: 0.8623 - val_loss: 0.4198 - val_accuracy: 0.8508\n",
      "Epoch 852/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3304 - accuracy: 0.8647 - val_loss: 0.4148 - val_accuracy: 0.8499\n",
      "Epoch 853/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3190 - accuracy: 0.8706 - val_loss: 0.4376 - val_accuracy: 0.8463\n",
      "Epoch 854/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3196 - accuracy: 0.8675 - val_loss: 0.4326 - val_accuracy: 0.8463\n",
      "Epoch 855/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3369 - accuracy: 0.8655 - val_loss: 0.4295 - val_accuracy: 0.8402\n",
      "Epoch 856/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3257 - accuracy: 0.8637 - val_loss: 0.4369 - val_accuracy: 0.8408\n",
      "Epoch 857/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3328 - accuracy: 0.8654 - val_loss: 0.4552 - val_accuracy: 0.8352\n",
      "Epoch 858/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3294 - accuracy: 0.8673 - val_loss: 0.4250 - val_accuracy: 0.8463\n",
      "Epoch 859/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3127 - accuracy: 0.8729 - val_loss: 0.4424 - val_accuracy: 0.8415\n",
      "Epoch 860/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3297 - accuracy: 0.8667 - val_loss: 0.4349 - val_accuracy: 0.8458\n",
      "Epoch 861/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3420 - accuracy: 0.8599 - val_loss: 0.4232 - val_accuracy: 0.8501\n",
      "Epoch 862/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3360 - accuracy: 0.8645 - val_loss: 0.4375 - val_accuracy: 0.8479\n",
      "Epoch 863/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3335 - accuracy: 0.8620 - val_loss: 0.4242 - val_accuracy: 0.8528\n",
      "Epoch 864/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3231 - accuracy: 0.8657 - val_loss: 0.4373 - val_accuracy: 0.8481\n",
      "Epoch 865/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3197 - accuracy: 0.8704 - val_loss: 0.4275 - val_accuracy: 0.8442\n",
      "Epoch 866/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3272 - accuracy: 0.8677 - val_loss: 0.4326 - val_accuracy: 0.8472\n",
      "Epoch 867/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3261 - accuracy: 0.8658 - val_loss: 0.4317 - val_accuracy: 0.8479\n",
      "Epoch 868/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3252 - accuracy: 0.8676 - val_loss: 0.4239 - val_accuracy: 0.8479\n",
      "Epoch 869/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3264 - accuracy: 0.8663 - val_loss: 0.4351 - val_accuracy: 0.8499\n",
      "Epoch 870/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3240 - accuracy: 0.8682 - val_loss: 0.4348 - val_accuracy: 0.8411\n",
      "Epoch 871/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3306 - accuracy: 0.8662 - val_loss: 0.4441 - val_accuracy: 0.8451\n",
      "Epoch 872/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.4342 - val_accuracy: 0.8415\n",
      "Epoch 873/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3280 - accuracy: 0.8654 - val_loss: 0.4268 - val_accuracy: 0.8515\n",
      "Epoch 874/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3299 - accuracy: 0.8665 - val_loss: 0.4260 - val_accuracy: 0.8544\n",
      "Epoch 875/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3163 - accuracy: 0.8722 - val_loss: 0.4163 - val_accuracy: 0.8551\n",
      "Epoch 876/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3295 - accuracy: 0.8639 - val_loss: 0.4321 - val_accuracy: 0.8463\n",
      "Epoch 877/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3412 - accuracy: 0.8589 - val_loss: 0.4350 - val_accuracy: 0.8422\n",
      "Epoch 878/910\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 0.3238 - accuracy: 0.8695 - val_loss: 0.4421 - val_accuracy: 0.8393\n",
      "Epoch 879/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3224 - accuracy: 0.8658 - val_loss: 0.4256 - val_accuracy: 0.8533\n",
      "Epoch 880/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3276 - accuracy: 0.8623 - val_loss: 0.4104 - val_accuracy: 0.8544\n",
      "Epoch 881/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3307 - accuracy: 0.8646 - val_loss: 0.4302 - val_accuracy: 0.8474\n",
      "Epoch 882/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3158 - accuracy: 0.8726 - val_loss: 0.4141 - val_accuracy: 0.8519\n",
      "Epoch 883/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3253 - accuracy: 0.8701 - val_loss: 0.4424 - val_accuracy: 0.8438\n",
      "Epoch 884/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3319 - accuracy: 0.8668 - val_loss: 0.4381 - val_accuracy: 0.8436\n",
      "Epoch 885/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3114 - accuracy: 0.8703 - val_loss: 0.4463 - val_accuracy: 0.8481\n",
      "Epoch 886/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3440 - accuracy: 0.8612 - val_loss: 0.4221 - val_accuracy: 0.8528\n",
      "Epoch 887/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3235 - accuracy: 0.8636 - val_loss: 0.4457 - val_accuracy: 0.8429\n",
      "Epoch 888/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3150 - accuracy: 0.8688 - val_loss: 0.4266 - val_accuracy: 0.8501\n",
      "Epoch 889/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3208 - accuracy: 0.8711 - val_loss: 0.4241 - val_accuracy: 0.8458\n",
      "Epoch 890/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3293 - accuracy: 0.8631 - val_loss: 0.4313 - val_accuracy: 0.8465\n",
      "Epoch 891/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3198 - accuracy: 0.8698 - val_loss: 0.4181 - val_accuracy: 0.8562\n",
      "Epoch 892/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3335 - accuracy: 0.8617 - val_loss: 0.4491 - val_accuracy: 0.8390\n",
      "Epoch 893/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3269 - accuracy: 0.8649 - val_loss: 0.4364 - val_accuracy: 0.8494\n",
      "Epoch 894/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3151 - accuracy: 0.8708 - val_loss: 0.4353 - val_accuracy: 0.8447\n",
      "Epoch 895/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3322 - accuracy: 0.8656 - val_loss: 0.4154 - val_accuracy: 0.8537\n",
      "Epoch 896/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3337 - accuracy: 0.8634 - val_loss: 0.4357 - val_accuracy: 0.8535\n",
      "Epoch 897/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3370 - accuracy: 0.8640 - val_loss: 0.4150 - val_accuracy: 0.8485\n",
      "Epoch 898/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3286 - accuracy: 0.8646 - val_loss: 0.4068 - val_accuracy: 0.8549\n",
      "Epoch 899/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.4247 - val_accuracy: 0.8479\n",
      "Epoch 900/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3247 - accuracy: 0.8671 - val_loss: 0.4096 - val_accuracy: 0.8547\n",
      "Epoch 901/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3132 - accuracy: 0.8714 - val_loss: 0.4468 - val_accuracy: 0.8456\n",
      "Epoch 902/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3131 - accuracy: 0.8713 - val_loss: 0.4156 - val_accuracy: 0.8506\n",
      "Epoch 903/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3236 - accuracy: 0.8648 - val_loss: 0.4486 - val_accuracy: 0.8397\n",
      "Epoch 904/910\n",
      "691/691 [==============================] - 4s 5ms/step - loss: 0.3299 - accuracy: 0.8646 - val_loss: 0.4323 - val_accuracy: 0.8497\n",
      "Epoch 905/910\n",
      "691/691 [==============================] - 3s 5ms/step - loss: 0.3238 - accuracy: 0.8652 - val_loss: 0.4269 - val_accuracy: 0.8492\n",
      "Epoch 906/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3277 - accuracy: 0.8624 - val_loss: 0.4214 - val_accuracy: 0.8463\n",
      "Epoch 907/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3193 - accuracy: 0.8687 - val_loss: 0.4312 - val_accuracy: 0.8465\n",
      "Epoch 908/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3141 - accuracy: 0.8722 - val_loss: 0.4257 - val_accuracy: 0.8440\n",
      "Epoch 909/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3273 - accuracy: 0.8674 - val_loss: 0.4197 - val_accuracy: 0.8504\n",
      "Epoch 910/910\n",
      "691/691 [==============================] - 3s 4ms/step - loss: 0.3225 - accuracy: 0.8658 - val_loss: 0.4252 - val_accuracy: 0.8556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avik\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "h2 = final_estimator2.fit(edited_train.iloc[:,:40] , edited_train['Disorder Subclass'] , epochs=910, verbose=1, batch_size = 32,\n",
    "                   validation_data = (valid_data.iloc[:,:40] , valid_data['Disorder Subclass']) )\n",
    "# plot history\n",
    "plt.plot(h2.history['accuracy'], label='train')\n",
    "plt.plot(h2.history['val_accuracy'], label='test')\n",
    "plt.legend(loc ='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(xlabel=\"epochs\")\n",
    "plt.ylabel(ylabel=\"accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# making prediction in test data :\n",
    "Disorder_Subclass_pred = final_estimator2.predict(edited_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation : On full train data accuracy is 0.866 approx. \n",
    "## Plot reveals that the model is performing better and giving a prediction accuracy of 0.856 approximately on validation data which is no longer an unseen data . \n",
    "## Finally we have make prediction 'Disorder_Subclass_pred' in encoded format for the original test data and then rolling back to the given categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cystic fibrosis', 'Mitochondrial myopathy', 'Diabetes', ...,\n",
       "       'Diabetes', 'Cancer', 'Tay-Sachs'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Disorder_Subclass = encoder2.inverse_transform(Disorder_Subclass_pred)\n",
    "Disorder_Subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layout :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_test['Disorder Subclass'] = Disorder_Subclass\n",
    "edited_test['Genetic_Disorder'] = Genetic_Disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Submission File : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Patient Id':test['Patient Id'].values,\n",
    "    'Genetic Disorder': edited_test['Genetic_Disorder'].values,\n",
    "    'Disorder Subclass': edited_test['Disorder Subclass'].values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Submission File in csv format : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"C:/Users/Avik/Desktop/OfGeneticsGenomeSubmission.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving leaderboard rank 14 , score is 35.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ################################## THE END ################################# # "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
